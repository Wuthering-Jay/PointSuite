# DataModule å¿«é€Ÿå‚è€ƒ

## ğŸ“¦ å¯¼å…¥

```python
# å‘åå…¼å®¹
from pointsuite.data.point_datamodule import PointDataModule

# æ–°æ–¹å¼ï¼ˆæ¨èï¼‰
from pointsuite.data.datamodule_binpkl import BinPklDataModule

# åŸºç±»ï¼ˆç”¨äºè‡ªå®šä¹‰ï¼‰
from pointsuite.data.datamodule_base import DataModuleBase

# ä»åŒ…å¯¼å…¥
from pointsuite.data import PointDataModule, BinPklDataModule, DataModuleBase
```

## ğŸ¯ åŸºç¡€ç”¨æ³•

```python
datamodule = BinPklDataModule(
    data_root='path/to/data',
    train_files=['train.pkl'],  # å¯é€‰ï¼ŒNone åˆ™è‡ªåŠ¨å‘ç°
    val_files=['val.pkl'],
    test_files=['test.pkl'],
    batch_size=8,               # use_dynamic_batch=False æ—¶ä½¿ç”¨
    num_workers=4,
)

datamodule.setup('fit')
trainer.fit(model, datamodule)
```

## ğŸ”¥ DynamicBatchSampler

```python
datamodule = BinPklDataModule(
    data_root='path/to/data',
    use_dynamic_batch=True,     # â† å¯ç”¨åŠ¨æ€æ‰¹æ¬¡
    max_points=500000,          # â† æ¯æ‰¹æœ€å¤š50ä¸‡ç‚¹
    num_workers=8,
)
```

## âš–ï¸ åŠ æƒé‡‡æ ·ï¼ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰

```python
# è®¡ç®—æ ·æœ¬æƒé‡
sample_weights = compute_weights_from_class_distribution(dataset)

datamodule = BinPklDataModule(
    data_root='path/to/data',
    use_dynamic_batch=True,
    max_points=500000,
    train_sampler_weights=sample_weights,  # â† åŠ æƒé‡‡æ ·
)
```

## ğŸ› ï¸ å®Œæ•´é…ç½®

```python
datamodule = BinPklDataModule(
    # æ•°æ®è·¯å¾„
    data_root='path/to/data',
    train_files=['train.pkl'],
    val_files=['val.pkl'],
    test_files=['test.pkl'],
    
    # BinPkl ç‰¹å®šå‚æ•°
    assets=['coord', 'intensity', 'classification'],
    ignore_label=-1,
    loop=2,                     # è®­ç»ƒæ•°æ®å¾ªç¯2æ¬¡
    cache_data=False,
    class_mapping={0: 0, 1: 1, 2: 2, 6: 3, 9: 4},
    
    # é‡‡æ ·ç­–ç•¥
    use_dynamic_batch=True,     # åŠ¨æ€æ‰¹æ¬¡
    max_points=500000,
    train_sampler_weights=None, # å¯é€‰ï¼šæ ·æœ¬æƒé‡
    
    # DataLoader å‚æ•°
    batch_size=8,               # ä»…å½“ use_dynamic_batch=False
    num_workers=8,
    pin_memory=True,
    persistent_workers=True,
    prefetch_factor=4,
    
    # æ•°æ®å¢å¼º
    train_transforms=[...],
    val_transforms=[...],
    test_transforms=[...],
)
```

## ğŸ¨ åˆ›å»ºè‡ªå®šä¹‰ DataModule

```python
from pointsuite.data.datamodule_base import DataModuleBase

class MyDataModule(DataModuleBase):
    def __init__(self, data_root, my_param=None, **kwargs):
        self.my_param = my_param
        super().__init__(data_root=data_root, **kwargs)
    
    def _create_dataset(self, data_paths, split, transforms):
        return MyDataset(
            data_paths=data_paths,
            split=split,
            my_param=self.my_param,
            transform=transforms
        )

# ä½¿ç”¨
datamodule = MyDataModule(
    data_root='path/to/data',
    my_param='value',
    use_dynamic_batch=True,
    max_points=500000
)
```

## ğŸ” æ–¹æ³•

### è®¾ç½®å’Œç”Ÿå‘½å‘¨æœŸ
- `setup(stage)` - è®¾ç½®æ•°æ®é›†
- `prepare_data()` - æ•°æ®å‡†å¤‡ï¼ˆå•è¿›ç¨‹ï¼‰
- `teardown(stage)` - æ¸…ç†èµ„æº

### DataLoader åˆ›å»º
- `train_dataloader()` - è®­ç»ƒ DataLoader
- `val_dataloader()` - éªŒè¯ DataLoader
- `test_dataloader()` - æµ‹è¯• DataLoader
- `predict_dataloader()` - é¢„æµ‹ DataLoader

### å·¥å…·æ–¹æ³•
- `get_dataset_info(split)` - è·å–æ•°æ®é›†ä¿¡æ¯
- `print_info()` - æ‰“å°è¯¦ç»†ä¿¡æ¯

## ğŸ“Š æ•°æ®é›†ä¿¡æ¯

```python
datamodule.setup('fit')

# è·å–ä¿¡æ¯
info = datamodule.get_dataset_info('train')
print(info)
# {
#     'split': 'train',
#     'num_samples': 100,
#     'total_length': 200,  # with loop=2
#     'assets': ['coord', 'intensity', 'classification'],
#     'loop': 2,
#     'cache_enabled': False,
#     'class_mapping': {...}
# }

# æ‰“å°æ‰€æœ‰ä¿¡æ¯
datamodule.print_info()
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å°æ•°æ®é›†ï¼ˆ< 10GBï¼‰
```python
datamodule = BinPklDataModule(
    data_root='...',
    batch_size=16,
    num_workers=4,
    cache_data=True,            # â† ç¼“å­˜åˆ°å†…å­˜
    persistent_workers=True,
    prefetch_factor=4,
)
```

### å¤§æ•°æ®é›†ï¼ˆ> 50GBï¼‰
```python
datamodule = BinPklDataModule(
    data_root='...',
    use_dynamic_batch=True,     # â† åŠ¨æ€æ‰¹æ¬¡æ§åˆ¶å†…å­˜
    max_points=500000,
    num_workers=8,
    cache_data=False,           # â† ä¸ç¼“å­˜
    persistent_workers=True,
    prefetch_factor=2,
)
```

### å¤šGPUè®­ç»ƒ
```python
datamodule = BinPklDataModule(
    data_root='...',
    batch_size=2,               # æ¯GPUæ‰¹æ¬¡å¤§å°
    num_workers=8,              # æ¯GPU workeræ•°
    persistent_workers=True,
    pin_memory=True,
)

trainer = pl.Trainer(
    devices=4,                  # 4ä¸ªGPU
    strategy='ddp',
)
trainer.fit(model, datamodule)
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: PointDataModule å’Œ BinPklDataModule æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
A: æ²¡æœ‰åŒºåˆ«ï¼`PointDataModule` æ˜¯ `BinPklDataModule` çš„åˆ«åï¼Œç”¨äºå‘åå…¼å®¹ã€‚

### Q: å¦‚ä½•å¯ç”¨ DynamicBatchSamplerï¼Ÿ
A: è®¾ç½® `use_dynamic_batch=True` å’Œ `max_points=500000`

### Q: å¦‚ä½•å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼Ÿ
A: è®¡ç®—æ ·æœ¬æƒé‡å¹¶ä¼ å…¥ `train_sampler_weights` å‚æ•°

### Q: å¦‚ä½•åˆ›å»ºæ”¯æŒæ–°æ ¼å¼çš„ DataModuleï¼Ÿ
A: ç»§æ‰¿ `DataModuleBase` å¹¶å®ç° `_create_dataset()` æ–¹æ³•

## ğŸ“š æ›´å¤šæ–‡æ¡£

- [å®Œæ•´é‡æ„æ–‡æ¡£](docs/DATAMODULE_REFACTOR.md)
- [DynamicBatchSampler è¯¦ç»†æŒ‡å—](docs/DYNAMIC_BATCH_SAMPLER.md)
- [ç¤ºä¾‹ä»£ç ](examples/datamodule_usage_example.py)
