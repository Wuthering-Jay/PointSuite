# ğŸš€ PointSuite è®­ç»ƒå°±ç»ªæ£€æŸ¥æ¸…å•

## âœ… æ ¸å¿ƒç»„ä»¶çŠ¶æ€

### 1. æ•°æ®æ¨¡å— (DataModule) - âœ… å®Œæ•´
- âœ… `DataModuleBase`: æŠ½è±¡åŸºç±»ï¼Œæ”¯æŒæ‰€æœ‰é˜¶æ®µ
- âœ… `BinPklDataModule`: å…·ä½“å®ç°
- âœ… æ”¯æŒ train/val/test/predict å››ä¸ªé˜¶æ®µ
- âœ… ç‹¬ç«‹çš„æ•°æ®è·¯å¾„é…ç½® (`train_data`, `val_data`, `test_data`, `predict_data`)
- âœ… ç‹¬ç«‹çš„ loop å‚æ•° (`train_loop`, `val_loop`, `test_loop`, `predict_loop`)
- âœ… ç‹¬ç«‹çš„ transform é…ç½®
- âœ… æ”¯æŒ DynamicBatchSamplerï¼ˆè®­ç»ƒå’Œæ¨ç†ç‹¬ç«‹é…ç½®ï¼‰
- âœ… æ”¯æŒ WeightedRandomSamplerï¼ˆä»…è®­ç»ƒé˜¶æ®µï¼‰

### 2. æ•°æ®é›† (Dataset) - âœ… å®Œæ•´
- âœ… `DatasetBase`: æŠ½è±¡åŸºç±»
- âœ… `BinPklDataset`: å…·ä½“å®ç°
- âœ… æ”¯æŒ loop å‚æ•°ï¼ˆæ‰€æœ‰é˜¶æ®µï¼‰
- âœ… æ”¯æŒ class_mappingï¼ˆæ˜ å°„åˆ° ignore_labelï¼‰
- âœ… test/predict é˜¶æ®µæä¾› indices å’Œæ–‡ä»¶ä¿¡æ¯

### 3. ä»»åŠ¡æ¨¡å— (Task) - âœ… å®Œæ•´
- âœ… `BaseTask`: æŠ½è±¡åŸºç±»ï¼ŒåŒ…å«æ‰€æœ‰é˜¶æ®µé€»è¾‘
  - âœ… `training_step`: è®¡ç®—æŸå¤±ï¼Œè¿”å› total_loss
  - âœ… `validation_step`: è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
  - âœ… `test_step`: è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡ï¼ˆæ”¯æŒå›è°ƒï¼‰
  - âœ… `on_validation_epoch_end`: è®°å½•æŒ‡æ ‡
  - âœ… `on_test_epoch_end`: è®°å½•æŒ‡æ ‡
  - âœ… `postprocess_predictions`: Mask3D å…¼å®¹é’©å­
- âœ… `SemanticSegmentationTask`: è¯­ä¹‰åˆ†å‰²å®ç°
  - âœ… `forward`: backbone + head
  - âœ… `training_step`: è°ƒç”¨ BaseTask
  - âœ… `predict_step`: è¿”å› logits + indices + æ–‡ä»¶ä¿¡æ¯

### 4. æŸå¤±å‡½æ•° (Losses) - âœ… å®Œæ•´
- âœ… `CrossEntropyLoss`: æ”¯æŒ ignore_index
- âœ… è‡ªåŠ¨ä»é…ç½®å®ä¾‹åŒ–
- âœ… æ”¯æŒå¤šæŸå¤±å‡½æ•°ç»„åˆï¼ˆå¸¦æƒé‡ï¼‰

### 5. æŒ‡æ ‡ (Metrics) - âœ… å®Œæ•´
- âœ… `OverallAccuracy`: æ•´ä½“ç²¾åº¦
- âœ… `MeanIoU`: å¹³å‡ IoU
- âœ… æ”¯æŒ labels å’Œ logits ä¸¤ç§è¾“å…¥æ ¼å¼
- âœ… è‡ªåŠ¨ä»é…ç½®å®ä¾‹åŒ–
- âœ… åˆ†åˆ«ä¸º val/test é˜¶æ®µåˆ›å»ºç‹¬ç«‹å®ä¾‹

### 6. å›è°ƒå‡½æ•° (Callbacks) - âœ… å®Œæ•´
- âœ… `SegmentationWriter`: ä¿å­˜é¢„æµ‹ç»“æœä¸º .las
  - âœ… `write_on_batch_end`: æµå¼å†™å…¥ä¸´æ—¶æ–‡ä»¶
  - âœ… `on_predict_end`: æŠ•ç¥¨å¹¶ä¿å­˜æœ€ç»ˆç»“æœ
  - âœ… æ”¯æŒ TTAï¼ˆå¤šæ¬¡é¢„æµ‹æŠ•ç¥¨ï¼‰
  - âœ… æ”¯æŒ reverse_class_mapping
  - âœ… ä¿ç•™åŸå§‹ LAS å±æ€§

### 7. Transforms - âœ… å®Œæ•´
- âœ… `CenterShift`: ä¸­å¿ƒåŒ–
- âœ… `AutoNormalizeHNorm`: å½’ä¸€åŒ–é«˜ç¨‹
- âœ… `RandomRotate`: éšæœºæ—‹è½¬
- âœ… `RandomScale`: éšæœºç¼©æ”¾
- âœ… `Collect`: æ”¶é›†æŒ‡å®šå­—æ®µ
- âœ… `ToTensor`: è½¬æ¢ä¸º Tensor

---

## âš ï¸ ç¼ºå¤±ç»„ä»¶

### 1. è®­ç»ƒå…¥å£ (main.py) - âŒ ç©ºæ–‡ä»¶
**è¿™æ˜¯å”¯ä¸€ç¼ºå¤±çš„å…³é”®ç»„ä»¶ï¼**

éœ€è¦å®ç°ï¼š
- LightningCLI é›†æˆ
- æ”¯æŒ fit/validate/test/predict å‘½ä»¤
- é…ç½®æ–‡ä»¶åŠ è½½
- å®éªŒç®¡ç†

---

## ğŸ¯ å››ä¸ªé˜¶æ®µæµç¨‹æ£€æŸ¥

### 1. Training (è®­ç»ƒ) - âœ… æ”¯æŒ
```python
# æ•°æ®æµï¼š
DataModule.train_dataloader() 
  â†’ Dataset.__getitem__(transform=train_transforms, loop=train_loop)
  â†’ collate_fn()
  â†’ Task.training_step(batch)
  â†’ Task._calculate_total_loss() â†’ losses
  â†’ è¿”å› total_loss

# å…³é”®ç‰¹æ€§ï¼š
âœ… æ”¯æŒ DynamicBatchSampler (use_dynamic_batch=True)
âœ… æ”¯æŒ WeightedRandomSampler (use_weighted_sampler=True)
âœ… æ”¯æŒ loop > 1 (æ•°æ®å¢å¼º)
âœ… shuffle=True, drop_last=True
```

### 2. Validation (éªŒè¯) - âœ… æ”¯æŒ
```python
# æ•°æ®æµï¼š
DataModule.val_dataloader()
  â†’ Dataset.__getitem__(transform=val_transforms, loop=val_loop)
  â†’ collate_fn()
  â†’ Task.validation_step(batch)
  â†’ Task._calculate_total_loss() â†’ losses
  â†’ Task.postprocess_predictions() â†’ processed_preds
  â†’ val_metrics.update(processed_preds, batch)
  â†’ Task.on_validation_epoch_end()
  â†’ val_metrics.compute() â†’ è®°å½•åˆ° logger

# å…³é”®ç‰¹æ€§ï¼š
âœ… è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
âœ… ä¸ä¿å­˜é¢„æµ‹ç»“æœ
âœ… æ”¯æŒ DynamicBatchSampler (use_dynamic_batch_inference=True)
âœ… æ”¯æŒ loop > 1 (TTA)
âœ… shuffle=False, drop_last=False
```

### 3. Test (æµ‹è¯•) - âœ… æ”¯æŒ
```python
# æ•°æ®æµï¼š
DataModule.test_dataloader()
  â†’ Dataset.__getitem__(transform=test_transforms, loop=test_loop)
      â†’ è¿”å› {coord, feat, class, indices, bin_file, bin_path, pkl_path}
  â†’ collate_fn()
  â†’ Task.test_step(batch)
  â†’ Task._calculate_total_loss() â†’ losses
  â†’ Task.postprocess_predictions() â†’ processed_preds
  â†’ test_metrics.update(processed_preds, batch)
  â†’ Task.on_test_epoch_end()
  â†’ test_metrics.compute() â†’ è®°å½•åˆ° logger

# å¯é€‰ï¼šä¿å­˜é¢„æµ‹ç»“æœ
trainer.test(model, datamodule, callbacks=[SegmentationWriter(...)])

# å…³é”®ç‰¹æ€§ï¼š
âœ… è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
âœ… å¯é€‰ä¿å­˜é¢„æµ‹ç»“æœï¼ˆé€šè¿‡å›è°ƒï¼‰
âœ… æ”¯æŒ DynamicBatchSampler (use_dynamic_batch_inference=True)
âœ… æ”¯æŒ loop > 1 (TTA)
âœ… shuffle=False, drop_last=False
âœ… Dataset æä¾› indices å’Œæ–‡ä»¶ä¿¡æ¯
```

### 4. Predict (é¢„æµ‹) - âœ… æ”¯æŒ
```python
# æ•°æ®æµï¼š
DataModule.predict_dataloader()
  â†’ Dataset.__getitem__(transform=predict_transforms, loop=predict_loop)
      â†’ è¿”å› {coord, feat, indices, bin_file, bin_path, pkl_path}
      â†’ æ—  'class' å­—æ®µï¼ˆæ— çœŸå€¼æ ‡ç­¾ï¼‰
  â†’ collate_fn()
  â†’ Task.predict_step(batch)
  â†’ Task.postprocess_predictions() â†’ processed_preds
  â†’ è¿”å› {logits, indices, bin_file, bin_path, pkl_path, coord}
  â†’ SegmentationWriter.write_on_batch_end()
      â†’ æµå¼å†™å…¥ä¸´æ—¶æ–‡ä»¶
  â†’ SegmentationWriter.on_predict_end()
      â†’ æŠ•ç¥¨å¹¶ä¿å­˜ .las æ–‡ä»¶

# å¿…é¡»é…ç½®å›è°ƒï¼š
trainer.predict(model, datamodule, callbacks=[SegmentationWriter(...)])

# å…³é”®ç‰¹æ€§ï¼š
âœ… ä¸è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡ï¼ˆæ— çœŸå€¼æ ‡ç­¾ï¼‰
âœ… å¿…é¡»ä¿å­˜é¢„æµ‹ç»“æœ
âœ… æ”¯æŒ DynamicBatchSampler (use_dynamic_batch_inference=True)
âœ… æ”¯æŒ loop > 1 (TTA + æŠ•ç¥¨)
âœ… shuffle=False, drop_last=False
âœ… Dataset æä¾› indices å’Œæ–‡ä»¶ä¿¡æ¯
```

---

## ğŸ”§ å·²çŸ¥é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

### 1. DynamicBatchSampler + TTA
- âš ï¸ ç‚¹æ•°åŸºäº transform **ä¹‹å‰**çš„å€¼é¢„è®¡ç®—
- âœ… é€‚ç”¨äºï¼šå‡å°‘ç‚¹æ•°æˆ–ç•¥å¾®å¢åŠ ç‚¹æ•°çš„ transform
- âŒ ä¸é€‚ç”¨äºï¼šå¤§å¹…å¢åŠ ç‚¹æ•°çš„ transformï¼ˆå¦‚å¯†é›†é‡‡æ ·ï¼‰
- ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼štransform å¤§å¹…å¢åŠ ç‚¹æ•°æ—¶ï¼Œè®¾ç½® `use_dynamic_batch_inference=False`

### 2. Predict é˜¶æ®µæ— çœŸå€¼æ ‡ç­¾
- âœ… Dataset ä¸è¿”å› 'class' å­—æ®µ
- âœ… Task.predict_step ä¸è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
- âœ… åªè¿”å›é¢„æµ‹ç»“æœ

### 3. Test vs Predict
- **Test**: æœ‰æ ‡ç­¾ï¼Œè®¡ç®—æŒ‡æ ‡ + å¯é€‰ä¿å­˜ç»“æœ
- **Predict**: æ— æ ‡ç­¾ï¼Œåªä¿å­˜ç»“æœ

---

## ğŸ“ è®­ç»ƒå‰å‡†å¤‡

### å¿…éœ€æ­¥éª¤ï¼š

1. **åˆ›å»º main.py** - âš ï¸ å½“å‰ä¸ºç©º
   ```python
   # éœ€è¦å®ç° LightningCLI å…¥å£
   from pytorch_lightning.cli import LightningCLI
   
   class PointSuiteCLI(LightningCLI):
       def add_arguments_to_parser(self, parser):
           # æ·»åŠ è‡ªå®šä¹‰å‚æ•°
           pass
   
   if __name__ == "__main__":
       cli = PointSuiteCLI()
   ```

2. **åˆ›å»ºå®éªŒé…ç½®æ–‡ä»¶**
   - `configs/experiments/my_experiment.yaml`
   - å®šä¹‰ model, data, trainer, callbacks

3. **å‡†å¤‡æ•°æ®**
   - bin + pkl æ–‡ä»¶ï¼ˆé€šè¿‡ tile.py ç”Ÿæˆï¼‰
   - ç¡®ä¿ pkl åŒ…å« 'num_points' å’Œæ–‡ä»¶ä¿¡æ¯

### å¯é€‰æ­¥éª¤ï¼š

4. **ç±»åˆ«æ˜ å°„** (å¦‚æœç±»åˆ«ä¸è¿ç»­)
   ```python
   class_mapping = {0: 0, 1: 1, 2: 2, 6: 3, 9: 4}
   reverse_class_mapping = {0: 0, 1: 1, 2: 2, 3: 6, 4: 9}
   ```

5. **åŠ æƒé‡‡æ ·** (å¦‚æœç±»åˆ«ä¸å¹³è¡¡)
   ```python
   # è®¡ç®—æƒé‡
   weights = compute_weights(train_dataset)
   # å¦‚æœ train_loop > 1ï¼Œéœ€è¦é‡å¤æƒé‡
   weights = weights * train_loop
   ```

---

## âœ… ç»“è®º

**æ¡†æ¶æ ¸å¿ƒåŠŸèƒ½å·²å®Œæ•´å®ç°ï¼**

å”¯ä¸€ç¼ºå¤±çš„æ˜¯ `main.py` è®­ç»ƒå…¥å£ï¼Œä½†è¿™ä¸å½±å“ä½ æ‰‹åŠ¨ç¼–å†™è®­ç»ƒè„šæœ¬ï¼š

```python
import pytorch_lightning as pl
from pointsuite.data import BinPklDataModule
from pointsuite.tasks import SemanticSegmentationTask
from pointsuite.models.backbones import PointTransformerV2m5
from pointsuite.models.heads import SegmentationHead

# 1. åˆ›å»º DataModule
datamodule = BinPklDataModule(
    train_data='data/train',
    val_data='data/val',
    test_data='data/test',
    batch_size=8,
    num_workers=4,
    # ... å…¶ä»–å‚æ•°
)

# 2. åˆ›å»º Model
backbone = PointTransformerV2m5(...)
head = SegmentationHead(...)
model = SemanticSegmentationTask(
    backbone=backbone,
    head=head,
    learning_rate=0.001,
    loss_configs=[...],
    metric_configs=[...]
)

# 3. åˆ›å»º Trainer
trainer = pl.Trainer(
    max_epochs=100,
    accelerator='gpu',
    devices=1,
    callbacks=[...]
)

# 4. è®­ç»ƒ
trainer.fit(model, datamodule)

# 5. æµ‹è¯•
trainer.test(model, datamodule)

# 6. é¢„æµ‹
from pointsuite.utils.callbacks import SegmentationWriter
writer = SegmentationWriter(output_dir='predictions')
trainer.predict(model, datamodule, callbacks=[writer])
```

**ğŸ‰ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼**
