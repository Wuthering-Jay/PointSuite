"""
DDP (åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ) æ”¯æŒæ£€æŸ¥æ¸…å•

æ£€æŸ¥å½“å‰ä»£ç åº“ä¸­çš„ DDP å…¼å®¹æ€§
"""

# =============================================================================
# âœ… å·²ç»æ­£ç¡®æ”¯æŒ DDP çš„éƒ¨åˆ†
# =============================================================================

already_ddp_compatible = """
1. âœ… Metrics (pointsuite/utils/metrics.py)
   - æ‰€æœ‰æŒ‡æ ‡ç»§æ‰¿è‡ª torchmetrics.Metric
   - ä½¿ç”¨ add_state(..., dist_reduce_fx="sum") è‡ªåŠ¨èšåˆ
   - æ··æ·†çŸ©é˜µåœ¨ DDP è¿›ç¨‹é—´è‡ªåŠ¨åŒæ­¥
   - OverallAccuracy, MeanIoU, Precision, Recall, F1Score, SegmentationMetrics
   
   åŸç†ï¼š
   - torchmetrics ä¼šåœ¨ compute() å‰è‡ªåŠ¨è°ƒç”¨ all_gather
   - æ¯ä¸ª GPU çš„å±€éƒ¨æ··æ·†çŸ©é˜µä¼šè¢«æ±‚å’Œåˆ°ä¸»è¿›ç¨‹
   
2. âœ… Losses (pointsuite/models/losses/)
   - æ‰€æœ‰æŸå¤±å‡½æ•°éƒ½æ˜¯æ ‡å‡†çš„ nn.Module
   - ä¸åŒ…å«éœ€è¦åŒæ­¥çš„çŠ¶æ€
   - CrossEntropyLoss, FocalLoss, LovaszLoss, DiceLoss, DiceCELoss
   
3. âœ… BaseTask çš„ log_dict()
   - PyTorch Lightning è‡ªåŠ¨å¤„ç† DDP ä¸‹çš„ logging
   - ä½¿ç”¨ self.log_dict(..., batch_size=batch_size) 
   - PL ä¼šè‡ªåŠ¨ reduce æŸå¤±åˆ°ä¸»è¿›ç¨‹
   
4. âœ… validation_step / test_step
   - æŒ‡æ ‡çš„ update() åœ¨å„ GPU æœ¬åœ°æ‰§è¡Œ
   - on_validation_epoch_end / on_test_epoch_end ä¸­ compute() æ—¶è‡ªåŠ¨åŒæ­¥
   
5. âœ… Model çš„ forward()
   - PointNet++ ç­‰æ¨¡å‹éƒ½æ˜¯æ ‡å‡† nn.Module
   - DDP ä¼šè‡ªåŠ¨åŒ…è£…å¹¶åŒæ­¥æ¢¯åº¦
"""

# =============================================================================
# âš ï¸ éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼ˆå·²ç»æ˜¯æ­£ç¡®çš„ï¼Œä½†éœ€è¦ç†è§£ï¼‰
# =============================================================================

ddp_considerations = """
1. âš ï¸ _get_batch_size() ä¸­çš„ .item()
   
   å½“å‰ä»£ç ï¼š
   ```python
   def _get_batch_size(self, batch: Dict[str, Any]) -> int:
       if 'batch_index' in batch:
           return batch['batch_index'].max().item() + 1  # âš ï¸ .item()
       elif 'offset' in batch:
           return len(batch['offset'])
   ```
   
   é—®é¢˜ï¼š
   - .item() ä¼šè§¦å‘ GPU -> CPU åŒæ­¥
   - åœ¨ DDP ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹çš„ batch_size å¯èƒ½ä¸åŒï¼ˆæœ€åä¸€ä¸ª batchï¼‰
   
   å½“å‰çŠ¶æ€ï¼šâœ… å·²ç»æ­£ç¡®
   - è¿™æ˜¯å¿…è¦çš„åŒæ­¥ï¼Œå› ä¸ºéœ€è¦ä¼ é€’ç»™ self.log_dict(batch_size=...)
   - PyTorch Lightning ä¼šæ­£ç¡®å¤„ç†ä¸åŒè¿›ç¨‹é—´çš„ batch_size å·®å¼‚
   - åªåœ¨ logging æ—¶è°ƒç”¨ï¼Œå¯¹æ€§èƒ½å½±å“å¾ˆå°
   
2. âš ï¸ predict_step() ä¸­çš„ .cpu()
   
   å½“å‰ä»£ç ï¼š
   ```python
   def predict_step(self, batch, batch_idx):
       preds = self.forward(batch)
       results = {
           "preds": preds.cpu(),  # âš ï¸ .cpu()
           "logits": logits.cpu(),
       }
       return results
   ```
   
   DDP åœºæ™¯ï¼š
   - åœ¨æ¨ç†æ—¶ï¼Œæ¯ä¸ª GPU ä¼šå¤„ç†æ•°æ®çš„ä¸åŒéƒ¨åˆ†
   - predict_step çš„è¾“å‡ºä¼šè¢«æ”¶é›†åˆ°ä¸»è¿›ç¨‹
   - .cpu() æ˜¯å¿…è¦çš„ï¼Œé¿å… GPU å†…å­˜çˆ†ç‚¸
   
   å½“å‰çŠ¶æ€ï¼šâœ… å·²ç»æ­£ç¡®
   - PyTorch Lightning çš„ Trainer.predict() ä¼šè‡ªåŠ¨æ”¶é›†æ‰€æœ‰ GPU çš„ç»“æœ
   - ä½¿ç”¨ .cpu() å¯ä»¥é¿å…è·¨ GPU ä¼ è¾“å¤§é‡æ•°æ®
"""

# =============================================================================
# âœ… ä¸éœ€è¦ä¿®æ”¹çš„åœ°æ–¹
# =============================================================================

no_changes_needed = """
1. âœ… training_step è¿”å›å€¼
   
   å½“å‰ä»£ç ï¼š
   ```python
   def training_step(self, batch, batch_idx):
       loss_dict = self._calculate_total_loss(preds, batch)
       self.log_dict(loss_dict, ...)
       return loss_dict["total_loss"]  # âœ… æ­£ç¡®
   ```
   
   DDP å¤„ç†ï¼š
   - PyTorch Lightning ä¼šè‡ªåŠ¨å¯¹è¿”å›çš„ loss è°ƒç”¨ all_reduce
   - æ¢¯åº¦ä¼šåœ¨ backward() åè‡ªåŠ¨åŒæ­¥ï¼ˆDDP çš„æ ¸å¿ƒåŠŸèƒ½ï¼‰
   - ä¸éœ€è¦æ‰‹åŠ¨ synchronize
   
2. âœ… validation_step / test_step
   
   å½“å‰ä»£ç ï¼š
   ```python
   def validation_step(self, batch, batch_idx):
       preds = self.forward(batch)
       loss_dict = self._calculate_total_loss(preds, batch)
       self.log_dict(loss_dict, ...)
       for metric in self.val_metrics.values():
           metric.update(preds, batch)  # âœ… æœ¬åœ°æ›´æ–°
   
   def on_validation_epoch_end(self):
       for name, metric in self.val_metrics.items():
           metric_results[name] = metric.compute()  # âœ… è‡ªåŠ¨åŒæ­¥
           metric.reset()
   ```
   
   DDP å¤„ç†ï¼š
   - update() åœ¨å„ GPU æœ¬åœ°æ‰§è¡Œï¼Œä¸éœ€è¦åŒæ­¥
   - compute() æ—¶ torchmetrics è‡ªåŠ¨è°ƒç”¨ all_gather åŒæ­¥çŠ¶æ€
   - reset() åœ¨å„ GPU æœ¬åœ°æ‰§è¡Œ
   
3. âœ… æŸå¤±å‡½æ•°è®¡ç®—
   
   å½“å‰ä»£ç ï¼š
   ```python
   def _calculate_total_loss(self, preds, batch):
       total_loss = torch.tensor(0.0, device=self.device, dtype=torch.float32)
       for name, loss_fn in self.losses.items():
           loss = loss_fn(preds, batch)
           total_loss += self.loss_weights[name] * loss
       return {"total_loss": total_loss}
   ```
   
   DDP å¤„ç†ï¼š
   - æŸå¤±åœ¨å„ GPU æœ¬åœ°è®¡ç®—
   - backward() æ—¶æ¢¯åº¦è‡ªåŠ¨åŒæ­¥
   - ä¸éœ€è¦æ‰‹åŠ¨åŒæ­¥æŸå¤±å€¼ï¼ˆåªç”¨äºæ˜¾ç¤ºï¼‰
"""

# =============================================================================
# ğŸ“‹ DDP ä½¿ç”¨æ£€æŸ¥æ¸…å•
# =============================================================================

ddp_checklist = """
ä½¿ç”¨ DDP è®­ç»ƒæ—¶éœ€è¦æ³¨æ„çš„é…ç½®ï¼š

1. âœ… Trainer é…ç½®
   ```yaml
   trainer:
     accelerator: gpu
     devices: 4              # ä½¿ç”¨ 4 ä¸ª GPU
     strategy: ddp           # æˆ– ddp_spawn, ddp_find_unused_parameters_false
     sync_batchnorm: true    # å¦‚æœæ¨¡å‹ä½¿ç”¨ BatchNormï¼Œå»ºè®®å¼€å¯
   ```

2. âœ… DataLoader é…ç½®
   - ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½® DistributedSampler
   - PyTorch Lightning ä¼šè‡ªåŠ¨å¤„ç†
   - æ¯ä¸ª GPU ä¼šè·å¾— batch_size / num_gpus çš„æ•°æ®
   
   ```yaml
   data:
     batch_size: 16  # æ¯ä¸ª GPU çš„ batch_size
     num_workers: 4  # æ¯ä¸ª GPU çš„ worker æ•°
   ```

3. âœ… Metrics é…ç½®
   - ä½¿ç”¨ torchmetricsï¼ˆå·²å®Œæˆï¼‰
   - æˆ–ä½¿ç”¨æˆ‘ä»¬çš„ SegmentationMetricsï¼ˆç»§æ‰¿è‡ª torchmetricsï¼‰
   
   ```yaml
   metrics:
     all:
       class_path: pointsuite.utils.metrics.SegmentationMetrics
       init_args:
         num_classes: 8
         ignore_index: -1
   ```

4. âœ… Logging
   - self.log(..., sync_dist=True) ä¼šåœ¨æ‰€æœ‰è¿›ç¨‹é—´åŒæ­¥
   - é»˜è®¤æƒ…å†µä¸‹ï¼Œvalidation çš„ log ä¼šè‡ªåŠ¨ sync_dist=True
   - training çš„ log é»˜è®¤ sync_dist=Falseï¼ˆæ€§èƒ½è€ƒè™‘ï¼‰
   
   å¦‚æœéœ€è¦ç²¾ç¡®çš„ training metricsï¼š
   ```python
   self.log_dict(metrics, sync_dist=True)  # å¼ºåˆ¶åŒæ­¥
   ```

5. âœ… å¯åŠ¨å‘½ä»¤
   
   æ–¹æ³• 1: torchrun (æ¨è)
   ```bash
   torchrun --nproc_per_node=4 train.py fit --config config.yaml
   ```
   
   æ–¹æ³• 2: python -m torch.distributed.launch
   ```bash
   python -m torch.distributed.launch --nproc_per_node=4 train.py fit --config config.yaml
   ```
   
   æ–¹æ³• 3: SLURM (é›†ç¾¤)
   ```bash
   srun --nodes=2 --ntasks-per-node=4 --gres=gpu:4 python train.py fit --config config.yaml
   ```
"""

# =============================================================================
# ğŸš€ æ€§èƒ½ä¼˜åŒ–å»ºè®®
# =============================================================================

performance_tips = """
DDP æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š

1. ä½¿ç”¨ SegmentationMetrics è€Œä¸æ˜¯å¤šä¸ªç‹¬ç«‹æŒ‡æ ‡
   âŒ å·®ï¼š
   ```yaml
   metrics:
     oa: {...}
     miou: {...}
     precision: {...}
     recall: {...}
     f1: {...}
   ```
   æ¯ä¸ªæŒ‡æ ‡éƒ½ä¼šè§¦å‘ä¸€æ¬¡ all_gatherï¼ˆ5æ¬¡åŒæ­¥ï¼‰
   
   âœ… å¥½ï¼š
   ```yaml
   metrics:
     all:
       class_path: pointsuite.utils.metrics.SegmentationMetrics
   ```
   åªè§¦å‘ä¸€æ¬¡ all_gather

2. é€‚å½“çš„ log é¢‘ç‡
   ```yaml
   trainer:
     log_every_n_steps: 50  # ä¸è¦å¤ªé¢‘ç¹
   ```

3. ä½¿ç”¨åˆé€‚çš„ sync_batchnorm
   - å° batch_size æ—¶ï¼šsync_batchnorm=True
   - å¤§ batch_size æ—¶ï¼šsync_batchnorm=Falseï¼ˆæ€§èƒ½æ›´å¥½ï¼‰

4. æ‰¾åˆ°æœ€ä½³çš„ num_workers
   - é€šå¸¸è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•° / GPU æ•°
   - ä¾‹å¦‚ï¼š64 æ ¸ CPUï¼Œ4 GPU -> num_workers=16

5. ä½¿ç”¨ gradient_clip_val
   ```yaml
   trainer:
     gradient_clip_val: 1.0  # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
   ```

6. è€ƒè™‘ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   ```yaml
   trainer:
     precision: 16  # æˆ– 'bf16'
   ```
"""

# =============================================================================
# ğŸ› å¸¸è§ DDP é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
# =============================================================================

common_issues = """
å¸¸è§ DDP é—®é¢˜ï¼š

1. âŒ é—®é¢˜ï¼šè¿›ç¨‹å¡ä½ä¸åŠ¨
   åŸå› ï¼šä¸åŒè¿›ç¨‹æ‰§è¡Œäº†ä¸åŒæ•°é‡çš„ collective æ“ä½œ
   è§£å†³ï¼šç¡®ä¿æ‰€æœ‰è¿›ç¨‹æ‰§è¡Œç›¸åŒçš„ä»£ç è·¯å¾„
   
   ä¾‹å¦‚ï¼Œé¿å…ï¼š
   ```python
   if self.global_rank == 0:
       metric.compute()  # âŒ åªæœ‰ä¸»è¿›ç¨‹æ‰§è¡Œ
   ```
   
   åº”è¯¥ï¼š
   ```python
   result = metric.compute()  # âœ… æ‰€æœ‰è¿›ç¨‹éƒ½æ‰§è¡Œ
   if self.global_rank == 0:
       print(result)  # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
   ```

2. âŒ é—®é¢˜ï¼šæŒ‡æ ‡ä¸å‡†ç¡®
   åŸå› ï¼šå¿˜è®°åœ¨ epoch ç»“æŸæ—¶ reset()
   è§£å†³ï¼šå·²åœ¨ on_validation_epoch_end ä¸­æ­£ç¡®å®ç°
   
   ```python
   def on_validation_epoch_end(self):
       for metric in self.val_metrics.values():
           result = metric.compute()
           metric.reset()  # âœ… å¿…é¡» reset
   ```

3. âŒ é—®é¢˜ï¼šOOM (Out of Memory)
   åŸå› ï¼šæ‰€æœ‰ GPU éƒ½å­˜å‚¨å®Œæ•´çš„ validation ç»“æœ
   è§£å†³ï¼šåœ¨ predict_step ä¸­ä½¿ç”¨ .cpu()ï¼ˆå·²å®ç°ï¼‰
   
4. âŒ é—®é¢˜ï¼šbatch_size ç›¸å…³çš„é”™è¯¯
   åŸå› ï¼šæœ€åä¸€ä¸ª batch å¯èƒ½ä¸å®Œæ•´
   è§£å†³ï¼šä½¿ç”¨ drop_last=False å’Œæ­£ç¡®çš„ batch_size loggingï¼ˆå·²å®ç°ï¼‰

5. âŒ é—®é¢˜ï¼šloss æ˜¯ NaN
   å¯èƒ½åŸå› ï¼š
   - å­¦ä¹ ç‡å¤ªå¤§
   - æ¢¯åº¦çˆ†ç‚¸ï¼ˆä½¿ç”¨ gradient_clip_valï¼‰
   - æ•°æ®å½’ä¸€åŒ–é—®é¢˜
   - æŸäº› GPU çš„æ•°æ®æœ‰é—®é¢˜
   
   è°ƒè¯•ï¼š
   ```yaml
   trainer:
     detect_anomaly: true  # æ£€æµ‹ NaN
     track_grad_norm: 2    # è¿½è¸ªæ¢¯åº¦èŒƒæ•°
   ```
"""

# =============================================================================
# æ€»ç»“
# =============================================================================

summary = """
âœ… æ€»ç»“ï¼šå½“å‰ä»£ç å·²ç»å®Œå…¨æ”¯æŒ DDP

éœ€è¦åšçš„äº‹æƒ…ï¼š
1. âœ… Metrics ä½¿ç”¨ torchmetricsï¼ˆå·²å®Œæˆï¼‰
2. âœ… ä½¿ç”¨ SegmentationMetrics å‡å°‘åŒæ­¥æ¬¡æ•°ï¼ˆå·²å®ç°ï¼‰
3. âœ… æ­£ç¡®çš„ batch_size loggingï¼ˆå·²å®ç°ï¼‰
4. âœ… åœ¨ predict_step ä½¿ç”¨ .cpu()ï¼ˆå·²å®ç°ï¼‰
5. âœ… åœ¨ epoch ç»“æŸæ—¶ reset metricsï¼ˆå·²å®ç°ï¼‰

ä¸éœ€è¦ä¿®æ”¹çš„ä»£ç ï¼š
- âœ… training_stepï¼ˆè‡ªåŠ¨åŒæ­¥æ¢¯åº¦ï¼‰
- âœ… validation_stepï¼ˆæŒ‡æ ‡è‡ªåŠ¨åŒæ­¥ï¼‰
- âœ… _calculate_total_lossï¼ˆæœ¬åœ°è®¡ç®—ï¼‰
- âœ… forward()ï¼ˆDDP è‡ªåŠ¨åŒ…è£…ï¼‰

ä½¿ç”¨ DDP çš„å‘½ä»¤ï¼š
```bash
# å•æœºå¤šå¡
torchrun --nproc_per_node=4 train.py fit --config config.yaml

# é…ç½®æ–‡ä»¶
trainer:
  accelerator: gpu
  devices: 4
  strategy: ddp
  sync_batchnorm: true  # å¦‚æœä½¿ç”¨ BatchNorm
```

æ€§èƒ½æå‡ï¼š
- ä½¿ç”¨ SegmentationMetricsï¼šåŒæ­¥æ¬¡æ•°ä» 5 æ¬¡å‡å°‘åˆ° 1 æ¬¡
- 4 GPU ç†è®ºåŠ é€Ÿï¼šæ¥è¿‘ 4xï¼ˆå–å†³äºé€šä¿¡å¼€é”€ï¼‰
- å®é™…åŠ é€Ÿï¼šé€šå¸¸ 3-3.5x
"""

if __name__ == "__main__":
    print("=" * 80)
    print("âœ… å·²ç»æ­£ç¡®æ”¯æŒ DDP çš„éƒ¨åˆ†")
    print("=" * 80)
    print(already_ddp_compatible)
    
    print("\n" + "=" * 80)
    print("âš ï¸ éœ€è¦æ³¨æ„çš„åœ°æ–¹")
    print("=" * 80)
    print(ddp_considerations)
    
    print("\n" + "=" * 80)
    print("âœ… ä¸éœ€è¦ä¿®æ”¹çš„åœ°æ–¹")
    print("=" * 80)
    print(no_changes_needed)
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ DDP ä½¿ç”¨æ£€æŸ¥æ¸…å•")
    print("=" * 80)
    print(ddp_checklist)
    
    print("\n" + "=" * 80)
    print("ğŸš€ æ€§èƒ½ä¼˜åŒ–å»ºè®®")
    print("=" * 80)
    print(performance_tips)
    
    print("\n" + "=" * 80)
    print("ğŸ› å¸¸è§ DDP é—®é¢˜")
    print("=" * 80)
    print(common_issues)
    
    print("\n" + "=" * 80)
    print("âœ… æ€»ç»“")
    print("=" * 80)
    print(summary)
