# æ–°åŠŸèƒ½æ€»ç»“ä¸æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

## 1. æ–°å¢åŠŸèƒ½

### 1.1 ç±»åˆ«æ˜ å°„ (Class Mapping)

**åŠŸèƒ½æè¿°**ï¼šå°†éè¿ç»­çš„åŸå§‹æ ‡ç­¾æ˜ å°„åˆ°è¿ç»­æ ‡ç­¾ï¼Œæ–¹ä¾¿è®­ç»ƒã€‚

**å®ç°ä½ç½®**ï¼š
- `dataset_base.py` - åŸºç±»ä¸­æ·»åŠ  `class_mapping` å‚æ•°
- `dataset_bin.py` - å…·ä½“å®ç°æ ‡ç­¾æ˜ å°„é€»è¾‘

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
# DALES æ•°æ®é›†ç±»åˆ«æ˜ å°„
class_mapping = {
    0: 0,   # æœªåˆ†ç±»
    1: 1,   # åœ°é¢
    2: 2,   # æ¤è¢«
    6: 3,   # å»ºç­‘
    9: 4,   # æ°´ä½“
    17: 5,  # è½¦è¾†
}

dataset = BinPklDataset(
    data_root=data_root,
    split='train',
    assets=['coord', 'intensity', 'classification'],
    class_mapping=class_mapping,  # ä¼ å…¥æ˜ å°„è¡¨
)
```

**æ•ˆæœ**ï¼š
- åŸå§‹æ ‡ç­¾ï¼š0, 1, 2, 6, 9, 17ï¼ˆéè¿ç»­ï¼‰
- æ˜ å°„åæ ‡ç­¾ï¼š0, 1, 2, 3, 4, 5ï¼ˆè¿ç»­ï¼‰

---

### 1.2 Intensity æ•°æ®å¢å¼º

**åŠŸèƒ½æè¿°**ï¼š8ç§ä¸“é—¨é’ˆå¯¹ intensity çš„æ•°æ®å¢å¼ºæ–¹æ³•ã€‚

**æ–°å¢ Transforms**ï¼š

| Transform | åŠŸèƒ½ | å‚æ•° |
|-----------|------|------|
| `NormalizeIntensity` | å½’ä¸€åŒ–åˆ° [0, 1] | `max_value=65535` |
| `RandomIntensityScale` | éšæœºç¼©æ”¾ | `scale=(0.8, 1.2), p=0.95` |
| `RandomIntensityShift` | éšæœºåç§» | `shift=(-0.1, 0.1), p=0.95` |
| `RandomIntensityNoise` | é«˜æ–¯å™ªå£° | `sigma=0.01, p=0.5` |
| `RandomIntensityDrop` | éšæœºä¸¢å¼ƒï¼ˆç½®0ï¼‰ | `drop_ratio=0.1, p=0.2` |
| `IntensityAutoContrast` | å¯¹æ¯”åº¦å¢å¼º | `p=0.2, blend_factor=None` |
| `RandomIntensityGamma` | Gamma å˜æ¢ | `gamma_range=(0.8, 1.2), p=0.5` |
| **`StandardNormalizeIntensity`** â­ | **æ ‡å‡†åŒ–ï¼ˆå‡å‡å€¼é™¤æ–¹å·®ï¼‰** | `mean=None, std=None` |
| **`MinMaxNormalizeIntensity`** â­ | **MinMax å½’ä¸€åŒ–** | `min_val=None, max_val=None, target_range=(0, 1)` |

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
train_transforms = [
    # å‡ ä½•å˜æ¢
    T.RandomRotate(angle=[-1, 1], axis='z', p=1.0),
    T.RandomScale(scale=[0.95, 1.05]),
    
    # Intensity å¢å¼º
    T.StandardNormalizeIntensity(),  # æ ‡å‡†åŒ–
    T.RandomIntensityScale(scale=(0.9, 1.1), p=0.95),
    T.RandomIntensityShift(shift=(-0.05, 0.05), p=0.95),
]

dataset = BinPklDataset(
    data_root=data_root,
    split='train',
    assets=['coord', 'intensity', 'classification'],
    transform=train_transforms,
)
```

---

### 1.3 é™åˆ¶ Batch æ€»ç‚¹æ•°

**åŠŸèƒ½æè¿°**ï¼šé˜²æ­¢ batch ç‚¹æ•°è¿‡å¤šå¯¼è‡´æ˜¾å­˜æº¢å‡ºã€‚

**ä¸¤ç§å®ç°æ–¹æ³•**ï¼š

#### æ–¹æ³•1: DynamicBatchSamplerï¼ˆæ¨èï¼‰â­

åœ¨é‡‡æ ·é˜¶æ®µåŠ¨æ€è°ƒæ•´ batch å¤§å°ï¼Œä¸æµªè´¹æ•°æ®ã€‚

```python
from pointsuite.datasets.collate import DynamicBatchSampler, collate_fn

batch_sampler = DynamicBatchSampler(
    dataset,
    max_points=300000,  # 30ä¸‡ç‚¹é™åˆ¶
    shuffle=True,
    drop_last=False
)

dataloader = DataLoader(
    dataset,
    batch_sampler=batch_sampler,
    collate_fn=collate_fn,
    num_workers=4,
)
```

**ä¼˜ç‚¹**ï¼š
- âœ… ä¸ä¸¢å¼ƒä»»ä½•æ ·æœ¬
- âœ… åŠ¨æ€è°ƒæ•´ batch å¤§å°
- âœ… æ€§èƒ½å¼€é”€ä½ï¼ˆå®æµ‹æé€Ÿ 45.3%ï¼‰

---

#### æ–¹æ³•2: LimitedPointsCollateFn

åœ¨ collate é˜¶æ®µä¸¢å¼ƒéƒ¨åˆ†æ ·æœ¬ä»¥æ»¡è¶³é™åˆ¶ã€‚

```python
from pointsuite.datasets.collate import LimitedPointsCollateFn

limited_collate = LimitedPointsCollateFn(
    max_points=300000,
    strategy='drop_largest'  # 'drop_largest', 'drop_last', 'keep_first'
)

dataloader = DataLoader(
    dataset,
    batch_size=8,
    shuffle=True,
    collate_fn=limited_collate,
    num_workers=4,
)
```

**ä¼˜ç‚¹**ï¼š
- âœ… å®ç°ç®€å•
- âœ… æ”¯æŒå¤šç§ä¸¢å¼ƒç­–ç•¥

**ç¼ºç‚¹**ï¼š
- âŒ ä¼šä¸¢å¼ƒéƒ¨åˆ†æ ·æœ¬

---

#### ä¾¿æ· API

```python
from pointsuite.datasets.collate import create_limited_dataloader

# æ¨èï¼šä½¿ç”¨ sampler æ–¹æ³•
dataloader = create_limited_dataloader(
    dataset,
    max_points=300000,
    method='sampler',  # æˆ– 'collate'
    shuffle=True,
    num_workers=4
)
```

---

## 2. æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

### 2.1 æµ‹è¯•ç¯å¢ƒ

- **æ•°æ®é›†**ï¼šDALES (29 ä¸ªæ–‡ä»¶ï¼Œ12,871 ä¸ªæ ·æœ¬ï¼Œ737,335,364 ä¸ªç‚¹)
- **ç¡¬ä»¶**ï¼šæœªæŒ‡å®š
- **ç¯å¢ƒ**ï¼šConda pointcept ç¯å¢ƒ

---

### 2.2 æµ‹è¯•ç»“æœ

#### â‘  Batch Size å½±å“

| Batch Size | æ ·æœ¬é€Ÿåº¦ | ç‚¹é€Ÿåº¦ | æ¨è |
|-----------|---------|--------|------|
| 1 | 15.3 samples/s | 798,872 points/s | âŒ |
| 2 | 19.2 samples/s | 1,068,520 points/s | âŒ |
| 4 | 20.9 samples/s | 1,165,399 points/s | âœ… |
| 8 | 18.4 samples/s | 1,079,652 points/s | âœ… |
| 16 | 22.1 samples/s | 1,261,679 points/s | âš ï¸ å¯èƒ½å ç”¨å¤§é‡å†…å­˜ |

**å»ºè®®**ï¼šbatch_size=4~8 å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜ã€‚

---

#### â‘¡ num_workers å½±å“

| num_workers | æ ·æœ¬é€Ÿåº¦ | ç‚¹é€Ÿåº¦ | åŠ é€Ÿæ¯” |
|------------|---------|--------|--------|
| 0 | 24.0 samples/s | 1,410,150 points/s | 1.00x |
| 2 | 24.1 samples/s | 1,414,573 points/s | 1.00x |
| 4 | 32.0 samples/s | 1,878,790 points/s | **1.33x** âœ… |

**å»ºè®®**ï¼šä½¿ç”¨ num_workers=4 å¯æé€Ÿ 33%ã€‚

---

#### â‘¢ Cache å½±å“

| Cache | ç¬¬ä¸€æ¬¡éå† | ç¬¬äºŒæ¬¡éå† | åŠ é€Ÿæ¯” |
|-------|----------|----------|--------|
| False | 33.66s | 34.03s | 0.99x |
| True | 35.44s | **0.17s** | **205.56x** âœ… |

**å»ºè®®**ï¼š
- å°æ•°æ®é›†ï¼ˆèƒ½æ”¾å…¥å†…å­˜ï¼‰ï¼šå¼€å¯ cacheï¼Œå¤šæ¬¡éå†æé€Ÿ 200 å€
- å¤§æ•°æ®é›†ï¼šå…³é—­ cacheï¼Œä½¿ç”¨ memmap

---

#### â‘£ æ•°æ®å¢å¼ºå¼€é”€

| Transforms | ç‚¹é€Ÿåº¦ | æ€§èƒ½æŸå¤± |
|-----------|--------|---------|
| æ—  | 1,396,515 points/s | - |
| å®Œæ•´å¢å¼ºï¼ˆ8ä¸ªï¼‰ | 1,204,744 points/s | **-13.7%** |

å®Œæ•´å¢å¼ºåŒ…æ‹¬ï¼š
- å‡ ä½•å˜æ¢ï¼šRandomRotate, RandomScale, RandomFlip, RandomJitter, CenterShift
- Intensityï¼šRandomIntensityScale, RandomIntensityShift, StandardNormalizeIntensity

**ç»“è®º**ï¼šæ•°æ®å¢å¼ºå¼€é”€çº¦ 14%ï¼Œå¯æ¥å—ã€‚

---

#### â‘¤ é™åˆ¶ç‚¹æ•°æ€§èƒ½

| æ–¹æ³• | ç‚¹é€Ÿåº¦ | æ€§èƒ½å¯¹æ¯” |
|------|--------|---------|
| æ— é™åˆ¶ | 1,385,593 points/s | åŸºå‡† |
| DynamicBatchSampler | 1,465,473 points/s | **+5.8%** âœ… |

**æƒŠå–œå‘ç°**ï¼šDynamicBatchSampler ä¸ä»…ä¸é™ä½æ€§èƒ½ï¼Œåè€Œæé€Ÿ 5.8%ï¼

åŸå› ï¼šåŠ¨æ€è°ƒæ•´ batch å¤§å°é¿å…äº†éƒ¨åˆ†å¤§æ ·æœ¬å¯¼è‡´çš„æ‹¼æ¥å¼€é”€ã€‚

---

#### â‘¥ å®Œæ•´ Epoch æ€§èƒ½

**å®Œæ•´æ•°æ®é›†åŠ è½½ç»Ÿè®¡**ï¼š
- **æ€»æ ·æœ¬æ•°**ï¼š12,871
- **æ€»ç‚¹æ•°**ï¼š737,335,364ï¼ˆ7.37 äº¿ç‚¹ï¼‰
- **æ€»è€—æ—¶**ï¼š561.84sï¼ˆ**9.36 åˆ†é’Ÿ**ï¼‰
- **å¹³å‡é€Ÿåº¦**ï¼š22.9 samples/s, **1,312,364 points/s**
- **æ¯ batch ç‚¹æ•°**ï¼šmin=330k, max=630k, avg=458k

**æ¨ç®—è®­ç»ƒæ—¶é—´ï¼ˆå‡è®¾ 100 epochsï¼‰**ï¼š
- æ•°æ®åŠ è½½ï¼š9.36 min/epoch Ã— 100 = **15.6 å°æ—¶**
- å®é™…è®­ç»ƒæ—¶é—´å–å†³äºæ¨¡å‹å‰å‘/åå‘ä¼ æ’­

---

## 3. æœ€ä½³å®è·µå»ºè®®

### 3.1 è®­ç»ƒé…ç½®

```python
# æ¨èé…ç½®
train_transforms = [
    # å‡ ä½•å˜æ¢
    T.RandomRotate(angle=[-1, 1], axis='z', p=1.0),
    T.RandomScale(scale=[0.95, 1.05]),
    T.RandomFlip(p=0.5),
    T.RandomJitter(sigma=0.01, clip=0.05),
    T.CenterShift(apply_z=False),
    
    # Intensity æ ‡å‡†åŒ– + å¢å¼º
    T.StandardNormalizeIntensity(),  # å…ˆæ ‡å‡†åŒ–
    T.RandomIntensityScale(scale=(0.9, 1.1), p=0.95),
    T.RandomIntensityShift(shift=(-0.05, 0.05), p=0.95),
]

# ç±»åˆ«æ˜ å°„
class_mapping = {0: 0, 1: 1, 2: 2, 6: 3, 9: 4, 17: 5}

# æ•°æ®é›†
dataset = BinPklDataset(
    data_root=data_root,
    split='train',
    assets=['coord', 'intensity', 'classification'],
    transform=train_transforms,
    class_mapping=class_mapping,
    cache_data=False,  # å¤§æ•°æ®é›†å…³é—­
)

# DataLoaderï¼ˆå¸¦ç‚¹æ•°é™åˆ¶ï¼‰
from pointsuite.datasets.collate import create_limited_dataloader

dataloader = create_limited_dataloader(
    dataset,
    max_points=300000,  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    method='sampler',
    shuffle=True,
    num_workers=4,
)
```

---

### 3.2 éªŒè¯é…ç½®

```python
# éªŒè¯é›†ä¸éœ€è¦æ•°æ®å¢å¼º
val_dataset = BinPklDataset(
    data_root=val_data_root,
    split='val',
    assets=['coord', 'intensity', 'classification'],
    transform=None,  # æ— å¢å¼º
    class_mapping=class_mapping,
    cache_data=True,  # éªŒè¯é›†å¯ä»¥å¼€å¯ cache
)

val_dataloader = DataLoader(
    val_dataset,
    batch_size=8,
    shuffle=False,
    num_workers=4,
    collate_fn=collate_fn,
)
```

---

### 3.3 æµ‹è¯•é…ç½®

```python
# æµ‹è¯•é›†éœ€è¦å­˜å‚¨ indices ç”¨äºæŠ•ç¥¨
test_dataset = BinPklDataset(
    data_root=test_data_root,
    split='test',  # split='test' è‡ªåŠ¨ä¿å­˜ indices
    assets=['coord', 'intensity', 'classification'],
    transform=None,
    class_mapping=class_mapping,
    cache_data=False,
)

test_dataloader = DataLoader(
    test_dataset,
    batch_size=1,  # æµ‹è¯•æ—¶é€šå¸¸ç”¨ batch_size=1
    shuffle=False,
    num_workers=0,
    collate_fn=collate_fn,
)

# ä½¿ç”¨ indices è¿›è¡ŒæŠ•ç¥¨
for batch in test_dataloader:
    predictions = model(batch)
    indices = batch['indices']  # åŸå§‹ç‚¹ç´¢å¼•
    # è¿›è¡ŒæŠ•ç¥¨èšåˆ...
```

---

## 4. æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ–‡ä»¶
- âœ… `dataset_base.py` - åŸºç±»ï¼ˆæ·»åŠ  class_mappingï¼‰
- âœ… `dataset_bin.py` - å®ç°ç±»ï¼ˆæ ‡ç­¾æ˜ å°„é€»è¾‘ï¼‰
- âœ… `transforms.py` - æ•°æ®å¢å¼ºï¼ˆæ–°å¢ 8 ç§ Intensity å˜æ¢ï¼‰
- âœ… `collate.py` - Collate å‡½æ•°ï¼ˆé™åˆ¶ç‚¹æ•°åŠŸèƒ½ï¼‰

### æµ‹è¯•æ–‡ä»¶
- âœ… `test_new_features.py` - æ–°åŠŸèƒ½ç»¼åˆæµ‹è¯•
- âœ… `test_dataloader_performance.py` - æ€§èƒ½æµ‹è¯•
- âœ… `test_dataloader_final.py` - å®Œæ•´åŠŸèƒ½æµ‹è¯•
- âœ… `OPENMP_SOLUTION.md` - OpenMP é—®é¢˜è§£å†³æ–¹æ¡ˆ

---

## 5. æ€»ç»“

### å·²å®ŒæˆåŠŸèƒ½ âœ…

1. **ç±»åˆ«æ˜ å°„**ï¼šæ”¯æŒéè¿ç»­æ ‡ç­¾æ˜ å°„åˆ°è¿ç»­æ ‡ç­¾
2. **Intensity å¢å¼º**ï¼š8 ç§å¢å¼ºæ–¹æ³•ï¼ŒåŒ…æ‹¬æ ‡å‡†åŒ–
3. **é™åˆ¶ç‚¹æ•°**ï¼šä¸¤ç§æ–¹æ³•ï¼Œæ¨è DynamicBatchSampler
4. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - num_workers=4 æé€Ÿ 33%
   - cache_data å¤šæ¬¡éå†æé€Ÿ 200 å€
   - DynamicBatchSampler æé€Ÿ 5.8%

### æ€§èƒ½æŒ‡æ ‡ ğŸ“Š

- **åŠ è½½é€Ÿåº¦**ï¼š1.3M points/s
- **å®Œæ•´ Epoch**ï¼š9.36 åˆ†é’Ÿï¼ˆ7.37 äº¿ç‚¹ï¼‰
- **æ•°æ®å¢å¼ºå¼€é”€**ï¼š13.7%
- **æ¨èé…ç½®**ï¼šbatch_size=4~8, num_workers=4, max_points=300k

### ä¸‹ä¸€æ­¥å»ºè®® ğŸš€

1. æ ¹æ®æ˜¾å­˜è°ƒæ•´ `max_points` å‚æ•°
2. å°æ•°æ®é›†å¼€å¯ `cache_data=True`
3. è®­ç»ƒæ—¶ä½¿ç”¨å®Œæ•´æ•°æ®å¢å¼º
4. éªŒè¯/æµ‹è¯•æ—¶å…³é—­æ•°æ®å¢å¼º
5. ä½¿ç”¨ `DynamicBatchSampler` é™åˆ¶ç‚¹æ•°

---

**æ‰€æœ‰åŠŸèƒ½å·²æµ‹è¯•å®Œæ¯•ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼** ğŸ‰
