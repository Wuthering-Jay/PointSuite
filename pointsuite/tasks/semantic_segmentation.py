import torch
import torch.nn as nn
from typing import Dict, Any

from .base_task import BaseTask

class SemanticSegmentationTask(BaseTask):
    """
    è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ (LightningModule)ã€‚

    å®ƒç»§æ‰¿è‡ª BaseTaskï¼Œå¹¶æ·»åŠ äº†ç‰¹å®šäºè¯­ä¹‰åˆ†å‰²çš„ç»„ä»¶ï¼š
    1. ä¸€ä¸ª `head` (åˆ†å‰²å¤´)ã€‚
    2. ä¿®æ”¹äº† `forward` é€»è¾‘ï¼Œä»¥è¿æ¥ backbone å’Œ headã€‚
    3. ä¿®æ”¹äº† `predict_step` ä»¥è¾“å‡ºæœ€ç»ˆçš„ argmax é¢„æµ‹ã€‚
    """
    
    def __init__(self,
                 backbone: nn.Module,
                 head: nn.Module,
                 **kwargs): # æ¥æ”¶æ¥è‡ª BaseTask çš„æ‰€æœ‰å‚æ•° (learning_rate, loss_configs, etc.)
        """
        Args:
            backbone (nn.Module): å·²ç»å®ä¾‹åŒ–çš„éª¨å¹²ç½‘ç»œ (ä¾‹å¦‚ PT-v2m5)ã€‚
            head (nn.Module): å·²ç»å®ä¾‹åŒ–çš„åˆ†å‰²å¤´ (ä¾‹å¦‚ SegmentationHead)ã€‚
            **kwargs: ä¼ é€’ç»™ BaseTask çš„å‚æ•°ã€‚
        """
        super().__init__(**kwargs)
        
        # å°† backbone å’Œ head ä¿å­˜ä¸ºå­æ¨¡å—
        # (æ³¨æ„: BaseTask å¹¶ä¸å‡å®šä¸€å®šæœ‰ backboneï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œä¿å­˜)
        self.backbone = backbone
        self.head = head

    def forward(self, batch: Dict[str, Any]) -> torch.Tensor:
        """
        å®šä¹‰æ¨¡å‹çš„å•æ¬¡å‰å‘ä¼ æ’­ã€‚
        
        Args:
            batch (Dict): æ¥è‡ª DataLoader çš„æ‰¹æ¬¡æ•°æ® (ç”± collate_fn äº§ç”Ÿ)ã€‚
                          æˆ‘ä»¬çš„ collate_fn æä¾›:
                          - 'coord': [N, 3] ç‚¹åæ ‡
                          - 'feat': [N, C] ç‚¹ç‰¹å¾
                          - 'class': [N] ç‚¹æ ‡ç­¾
                          - 'offset': [B] ç´¯ç§¯åç§»é‡
        
        Returns:
            torch.Tensor: æ¨¡å‹çš„åŸå§‹ Logits è¾“å‡º (shape: [N_total_points, num_classes])ã€‚
        """
        # 1. Backbone æå–ç‰¹å¾
        # ä¸åŒ backbone å¯èƒ½æœ‰ä¸åŒçš„è¾“å…¥æ ¼å¼ï¼š
        # - ç®€å•æ¨¡å‹ï¼šç›´æ¥æ¥æ”¶ batch['feat']
        # - PointNet++ï¼šéœ€è¦æ•´ä¸ª batch å­—å…¸
        
        if hasattr(self.backbone, 'forward') and 'batch' in self.backbone.forward.__code__.co_varnames:
            # Backbone æ¥æ”¶æ•´ä¸ª batch å­—å…¸
            backbone_output = self.backbone(batch)
        else:
            # Backbone åªæ¥æ”¶ç‰¹å¾å¼ é‡ï¼ˆå¦‚ç®€å• MLPï¼‰
            backbone_output = self.backbone(batch.get('feat', batch.get('coord')))
        
        # 2. å¤„ç† backbone è¾“å‡º
        # å¦‚æœè¾“å‡ºæ˜¯å­—å…¸ï¼ˆå¦‚ PointNet++ è¿”å› {'feat': ..., 'sa_xyz': ...}ï¼‰
        if isinstance(backbone_output, dict):
            features = backbone_output['feat']  # æå–ç‰¹å¾
        else:
            features = backbone_output
        
        # 3. Head ç”Ÿæˆ logits
        logits = self.head(features)
        return logits

    def training_step(self, batch: Dict[str, Any], batch_idx: int) -> torch.Tensor:
        """
        æ‰§è¡Œå•ä¸ªè®­ç»ƒæ­¥éª¤ã€‚
        """
        # 1. å‰å‘ä¼ æ’­
        preds_logits = self.forward(batch)
        
        # 2. è®¡ç®—æŸå¤± (ä½¿ç”¨ BaseTask çš„è¾…åŠ©å‡½æ•°)
        #    BaseTask._calculate_total_loss é»˜è®¤ä¼šè°ƒç”¨ loss(preds, batch)
        #    æ‚¨çš„æŸå¤±å‡½æ•° (ä¾‹å¦‚ CrossEntropyLoss) éœ€è¦çŸ¥é“å¦‚ä½•ä» 'preds' (logits)
        #    å’Œ 'batch' (åŒ…å« 'class') ä¸­æå–æ‰€éœ€ä¿¡æ¯ã€‚
        loss_dict = self._calculate_total_loss(preds_logits, batch)
        
        # 3. è®°å½•è®­ç»ƒæŸå¤± (PL ä¼šè‡ªåŠ¨æ·»åŠ  'train/' å‰ç¼€)
        #    prog_bar=True ä¼šåœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤º 'total_loss'
        batch_size = self._get_batch_size(batch)
        self.log_dict(loss_dict, on_step=True, on_epoch=True, prog_bar=True, batch_size=batch_size)
        
        # 4. è¿”å›æ€»æŸå¤±
        return loss_dict["total_loss"]

    def predict_step(self, batch: Dict[str, Any], batch_idx: int, dataloader_idx: int = 0) -> Dict[str, torch.Tensor]:
        """
        æ‰§è¡Œå•ä¸ªé¢„æµ‹æ­¥éª¤ (ç”¨äºç”Ÿäº§)ã€‚
        """
        # 1. å‰å‘ä¼ æ’­
        preds_logits = self.forward(batch)
        
        # 2. è®¡ç®—æœ€ç»ˆçš„ç±»åˆ«é¢„æµ‹
        # preds_labels = torch.argmax(preds_logits, dim=-1)  # ä½¿ç”¨ -1 ä»¥æ”¯æŒ [B, N, C] æˆ– [N, C]
        
        # 3. è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒPredictionWriter å›è°ƒå°†å¤„ç†è¿™ä¸ªå­—å…¸
        #    æˆ‘ä»¬è¿”å› CPU å¼ é‡ä»¥é‡Šæ”¾ GPU å†…å­˜
        results = {
            # "preds": preds_labels.cpu(),
            "logits": preds_logits.cpu(),  # ä¹Ÿä¿å­˜ logits ç”¨äºåå¤„ç†
        }
        
        # (å¯é€‰) å¦‚æœéœ€è¦åŸå§‹ç´¢å¼• (ç”¨äºæ‹¼æ¥/æŠ•ç¥¨)
        # æˆ‘ä»¬çš„æ•°æ®é›†å¯èƒ½æä¾› 'indices' å­—æ®µ
        if "indices" in batch:
            results["indices"] = batch["indices"].cpu()
        
        # ğŸ”¥ æ–°å¢ï¼šä¼ é€’æ–‡ä»¶ä¿¡æ¯åˆ° callbackï¼Œé¿å…æ¨æ–­
        # è¿™äº›ä¿¡æ¯ç”± BinPklDataset åœ¨ test split æ—¶æä¾›
        if "bin_file" in batch:
            results["bin_file"] = batch["bin_file"]  # é€šå¸¸æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
        if "bin_path" in batch:
            results["bin_path"] = batch["bin_path"]
        if "pkl_path" in batch:
            results["pkl_path"] = batch["pkl_path"]
        
        # ä¿å­˜åæ ‡ä¿¡æ¯ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        if "coord" in batch:
            results["coord"] = batch["coord"].cpu()
            
        return results