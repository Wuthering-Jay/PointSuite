"""
è¯­ä¹‰åˆ†å‰²ä»»åŠ¡æ¨¡å—

è¯¥æ¨¡å—å®ç°äº†ç‚¹äº‘è¯­ä¹‰åˆ†å‰²çš„å®Œæ•´ä»»åŠ¡é€»è¾‘ï¼Œç»§æ‰¿è‡ª BaseTaskã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ”¯æŒä»»æ„ backbone + head ç»„åˆ
- è‡ªåŠ¨è¿½è¸ªæœ€ä½³ mIoU
- è¯¦ç»†çš„æ¯ç±»æŒ‡æ ‡æ‰“å°
- é¢„æµ‹ç»“æœå¯¼å‡ºæ”¯æŒ

é…ç½®ç¤ºä¾‹
--------
.. code-block:: yaml

    model:
        backbone:
            class_path: pointsuite.models.backbones.ptv2.PointTransformerV2
            init_args:
                in_channels: 6
        head:
            class_path: pointsuite.models.heads.SegmentationHead
            init_args:
                in_channels: 512
                num_classes: 8
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, List, Optional

from .base_task import BaseTask
from ..utils.logger import (
    Colors,
    log_info,
    log_warning,
    print_header,
    print_section,
)
from ..utils.config import import_class


def _display_width(s: str) -> int:
    """
    è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦
    
    ä¸­æ–‡å­—ç¬¦å  2 ä¸ªå®½åº¦ï¼Œå…¶ä»–å­—ç¬¦å  1 ä¸ªå®½åº¦ã€‚
    
    å‚æ•°
    ----
    s : str
        è¾“å…¥å­—ç¬¦ä¸²
        
    è¿”å›
    ----
    int
        æ˜¾ç¤ºå®½åº¦
    """
    width = 0
    for c in s:
        if '\u4e00' <= c <= '\u9fff':
            width += 2
        else:
            width += 1
    return width


def _pad_to_width(s: str, target_width: int) -> str:
    """
    å°†å­—ç¬¦ä¸²å¡«å……åˆ°æŒ‡å®šæ˜¾ç¤ºå®½åº¦
    
    å‚æ•°
    ----
    s : str
        è¾“å…¥å­—ç¬¦ä¸²
    target_width : int
        ç›®æ ‡å®½åº¦
        
    è¿”å›
    ----
    str
        å¡«å……åçš„å­—ç¬¦ä¸²
    """
    current_width = _display_width(s)
    padding = target_width - current_width
    return s + ' ' * max(0, padding)


class SemanticSegmentationTask(BaseTask):
    """
    è¯­ä¹‰åˆ†å‰²ä»»åŠ¡
    
    ç»§æ‰¿è‡ª BaseTaskï¼Œæ·»åŠ äº†è¯­ä¹‰åˆ†å‰²ç‰¹å®šçš„ç»„ä»¶ï¼š
    - backbone + head ç½‘ç»œç»“æ„
    - æœ€ä½³ mIoU è¿½è¸ª
    - è¯¦ç»†çš„æ¯ç±»æŒ‡æ ‡æ‰“å°
    
    Attributes
    ----------
    backbone : nn.Module
        ç‰¹å¾æå–éª¨å¹²ç½‘ç»œ
    head : nn.Module
        åˆ†å‰²å¤´
    best_miou : float
        æœ€ä½³ mIoU å€¼
    best_miou_epoch : int
        æœ€ä½³ mIoU å¯¹åº”çš„è½®æ¬¡
    """
    
    def __init__(
        self,
        backbone: Optional[nn.Module] = None,
        head: Optional[nn.Module] = None,
        model_config: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> None:
        """
        åˆå§‹åŒ–è¯­ä¹‰åˆ†å‰²ä»»åŠ¡
        
        å‚æ•°
        ----
        backbone : nn.Module, optional
            å·²å®ä¾‹åŒ–çš„éª¨å¹²ç½‘ç»œ
        head : nn.Module, optional
            å·²å®ä¾‹åŒ–çš„åˆ†å‰²å¤´
        model_config : dict, optional
            æ¨¡å‹é…ç½®å­—å…¸ï¼Œç”¨äºä»é…ç½®å®ä¾‹åŒ– backbone å’Œ headã€‚
            å¦‚æœæä¾›ï¼Œåˆ™å¿½ç•¥ backbone å’Œ head å‚æ•°ã€‚
            
            æ ¼å¼::
            
                {
                    'backbone': {'class_path': '...', 'init_args': {...}},
                    'head': {'class_path': '...', 'init_args': {...}}
                }
                
        **kwargs
            ä¼ é€’ç»™ BaseTask çš„å‚æ•°
        """
        super().__init__(**kwargs)
        
        # è¿½è¸ªæœ€ä½³ mIoU
        self.best_miou = 0.0
        self.best_miou_epoch = -1
        
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä¿å­˜ hyperparameters
        # å¦‚æœä½¿ç”¨ model_configï¼Œæˆ‘ä»¬å¿½ç•¥ backbone å’Œ head å¯¹è±¡ï¼Œé¿å…é‡å¤ä¿å­˜å’Œè­¦å‘Š
        # å¦‚æœä½¿ç”¨ backbone/head å¯¹è±¡ï¼Œæˆ‘ä»¬å¿…é¡»ä¿å­˜å®ƒä»¬ä»¥æ”¯æŒè‡ªåŠ¨é‡å»ºï¼ˆå°½ç®¡ä¼šæœ‰è­¦å‘Šï¼‰
        if model_config is not None:
            self.save_hyperparameters(ignore=['backbone', 'head'])
            
            # ä»é…ç½®å®ä¾‹åŒ–
            backbone_cfg = model_config.get('backbone')
            head_cfg = model_config.get('head')
            
            if backbone_cfg:
                backbone_cls = import_class(backbone_cfg['class_path'])
                self.backbone = backbone_cls(**backbone_cfg.get('init_args', {}))
            
            if head_cfg:
                head_cls = import_class(head_cfg['class_path'])
                self.head = head_cls(**head_cfg.get('init_args', {}))
                
        else:
            # å…¼å®¹æ—§æ–¹å¼ï¼šç›´æ¥ä¼ å…¥å¯¹è±¡
            # è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬ä¸ ignore backbone/headï¼Œä»¥ä¾¿ load_from_checkpoint èƒ½å·¥ä½œ
            # ç”¨æˆ·ä¼šçœ‹åˆ° PL çš„è­¦å‘Šï¼Œä½†è¿™æ˜¯é¢„æœŸçš„
            self.save_hyperparameters()
            self.backbone = backbone
            self.head = head
            
        # éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        if not hasattr(self, 'backbone') or self.backbone is None:
            raise ValueError("Backbone æœªåˆå§‹åŒ–ï¼è¯·æä¾› backbone å¯¹è±¡æˆ– model_config")
        if not hasattr(self, 'head') or self.head is None:
            raise ValueError("Head æœªåˆå§‹åŒ–ï¼è¯·æä¾› head å¯¹è±¡æˆ– model_config")

    def forward(self, batch: Dict[str, Any]) -> torch.Tensor:
        """
        å®šä¹‰æ¨¡å‹çš„å•æ¬¡å‰å‘ä¼ æ’­ã€‚
        
        Args:
            batch (Dict): æ¥è‡ª DataLoader çš„æ‰¹æ¬¡æ•°æ® (ç”± collate_fn äº§ç”Ÿ)ã€‚
                          æˆ‘ä»¬çš„ collate_fn æä¾›:
                          - 'coord': [N, 3] ç‚¹åæ ‡
                          - 'feat': [N, C] ç‚¹ç‰¹å¾
                          - 'class': [N] ç‚¹æ ‡ç­¾
                          - 'offset': [B] ç´¯ç§¯åç§»é‡
        
        Returns:
            torch.Tensor: æ¨¡å‹çš„åŸå§‹ Logits è¾“å‡º (shape: [N_total_points, num_classes])ã€‚
        """
        # 1. Backbone æå–ç‰¹å¾
        # ä¸åŒ backbone å¯èƒ½æœ‰ä¸åŒçš„è¾“å…¥æ ¼å¼ï¼š
        # - ç®€å•æ¨¡å‹ï¼šç›´æ¥æ¥æ”¶ batch['feat']
        # - PointTransformerV2/PointNet++ï¼šéœ€è¦æ•´ä¸ª batch å­—å…¸
        
        # æ£€æŸ¥ backbone æ˜¯å¦éœ€è¦æ•´ä¸ª batch å­—å…¸
        # æ–¹æ³•1: æ£€æŸ¥å‚æ•°åæ˜¯å¦ä¸º 'batch' æˆ– 'data_dict'
        # æ–¹æ³•2: æ£€æŸ¥æ˜¯å¦ä¸º PointTransformerV2 ç­‰å·²çŸ¥éœ€è¦ dict çš„æ¨¡å‹
        forward_params = self.backbone.forward.__code__.co_varnames if hasattr(self.backbone, 'forward') else []
        needs_dict = ('batch' in forward_params or 
                     'data_dict' in forward_params or
                     'PointTransformerV2' in self.backbone.__class__.__name__)
        
        if needs_dict:
            # Backbone æ¥æ”¶æ•´ä¸ª batch å­—å…¸
            backbone_output = self.backbone(batch)
        else:
            # Backbone åªæ¥æ”¶ç‰¹å¾å¼ é‡ï¼ˆå¦‚ç®€å• MLPï¼‰
            backbone_output = self.backbone(batch.get('feat', batch.get('coord')))
        
        # 2. å¤„ç† backbone è¾“å‡º
        # å¦‚æœè¾“å‡ºæ˜¯å­—å…¸ï¼ˆå¦‚ PointNet++ è¿”å› {'feat': ..., 'sa_xyz': ...}ï¼‰
        if isinstance(backbone_output, dict):
            features = backbone_output['feat']  # æå–ç‰¹å¾
        else:
            features = backbone_output
        
        # 3. Head ç”Ÿæˆ logits
        logits = self.head(features)
        
        # è¿”å›å­—å…¸ä»¥æ”¯æŒè¾…åŠ©æŸå¤± (Auxiliary Loss)
        # 'logits': æ ‡å‡†è¾“å‡º
        # 'features': Head ä¹‹å‰çš„ç‰¹å¾ (Backbone è¾“å‡º)
        return {
            'logits': logits,
            'features': features
        }

    def training_step(self, batch: Dict[str, Any], batch_idx: int) -> torch.Tensor:
        """
        æ‰§è¡Œå•ä¸ªè®­ç»ƒæ­¥éª¤ã€‚
        """
        # 1. å‰å‘ä¼ æ’­
        preds_logits = self.forward(batch)
        
        # 2. è®¡ç®—æŸå¤± (ä½¿ç”¨ BaseTask çš„è¾…åŠ©å‡½æ•°)
        #    BaseTask._calculate_total_loss é»˜è®¤ä¼šè°ƒç”¨ loss(preds, batch)
        #    æ‚¨çš„æŸå¤±å‡½æ•° (ä¾‹å¦‚ CrossEntropyLoss) éœ€è¦çŸ¥é“å¦‚ä½•ä» 'preds' (logits)
        #    å’Œ 'batch' (åŒ…å« 'class') ä¸­æå–æ‰€éœ€ä¿¡æ¯ã€‚
        loss_dict = self._calculate_total_loss(preds_logits, batch)
        
        # 3. è®°å½•è®­ç»ƒæŸå¤± (PL ä¼šè‡ªåŠ¨æ·»åŠ  'train/' å‰ç¼€)
        #    prog_bar=True ä¼šåœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤º 'total_loss'
        batch_size = self._get_batch_size(batch)
        self.log_dict(loss_dict, on_step=True, on_epoch=True, prog_bar=True, batch_size=batch_size)
        
        # 4. è¿”å›æ€»æŸå¤±
        return loss_dict["total_loss"]

    def predict_step(self, batch: Dict[str, Any], batch_idx: int, dataloader_idx: int = 0) -> Dict[str, torch.Tensor]:
        """
        æ‰§è¡Œå•ä¸ªé¢„æµ‹æ­¥éª¤ï¼ˆç”¨äºç”Ÿäº§ç¯å¢ƒã€æ— çœŸå€¼æ ‡ç­¾ï¼‰
        
        ä¸ test_step çš„åŒºåˆ«ï¼š
        - predict_step: æ— çœŸå€¼æ ‡ç­¾ï¼Œä¸è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡ï¼Œåªè¿”å›é¢„æµ‹ç»“æœ
        - test_step: æœ‰çœŸå€¼æ ‡ç­¾ï¼Œè®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡ï¼Œå¯é€‰ä¿å­˜é¢„æµ‹ç»“æœ
        
        ä½¿ç”¨åœºæ™¯ï¼š
        - æ–°åœºæ™¯é¢„æµ‹ï¼ˆæ— æ ‡ç­¾ï¼‰
        - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
        - éœ€è¦ä¿å­˜ .las æ–‡ä»¶æ—¶ä½¿ç”¨ Trainer.predict() + SemanticPredictLasWriter
        """
        # 1. å‰å‘ä¼ æ’­
        preds = self.forward(batch)
        
        # 2. åå¤„ç†é¢„æµ‹ (æ”¯æŒ Mask3D ç­‰å¤æ‚è¾“å‡º)
        #    å­ç±»å¯ä»¥è¦†ç›– postprocess_predictions æ¥è‡ªå®šä¹‰è¡Œä¸º
        processed_preds = self.postprocess_predictions(preds)
        
        # 3. è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒPredictionWriter å›è°ƒå°†å¤„ç†è¿™ä¸ªå­—å…¸
        #    æˆ‘ä»¬è¿”å› CPU å¼ é‡ä»¥é‡Šæ”¾ GPU å†…å­˜
        results = {
            "logits": processed_preds.cpu(),  # å¯ä»¥æ˜¯ logits [N, C] æˆ– labels [N]
        }
        
        # (å¯é€‰) å¦‚æœéœ€è¦åŸå§‹ç´¢å¼• (ç”¨äºæ‹¼æ¥/æŠ•ç¥¨)
        # æˆ‘ä»¬çš„æ•°æ®é›†å¯èƒ½æä¾› 'indices' å­—æ®µ
        if "indices" in batch:
            results["indices"] = batch["indices"].cpu()
        
        # ğŸ”¥ ä¼ é€’æ–‡ä»¶ä¿¡æ¯åˆ° callbackï¼ˆç”¨äºé¢„æµ‹ç»“æœçš„æ–‡ä»¶çº§èšåˆï¼‰
        # è¿™äº›ä¿¡æ¯ç”± dataset åœ¨ test/predict split æ—¶æä¾›
        if "bin_file" in batch:
            results["bin_file"] = batch["bin_file"]  # æ–‡ä»¶æ ‡è¯†ç¬¦ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        if "bin_path" in batch:
            results["bin_path"] = batch["bin_path"]  # åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„
        if "pkl_path" in batch:
            results["pkl_path"] = batch["pkl_path"]  # å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        
        # ä¿å­˜åæ ‡ä¿¡æ¯ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        if "coord" in batch:
            results["coord"] = batch["coord"].cpu()
            
        return results
    
    def _print_validation_metrics(self, print_metrics: Dict[str, Any]) -> None:
        """
        æ‰“å°è¯­ä¹‰åˆ†å‰²çš„è¯¦ç»†éªŒè¯æŒ‡æ ‡
        
        å‚æ•°
        ----
        print_metrics : dict
            è®¡ç®—å‡ºçš„æŒ‡æ ‡å­—å…¸
        """
        miou_key = 'mean_iou'
        if miou_key not in print_metrics:
            super()._print_validation_metrics(print_metrics)
            return
        
        try:
            current_miou = float(print_metrics[miou_key])
            
            # æ›´æ–°æœ€ä½³ mIoU
            if current_miou > self.best_miou:
                self.best_miou = current_miou
                self.best_miou_epoch = self.current_epoch
            
            overall_acc = print_metrics.get('overall_accuracy', None)
            
            # è·å–æ¯ç±»æŒ‡æ ‡
            per_class_iou = print_metrics.get('iou_per_class', print_metrics.get('per_class_iou', None))
            per_class_precision = print_metrics.get('precision_per_class', print_metrics.get('per_class_precision', None))
            per_class_recall = print_metrics.get('recall_per_class', print_metrics.get('per_class_recall', None))
            per_class_f1 = print_metrics.get('f1_per_class', print_metrics.get('per_class_f1', None))
            
            # å…¼å®¹æ—§ä»£ç ï¼šä» metric å¯¹è±¡è·å–
            if per_class_iou is None and 'mean_iou' in self.val_metrics:
                metric = self.val_metrics['mean_iou']
                if hasattr(metric, 'confusion_matrix'):
                    confmat = metric.confusion_matrix.cpu().numpy()
                    intersection = np.diag(confmat)
                    union = confmat.sum(1) + confmat.sum(0) - np.diag(confmat)
                    per_class_iou = intersection / (union + 1e-10)
                    per_class_precision = intersection / (confmat.sum(0) + 1e-10)
                    per_class_recall = intersection / (confmat.sum(1) + 1e-10)
                    per_class_f1 = 2 * per_class_precision * per_class_recall / (per_class_precision + per_class_recall + 1e-10)

            # æ‰“å°æ ‡é¢˜
            display_epoch = self.current_epoch + 1
            print()
            print("=" * 100)
            print(f"Validation Epoch {display_epoch} - Metrics")
            print("=" * 100)
            
            if overall_acc is not None:
                print(f"Overall Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)")
            print(f"Mean IoU (current): {current_miou:.4f}")
            print(f"Mean IoU (best)   : {self.best_miou:.4f} (Epoch {self.best_miou_epoch + 1})")
            if current_miou > self.best_miou - 1e-6:
                print("* New best mIoU achieved!")
            print("=" * 100)
            
            # æ‰“å°æ¯ç±»æŒ‡æ ‡
            if per_class_iou is not None:
                self._print_per_class_metrics(
                    per_class_iou, per_class_precision, per_class_recall, per_class_f1,
                    print_metrics, current_miou
                )
            print("=" * 100)
            print()
            
        except Exception as e:
            self._task_logger.warning(f"æ— æ³•æ‰“å°è¯¦ç»†æŒ‡æ ‡: {e}")
            import traceback
            traceback.print_exc()
    
    def _print_test_metrics(self, print_metrics: Dict[str, Any]) -> None:
        """
        æ‰“å°è¯­ä¹‰åˆ†å‰²çš„è¯¦ç»†æµ‹è¯•æŒ‡æ ‡
        
        å‚æ•°
        ----
        print_metrics : dict
            è®¡ç®—å‡ºçš„æŒ‡æ ‡å­—å…¸
        """
        miou_key = 'mean_iou'
        if miou_key not in print_metrics:
            super()._print_test_metrics(print_metrics)
            return
        
        try:
            current_miou = float(print_metrics[miou_key])
            overall_acc = print_metrics.get('overall_accuracy', None)
            
            # è·å–æ¯ç±»æŒ‡æ ‡
            per_class_iou = print_metrics.get('iou_per_class', print_metrics.get('per_class_iou', None))
            per_class_precision = print_metrics.get('precision_per_class', print_metrics.get('per_class_precision', None))
            per_class_recall = print_metrics.get('recall_per_class', print_metrics.get('per_class_recall', None))
            per_class_f1 = print_metrics.get('f1_per_class', print_metrics.get('per_class_f1', None))
            
            # å…¼å®¹æ—§ä»£ç 
            if per_class_iou is None and 'mean_iou' in self.test_metrics:
                metric = self.test_metrics['mean_iou']
                if hasattr(metric, 'confusion_matrix'):
                    confmat = metric.confusion_matrix.cpu().numpy()
                    intersection = np.diag(confmat)
                    union = confmat.sum(1) + confmat.sum(0) - np.diag(confmat)
                    per_class_iou = intersection / (union + 1e-10)
                    per_class_precision = intersection / (confmat.sum(0) + 1e-10)
                    per_class_recall = intersection / (confmat.sum(1) + 1e-10)
                    per_class_f1 = 2 * per_class_precision * per_class_recall / (per_class_precision + per_class_recall + 1e-10)

            print()
            print("=" * 100)
            print("Test Results - Metrics")
            print("=" * 100)
            if overall_acc is not None:
                print(f"Overall Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)")
            print(f"Mean IoU: {current_miou:.4f}")
            print("=" * 100)
            
            if per_class_iou is not None:
                self._print_per_class_metrics(
                    per_class_iou, per_class_precision, per_class_recall, per_class_f1,
                    print_metrics, current_miou
                )
            print("=" * 100)
            print()
            
        except Exception as e:
            self._task_logger.warning(f"æ— æ³•æ‰“å°è¯¦ç»†æµ‹è¯•æŒ‡æ ‡: {e}")
            import traceback
            traceback.print_exc()
    
    def _print_per_class_metrics(
        self, 
        per_class_iou, 
        per_class_precision, 
        per_class_recall, 
        per_class_f1,
        print_metrics: Dict[str, Any],
        mean_iou: float
    ):
        """
        æ‰“å°æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡è¡¨æ ¼
        
        Args:
            per_class_iou: æ¯ç±» IoU æ•°ç»„
            per_class_precision: æ¯ç±» Precision æ•°ç»„
            per_class_recall: æ¯ç±» Recall æ•°ç»„
            per_class_f1: æ¯ç±» F1 æ•°ç»„
            print_metrics: æŒ‡æ ‡å­—å…¸ï¼ˆç”¨äºè·å–ç±»åˆ«åï¼‰
            mean_iou: å¹³å‡ IoU
        """
        # è·å–ç±»åˆ«å
        class_names = print_metrics.get('class_names', None)
        if class_names is None:
            class_names = self.hparams.get('class_names', None) if hasattr(self, 'hparams') else None
        
        # ç¡®ä¿æ˜¯ numpy æ•°ç»„
        if isinstance(per_class_iou, torch.Tensor): 
            per_class_iou = per_class_iou.cpu().numpy()
        if isinstance(per_class_precision, torch.Tensor): 
            per_class_precision = per_class_precision.cpu().numpy()
        if isinstance(per_class_recall, torch.Tensor): 
            per_class_recall = per_class_recall.cpu().numpy()
        if isinstance(per_class_f1, torch.Tensor): 
            per_class_f1 = per_class_f1.cpu().numpy()
        
        num_classes = len(per_class_iou)
        
        # è®¡ç®—æœ€å¤§ç±»åˆ«åå®½åº¦
        max_name_width = 8  # æœ€å°å®½åº¦
        for i in range(num_classes):
            c_name = class_names[i] if class_names and i < len(class_names) else f"Class {i}"
            max_name_width = max(max_name_width, _display_width(c_name))
        max_name_width = min(max_name_width, 20)  # æœ€å¤§å®½åº¦é™åˆ¶
        
        # è¡¨å¤´
        header_class = _pad_to_width("Class", max_name_width)
        print(f"  {header_class}  {'IoU':>8}  {'Precision':>10}  {'Recall':>8}  {'F1-Score':>10}")
        print(f"  {'-'*max_name_width}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
        
        for i in range(num_classes):
            c_name = class_names[i] if class_names and i < len(class_names) else f"Class {i}"
            c_name_padded = _pad_to_width(c_name, max_name_width)
            print(f"  {c_name_padded}  {per_class_iou[i]:8.4f}  {per_class_precision[i]:10.4f}  "
                  f"{per_class_recall[i]:8.4f}  {per_class_f1[i]:10.4f}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        mean_precision = np.nanmean(per_class_precision)
        mean_recall = np.nanmean(per_class_recall)
        mean_f1 = np.nanmean(per_class_f1)
        
        print(f"  {'-'*max_name_width}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
        mean_label = _pad_to_width("Mean", max_name_width)
        print(f"  {mean_label}  {mean_iou:8.4f}  {mean_precision:10.4f}  "
              f"{mean_recall:8.4f}  {mean_f1:10.4f}")