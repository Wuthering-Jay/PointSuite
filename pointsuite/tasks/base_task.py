import torch
import torch.nn as nn
import pytorch_lightning as pl
import torchmetrics
import importlib
import yaml
from typing import List, Dict, Any

class BaseTask(pl.LightningModule):
    """
    ‰∏Ä‰∏™ÊäΩË±°ÁöÑ‰ªªÂä°Âü∫Á±ª (LightningModule)„ÄÇ
    
    ÂÆÉË¥üË¥£Â§ÑÁêÜÊâÄÊúâ‰ªªÂä°ÂÖ±ÊúâÁöÑÈÄªËæëÔºö
    1. Ëá™Âä®‰ªé YAML ÈÖçÁΩÆ‰∏≠ÂÆû‰æãÂåñÊçüÂ§±ÂáΩÊï∞ (losses)„ÄÇ
    2. Ëá™Âä®‰ªé YAML ÈÖçÁΩÆ‰∏≠ÂÆû‰æãÂåñÊåáÊ†á (metrics)„ÄÇ
    3. Ëá™Âä®Âú® validation/test epoch ÁªìÊùüÊó∂ËÆ°ÁÆóÂíåËÆ∞ÂΩïÊâÄÊúâÊåáÊ†á„ÄÇ
    
    Ê≥®ÊÑè: 
    Êàë‰ª¨ *‰∏ç* Âú®ËøôÈáåÂÆûÁé∞ `configure_optimizers`„ÄÇ
    PyTorch Lightning ÁöÑ `LightningCLI` ‰ºöËá™Âä®ËØªÂèñÊÇ®Âú®
    `configs/schedules/` ÁõÆÂΩï‰∏≠ÂÆö‰πâÁöÑ `optimizer` Âíå `lr_scheduler` 
    ÈÖçÁΩÆÔºåÂπ∂Ëá™Âä®‰∏∫ÊÇ®ÈÖçÁΩÆÂÆÉ‰ª¨„ÄÇËøô‰øùÊåÅ‰∫Ü Task Ê®°ÂùóÁöÑÁÆÄÊ¥Å„ÄÇ
    """
    
    def __init__(self,
                 learning_rate: float = 1e-3,
                 loss_configs: List[Dict[str, Any]] = None,
                 metric_configs: List[Dict[str, Any]] = None,
                 class_mapping: Dict[int, int] = None,
                 class_names: List[str] = None,
                 ignore_label: int = -1):
        """
        Args:
            learning_rate (float): Â≠¶‰π†Áéá„ÄÇ
                                   Êàë‰ª¨Âú®Ê≠§Â§ÑÊé•Êî∂ learning_rate (ËÄå‰∏çÊòØ‰ªÖÂú®‰ºòÂåñÂô®ÈÖçÁΩÆ‰∏≠)
                                   ‰∏ªË¶ÅÊúâ‰∏§‰∏™ÂéüÂõ†:
                                   1. Êó•ÂøóËÆ∞ÂΩï: 'self.save_hyperparameters()' ‰ºöËá™Âä®
                                      Â∞Ü 'learning_rate' ËÆ∞ÂΩïÂà∞ TensorBoard/Wandb„ÄÇ
                                   2. ÁÅµÊ¥ªÊÄß: ÂÖÅËÆ∏Âú®‰∏ç‰ΩøÁî® 'LightningCLI' ÁöÑÁ∫Ø Python Ê®°Âºè‰∏ã
                                      ËΩªÊùæËÆøÈóÆ 'self.hparams.learning_rate' Êù•ÈÖçÁΩÆ‰ºòÂåñÂô®„ÄÇ
                                   
                                   Âú® YAML ÈÖçÁΩÆ‰∏≠ÔºåÊàë‰ª¨Â∫îÂ∞ÜÊ≠§ 'learning_rate' ËßÜ‰∏∫‚ÄúÂçï‰∏Ä‰∫ãÂÆûÊù•Ê∫ê‚ÄùÔºå
                                   Âπ∂Âú® 'optimizer' ÈÖçÁΩÆ‰∏≠‰ΩøÁî® YAML ÈìæÊé• (‰æãÂ¶Ç:
                                   lr: ${model.init_args.learning_rate}) Êù•ÂºïÁî®ÂÆÉ„ÄÇ
                                   
            loss_configs (List[Dict]): 
                Êù•Ëá™ YAML ÁöÑÊçüÂ§±ÂáΩÊï∞ÈÖçÁΩÆÂàóË°®„ÄÇ
                Á§∫‰æã: 
                - class_path: point_suite.models.losses.focal_loss.FocalLoss
                  init_args: { gamma: 2.0 }
                  weight: 1.0 # (ÂèØÈÄâ) ÊçüÂ§±ÁöÑÊùÉÈáç
                  
            metric_configs (List[Dict]): 
                Êù•Ëá™ YAML ÁöÑÊåáÊ†áÈÖçÁΩÆÂàóË°®„ÄÇ
                Á§∫‰æã:
                - class_path: pointsuite.utils.metrics.OverallAccuracy
                  init_args: { num_classes: 8 }
                  
            class_mapping (Dict[int, int]): 
                ÂéüÂßãÁ±ªÂà´Ê†áÁ≠æ -> ËøûÁª≠Á±ªÂà´Ê†áÁ≠æÁöÑÊò†Â∞Ñ
                ‰æãÂ¶Ç: {0: 0, 1: 1, 2: 2, 6: 3, 9: 4}
                Ê≠§Êò†Â∞ÑÂ∞ÜË¢´‰øùÂ≠òÂà∞ checkpointÔºåÂπ∂Âú®È¢ÑÊµãÊó∂Ëá™Âä®Âä†ËΩΩÂà∞ SemanticPredictLasWriter
                Â¶ÇÊûú‰∏∫ NoneÔºåË°®Á§∫‰∏ç‰ΩøÁî®Á±ªÂà´Êò†Â∞Ñ
                
            class_names (List[str]): 
                Á±ªÂà´ÂêçÁß∞ÂàóË°®ÔºåÁî®‰∫éÈ™åËØÅÊó∂ÊòæÁ§∫
                ‰æãÂ¶Ç: ['Ground', 'Vegetation', 'Building']
                Â¶ÇÊûú‰∏∫ NoneÔºåÈ™åËØÅÊó∂ÊòæÁ§∫ Class 0, Class 1, ...
        """
        super().__init__()
        # Â∞ÜË∂ÖÂèÇÊï∞‰øùÂ≠òÂà∞ checkpoint
        # üî• ÂÖ≥ÈîÆ‰øÆÊîπÔºö‰øùÂ≠òÊâÄÊúâÂèÇÊï∞ÔºåÂåÖÊã¨ loss_configs Âíå metric_configs
        # ËøôÊ†∑ load_from_checkpoint ÊâçËÉΩÊ≠£Á°ÆÈáçÂª∫ Task
        self.save_hyperparameters()
        
        # ‰øùÂ≠ò class_mapping Áî®‰∫é SemanticPredictLasWriter
        self.class_mapping = class_mapping
        
        # ËøΩË∏™ÊúÄ‰Ω≥ mIoU
        self.best_miou = 0.0
        self.best_miou_epoch = -1
        
        # üî• Ëá™ÂÆö‰πâ hparams ‰øùÂ≠òÈí©Â≠êÔºåÁ°Æ‰øù‰∏≠ÊñáÊ≠£Á°ÆÊòæÁ§∫
        self._custom_save_hparams()
        
        # --- 1. Âä®ÊÄÅÂÆû‰æãÂåñÊçüÂ§±ÂáΩÊï∞ ---
        self.losses = nn.ModuleDict()
        self.loss_weights = {}
        if loss_configs:
            for cfg in loss_configs:
                # 'loss_name' ÊòØÊàë‰ª¨ÁªôËøô‰∏™ÊçüÂ§±Ëµ∑ÁöÑÂêçÂ≠óÔºå‰æãÂ¶Ç 'focal_loss'
                loss_name = cfg.get("name", cfg["class_path"].split('.')[-1].lower())
                loss_class = self._import_class(cfg["class_path"])
                init_args = cfg.get("init_args", {})
                
                self.losses[loss_name] = loss_class(**init_args)
                self.loss_weights[loss_name] = cfg.get("weight", 1.0)
                
        # --- 2. Âä®ÊÄÅÂÆû‰æãÂåñÊåáÊ†á ---
        # Êàë‰ª¨‰ΩøÁî® ModuleDict Êù•Á°Æ‰øùÊåáÊ†áË¢´Ê≠£Á°ÆÁßªÂä®Âà∞ GPU
        self.val_metrics = nn.ModuleDict()
        self.test_metrics = nn.ModuleDict()
        if metric_configs:
            for cfg in metric_configs:
                metric_name = cfg.get("name", cfg["class_path"].split('.')[-1].lower())
                metric_class = self._import_class(cfg["class_path"])
                init_args = cfg.get("init_args", {})
                
                # ‰∏∫ val Âíå test ÂàÜÂà´ÂàõÂª∫ÂÆû‰æãÔºå‰ª•ÈÅøÂÖçÁä∂ÊÄÅÂÜ≤Á™Å
                self.val_metrics[metric_name] = metric_class(**init_args)
                self.test_metrics[metric_name] = metric_class(**init_args)
    
    def _custom_save_hparams(self):
        """
        Ëá™ÂÆö‰πâ‰øùÂ≠ò hparams.yamlÔºåÁ°Æ‰øù‰∏≠ÊñáÂ≠óÁ¨¶Ê≠£Á°ÆÊòæÁ§∫
        Ë¶ÜÁõñ PyTorch Lightning ÈªòËÆ§ÁöÑ YAML dump Ë°å‰∏∫
        """
        try:
            import os
            # Ëé∑Âèñ log_dir
            if hasattr(self.logger, 'log_dir') and self.logger.log_dir:
                hparams_file = os.path.join(self.logger.log_dir, 'hparams.yaml')
                # Âª∂Ëøü‰øùÂ≠òÔºöÂú® trainer ÂÆåÊàêËÆæÁΩÆÂêéÂÜç‰øùÂ≠ò
                # ËøôÈáåÂè™ÊòØÊ†áËÆ∞ÔºåÂÆûÈôÖ‰øùÂ≠ò‰ºöÂú® on_train_start ‰∏≠ËøõË°å
                self._pending_hparams_save = True
        except Exception:
            pass  # Â¶ÇÊûúÂ§±Ë¥•Â∞±‰ΩøÁî®ÈªòËÆ§Ë°å‰∏∫
    
    def on_train_start(self):
        """ËÆ≠ÁªÉÂºÄÂßãÊó∂‰øùÂ≠ò hparamsÔºàÁ°Æ‰øù‰∏≠ÊñáÊ≠£Á°ÆÊòæÁ§∫Ôºâ"""
        if hasattr(self, '_pending_hparams_save') and self._pending_hparams_save:
            try:
                import os
                if hasattr(self.logger, 'log_dir') and self.logger.log_dir:
                    hparams_file = os.path.join(self.logger.log_dir, 'hparams.yaml')
                    # ‰ΩøÁî® allow_unicode=True Á°Æ‰øù‰∏≠ÊñáÊ≠£Á°Æ‰øùÂ≠ò
                    with open(hparams_file, 'w', encoding='utf-8') as f:
                        yaml.dump(
                            dict(self.hparams), 
                            f, 
                            allow_unicode=True,  # üî• ÂÖ≥ÈîÆÔºöÂÖÅËÆ∏ Unicode Â≠óÁ¨¶
                            default_flow_style=False,
                            sort_keys=False
                        )
                self._pending_hparams_save = False
            except Exception as e:
                print(f"Warning: Could not save hparams with Chinese characters: {e}")

    def _import_class(self, class_path: str) -> type:
        """‰∏Ä‰∏™ËæÖÂä©ÂáΩÊï∞ÔºåÁî®‰∫é‰ªéÂ≠óÁ¨¶‰∏≤Ë∑ØÂæÑÂä®ÊÄÅÂØºÂÖ•Á±ª"""
        module_name, class_name = class_path.rsplit('.', 1)
        module = importlib.import_module(module_name)
        return getattr(module, class_name)

    def _calculate_total_loss(self, preds: Any, batch: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """
        (Â≠êÁ±ªÂèØ‰ª•Ë¶ÜÁõñ)
        ËÆ°ÁÆóÊâÄÊúâÊçüÂ§±ÂáΩÊï∞ÁöÑÂä†ÊùÉÊÄªÂíå„ÄÇ
        
        Ê≥®ÊÑèÔºöLoss ËÆ°ÁÆóÂº∫Âà∂Âú® FP32 ‰∏ãËøêË°åÔºå‰ª•ÈÅøÂÖçÊ∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉ‰∏≠ÁöÑÊï∞ÂÄº‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºå
        ÁâπÂà´ÊòØÂΩì‰ΩøÁî® ignore_index=-1 Êó∂„ÄÇ
        
        Args:
            preds (Any): Ê®°ÂûãÁöÑ forward() ËæìÂá∫„ÄÇ
            batch (Dict): Êù•Ëá™ DataLoader ÁöÑÊâπÊ¨°Êï∞ÊçÆ„ÄÇ
            
        Returns:
            Dict[str, torch.Tensor]: ÂåÖÂê´ 'total_loss' ÂíåÊØè‰∏™ÂçïÁã¨ÊçüÂ§±ÁöÑÂ≠óÂÖ∏„ÄÇ
        """
        loss_dict = {}
        total_loss = torch.tensor(0.0, device=self.device, dtype=torch.float32)
        
        # Âº∫Âà∂ Loss ËÆ°ÁÆóÂú® FP32 ‰∏ãËøêË°åÔºåÈÅøÂÖçÊ∑∑ÂêàÁ≤æÂ∫¶ÈóÆÈ¢ò
        # Ê≥®ÊÑèÔºöËøôÈáåÈúÄË¶ÅÂêåÊó∂Á¶ÅÁî® autocast Âπ∂Â∞Ü tensors ËΩ¨‰∏∫ FP32
        with torch.amp.autocast('cuda', enabled=False):
            # Â∞Ü preds ËΩ¨Êç¢‰∏∫ FP32Ôºå‰ΩÜ‰øùÁïôÊ¢ØÂ∫¶
            if isinstance(preds, torch.Tensor):
                if preds.is_floating_point() and preds.dtype != torch.float32:
                    preds = preds.float()
            elif isinstance(preds, dict):
                preds_fp32 = {}
                for k, v in preds.items():
                    if isinstance(v, torch.Tensor) and v.is_floating_point() and v.dtype != torch.float32:
                        preds_fp32[k] = v.float()
                    else:
                        preds_fp32[k] = v
                preds = preds_fp32
            
            # ÂêåÊ†∑Â§ÑÁêÜ batch ‰∏≠ÁöÑ target (ËôΩÁÑ∂ÈÄöÂ∏∏ÊòØ long Á±ªÂûã)
            batch_fp32 = {}
            for k, v in batch.items():
                if isinstance(v, torch.Tensor) and v.is_floating_point() and v.dtype != torch.float32:
                    batch_fp32[k] = v.float()
                else:
                    batch_fp32[k] = v
            
            for name, loss_fn in self.losses.items():
                # ÊçüÂ§±ÂáΩÊï∞Êé•Êî∂ (preds, batch)
                loss = loss_fn(preds, batch_fp32)
                # Á°Æ‰øù loss ‰πüÊòØ FP32
                if loss.dtype != torch.float32:
                    loss = loss.float()
                loss_dict[name] = loss
                total_loss += self.loss_weights[name] * loss
            
        loss_dict["total_loss"] = total_loss
        return loss_dict
    
    def _get_batch_size(self, batch: Dict[str, Any]) -> int:
        """
        ‰ªé batch ‰∏≠Êé®Êñ≠ batch_size„ÄÇ
        
        ÈÄÇÈÖçÊàë‰ª¨È°πÁõÆÁöÑ collate_fnÔºö
        - Â¶ÇÊûúÊúâ 'batch_index'Ôºå‰ΩøÁî® max + 1
        - Â¶ÇÊûúÊúâ 'offset'Ôºå‰ΩøÁî® len(offset)
        - Âê¶ÂàôËøîÂõû 1
        """
        if 'batch_index' in batch:
            return batch['batch_index'].max().item() + 1
        elif 'offset' in batch:
            return len(batch['offset'])
        else:
            return 1
    
    def postprocess_predictions(self, preds: Any) -> torch.Tensor:
        """
        ÂêéÂ§ÑÁêÜÈ¢ÑÊµãÁªìÊûúÔºåÂ∞ÜÊ®°ÂûãËæìÂá∫ËΩ¨Êç¢‰∏∫Ê†áÁ≠æÊàñ logits
        
        ËøôÊòØ‰∏Ä‰∏™ÂèØÈÄâÁöÑÈí©Â≠êÊñπÊ≥ïÔºåÂ≠êÁ±ªÂèØ‰ª•Ë¶ÜÁõñ‰ª•ÊîØÊåÅÂ§çÊùÇÁöÑËæìÂá∫Â§ÑÁêÜ„ÄÇ
        
        ÈªòËÆ§Ë°å‰∏∫:
        - Â¶ÇÊûú preds ÊòØÂ≠óÂÖ∏‰∏îÂåÖÂê´ 'logits' ÈîÆÔºåËøîÂõû preds['logits']
        - Â¶ÇÊûú preds ÊòØÂ≠óÂÖ∏‰∏îÂåÖÂê´ 'labels' ÈîÆÔºåËøîÂõû preds['labels']
        - Âê¶ÂàôÂÅáËÆæ preds Â∞±ÊòØ logits/labelsÔºåÁõ¥Êé•ËøîÂõû
        
        Áî®ÈÄî:
        1. Mask3D: ÂèØ‰ª•Âú®ËøôÈáåÂÆûÁé∞ class_logits @ mask_logits
        2. Â§ö‰ªªÂä°Ê®°Âûã: ÂèØ‰ª•ÊèêÂèñÁâπÂÆö‰ªªÂä°ÁöÑËæìÂá∫
        3. ÂêéÂ§ÑÁêÜ: argmax, softmax, sigmoid Á≠â
        
        Args:
            preds: Ê®°ÂûãÁöÑÂéüÂßãËæìÂá∫ (ÂèØ‰ª•ÊòØ Tensor, Dict, Tuple Á≠â)
            
        Returns:
            torch.Tensor: 
                - ÂØπ‰∫éÈ™åËØÅ/ÊµãËØï: ËøîÂõû logits [N, C] Áî®‰∫é metrics ËÆ°ÁÆó
                - ÂØπ‰∫éÈ¢ÑÊµã: ËøîÂõû logits [N, C] Êàñ labels [N] Áî®‰∫é‰øùÂ≠ò
        
        Examples:
            >>> # Á§∫‰æã 1: Ê†áÂáÜËØ≠‰πâÂàÜÂâ≤ (ÈªòËÆ§)
            >>> def postprocess_predictions(self, preds):
            >>>     return preds  # Áõ¥Êé•ËøîÂõû logits
            
            >>> # Á§∫‰æã 2: Mask3D
            >>> def postprocess_predictions(self, preds):
            >>>     class_logits = preds['class_logits']  # [N_queries, C]
            >>>     mask_logits = preds['mask_logits']    # [N_queries, N]
            >>>     point_logits = class_logits.T @ mask_logits  # [C, N]
            >>>     return point_logits.T  # [N, C]
            
            >>> # Á§∫‰æã 3: Áõ¥Êé•ËøîÂõûÊ†áÁ≠æ
            >>> def postprocess_predictions(self, preds):
            >>>     if isinstance(preds, dict) and 'labels' in preds:
            >>>         return preds['labels']  # [N] - Metrics ‰ºöËá™Âä®Ê£ÄÊµã
            >>>     return torch.argmax(preds, dim=-1)  # ÊâãÂä® argmax
        """
        # ÈªòËÆ§ÂÆûÁé∞ÔºöÂ§ÑÁêÜÂ∏∏ËßÅÁöÑÂ≠óÂÖ∏Ê†ºÂºè
        if isinstance(preds, dict):
            if 'logits' in preds:
                return preds['logits']
            elif 'labels' in preds:
                return preds['labels']
            elif 'pred' in preds:
                return preds['pred']
            else:
                # Â¶ÇÊûúÊòØÂ≠óÂÖ∏‰ΩÜÊ≤°ÊúâÊ†áÂáÜÈîÆÔºåËøîÂõûÁ¨¨‰∏Ä‰∏™ÂÄº
                # ËøôÂèØËÉΩÈúÄË¶ÅÂ≠êÁ±ªË¶ÜÁõñ
                return next(iter(preds.values()))
        
        # Â¶ÇÊûú‰∏çÊòØÂ≠óÂÖ∏ÔºåÂÅáËÆæÂ∞±ÊòØ logits/labels
        return preds
    
    # --- ËÆ≠ÁªÉ (Training) ÈÄªËæë ---
    
    def training_step(self, batch: Dict[str, Any], batch_idx: int):
        """
        ËÆ≠ÁªÉÊ≠•È™§„ÄÇ
        """
        # Á°Æ‰øùÊ®°ÂûãÂú®ËÆ≠ÁªÉÊ®°ÂºèÔºàËß£ÂÜ≥ eval mode Ë≠¶ÂëäÔºâ
        if batch_idx == 0:
            self.train()
        
        # Ë∞ÉËØï‰ø°ÊÅØÔºöËÆ∞ÂΩïËÆ≠ÁªÉÊ≠•Êï∞ÂíåÊï∞ÊçÆÁªüËÆ°
        if batch_idx % 50 == 0 or batch_idx > 160:  # Âú®ÈóÆÈ¢òÂå∫ÂüüÈôÑËøëÊõ¥È¢ëÁπÅËÆ∞ÂΩï
            coord = batch.get('coord', None)
            if coord is not None:
                print(f"\n[Step {self.global_step}] Batch {batch_idx}: "
                      f"points={len(coord)}, "
                      f"coord_range=[{coord.min(0)[0]}, {coord.max(0)[0]}]")
        
        # ÂâçÂêë‰º†Êí≠
        try:
            preds = self(batch)
        except Exception as e:
            # ‰øùÂ≠òÈóÆÈ¢òÊï∞ÊçÆ
            import pickle
            error_data_path = f'error_batch_{batch_idx}_step_{self.global_step}.pkl'
            with open(error_data_path, 'wb') as f:
                pickle.dump({
                    'batch_idx': batch_idx,
                    'global_step': self.global_step,
                    'batch': {k: v.cpu() if isinstance(v, torch.Tensor) else v 
                             for k, v in batch.items()},
                    'error': str(e)
                }, f)
            print(f"\n{'='*80}")
            print(f"[ERROR] Âú® batch_idx={batch_idx}, global_step={self.global_step} Êó∂ÂèëÁîüÈîôËØØ")
            print(f"ÈóÆÈ¢òÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞: {error_data_path}")
            print(f"{'='*80}\n")
            raise
        
        # Loss ËÆ°ÁÆó
        loss_dict = self._calculate_total_loss(preds, batch)
        total_loss = loss_dict["total_loss"]
        
        # ‰øùÂ≠òÊúÄÊñ∞ÁöÑ loss Âà∞Ê®°Âùó‰∏≠Ôºå‰æõ CustomProgressBar Áõ¥Êé•ËØªÂèñ
        # ÈÅøÂÖç PL ÈªòËÆ§ËøõÂ∫¶Êù°ÁöÑÂπ≥ÊªëÂ§ÑÁêÜÂØºËá¥Êï∞ÂÄºÁúãËµ∑Êù•‚ÄúÂç°Ê≠ª‚Äù
        current_loss = total_loss.item()
        self.last_loss = current_loss
        # üî• Âº∫Âà∂Êõ¥Êñ∞ trainer ‰∏äÁöÑÂ±ûÊÄßÔºåÁ°Æ‰øù CustomProgressBar ËÉΩËØªÂèñÂà∞ÊúÄÊñ∞ÂÄº
        if self.trainer is not None:
            self.trainer.live_loss = current_loss
        
        # ËÆ∞ÂΩïÊçüÂ§±
        batch_size = self._get_batch_size(batch)
        for name, loss_value in loss_dict.items():
            # ÊâÄÊúâÊçüÂ§±ÈÉΩÊòæÁ§∫Âú®ËøõÂ∫¶Êù°ÔºåÂêåÊó∂ËÆ∞ÂΩïÂà∞ TensorBoard
            self.log(
                f"{name}_step",
                loss_value,
                on_step=True,
                on_epoch=False,
                prog_bar=True,
                batch_size=batch_size,
            )
            
        # Ë∞ÉËØïÔºöÊØè 100 Ê≠•ÊâìÂç∞‰∏ÄÊ¨° lossÔºåÁ°ÆËÆ§ÊòØÂê¶Âú®ÂèòÂåñ
        if batch_idx % 100 == 0:
            print(f" [Step {self.global_step}] Loss: {total_loss.item():.6f}")
        
        return total_loss

    def on_train_epoch_end(self):
        """
        Âú®ËÆ≠ÁªÉ epoch ÁªìÊùüÊó∂Ë∞ÉÁî®ÔºåÊ∏ÖÁêÜÊòæÂ≠ò‰ª•‰æøÈ™åËØÅ„ÄÇ
        """
        # Âº∫Âà∂Ê∏ÖÁêÜ CUDA ÁºìÂ≠òÔºåÈÅøÂÖçÈ™åËØÅÊó∂ OOM
        if torch.cuda.is_available():
            import gc
            gc.collect()  # Python ÂûÉÂúæÂõûÊî∂
            torch.cuda.empty_cache()  # CUDA ÁºìÂ≠òÊ∏ÖÁêÜ
            torch.cuda.synchronize()  # ÂêåÊ≠• CUDA Êìç‰Ωú
            # ËæìÂá∫ÊòæÂ≠ò‰ΩøÁî®ÊÉÖÂÜµ
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            print(f"\n[Memory] Epoch {self.current_epoch} training end: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB")
            print(f"[Memory] Cleared cache and GC, starting validation...\n")
    
    def on_validation_start(self):
        """
        Âú®È™åËØÅÂºÄÂßãÂâçÂÜçÊ¨°Ê∏ÖÁêÜÊòæÂ≠ò„ÄÇ
        """
        if torch.cuda.is_available():
            import gc
            gc.collect()
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            print(f"[Memory] Validation start: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\n")
    
    def validation_step(self, batch: Dict[str, Any], batch_idx: int):
        # 1. ÂâçÂêë‰º†Êí≠
        preds = self.forward(batch)
        
        # 2. ËÆ°ÁÆóÊçüÂ§±
        loss_dict = self._calculate_total_loss(preds, batch)
        
        # 3. ËÆ∞ÂΩïÊçüÂ§± (PL ‰ºöËá™Âä®Ê∑ªÂä† 'val/' ÂâçÁºÄ)
        batch_size = self._get_batch_size(batch)
        self.log_dict(loss_dict, on_step=False, on_epoch=True, prog_bar=False, batch_size=batch_size)
        
        # 4. ÂêéÂ§ÑÁêÜÈ¢ÑÊµãÁªìÊûú (ÊîØÊåÅ Mask3D Á≠âÂ§çÊùÇËæìÂá∫)
        processed_preds = self.postprocess_predictions(preds)
        
        # 5. Êõ¥Êñ∞ÊåáÊ†á
        # ÊèêÂèñÁõÆÊ†áÊ†áÁ≠æ (ÊîØÊåÅÂ§öÁßçÂëΩÂêçÁ∫¶ÂÆö)
        target = batch.get('class', batch.get('label', batch.get('labels', batch.get('target'))))
        for metric in self.val_metrics.values():
            metric.update(processed_preds, target)

    def on_validation_epoch_end(self):
        # 5. Âú® epoch ÁªìÊùüÊó∂ÔºåËÆ°ÁÆóÂπ∂ËÆ∞ÂΩïÊâÄÊúâÊåáÊ†á
        metric_results = {}
        
        # ‰∏¥Êó∂Â≠òÂÇ®Áî®‰∫éÊâìÂç∞ÁöÑÊåáÊ†á
        print_metrics = {}
        
        for name, metric in self.val_metrics.items():
            val = metric.compute()
            
            # Â§ÑÁêÜËøîÂõûÂ≠óÂÖ∏ÁöÑÊåáÊ†á (Â¶Ç SegmentationMetrics)
            if isinstance(val, dict):
                # ËÆ∞ÂΩïÂà∞ metric_results (Áî®‰∫é log)
                for k, v in val.items():
                    # ËøáÊª§ÊéâÈùûÊ†áÈáèÂÄº (Â¶Ç class_names ÂàóË°®)
                    if isinstance(v, (torch.Tensor, float, int)):
                        # Á°Æ‰øù tensor ÊòØÊ†áÈáè
                        if isinstance(v, torch.Tensor) and v.numel() > 1:
                            continue
                        metric_results[k] = v
                
                # ‰øùÂ≠òÂÆåÊï¥ÁªìÊûúÁî®‰∫éÊâìÂç∞
                print_metrics.update(val)
                
                # Â¶ÇÊûúÂåÖÂê´Ê∑∑Ê∑ÜÁü©ÈòµÁõ∏ÂÖ≥ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåÂ∞ùËØïÊèêÂèñ
                if 'iou_per_class' in val:
                    print_metrics['per_class_iou'] = val['iou_per_class']
                if 'precision_per_class' in val:
                    print_metrics['per_class_precision'] = val['precision_per_class']
                if 'recall_per_class' in val:
                    print_metrics['per_class_recall'] = val['recall_per_class']
                if 'f1_per_class' in val:
                    print_metrics['per_class_f1'] = val['f1_per_class']
                
            else:
                metric_results[name] = val
                print_metrics[name] = val
            
            metric.reset() # ÈáçÁΩÆÊåáÊ†áÁä∂ÊÄÅ
        
        # ËÆ∞ÂΩïÊåáÊ†á (prog_bar=False ‰ª•ÈÅøÂÖçÊ±°ÊüìËøõÂ∫¶Êù°)
        self.log_dict(metric_results, on_step=False, on_epoch=True, prog_bar=False)
        
        # --- ÊâìÂç∞ËØ¶ÁªÜÊåáÊ†á ---
        # Ê£ÄÊü•ÊòØÂê¶Êúâ mIoU ‰ø°ÊÅØ (Êó†ËÆ∫ÊòØÊù•Ëá™ SegmentationMetrics ËøòÊòØÂçïÁã¨ÁöÑ MeanIoU)
        miou_key = 'mean_iou'
        if miou_key in print_metrics:
            try:
                current_miou = float(print_metrics[miou_key])
                
                # Êõ¥Êñ∞ÊúÄ‰Ω≥ mIoU
                if current_miou > self.best_miou:
                    self.best_miou = current_miou
                    self.best_miou_epoch = self.current_epoch
                
                # Ëé∑ÂèñÂÖ∂‰ªñÊåáÊ†á
                overall_acc = print_metrics.get('overall_accuracy', None)
                
                # ÂáÜÂ§áÊØèÁ±ªÊåáÊ†á
                per_class_iou = print_metrics.get('per_class_iou', None)
                per_class_precision = print_metrics.get('per_class_precision', None)
                per_class_recall = print_metrics.get('per_class_recall', None)
                per_class_f1 = print_metrics.get('per_class_f1', None)
                
                # Â¶ÇÊûúÊ≤°ÊúâÁõ¥Êé•Êèê‰æõÊØèÁ±ªÊåáÊ†áÔºåÂ∞ùËØï‰ªéÊóßÁöÑ MeanIoU metric ÂØπË±°‰∏≠Ëé∑Âèñ (ÂÖºÂÆπÊóß‰ª£Á†Å)
                if per_class_iou is None and 'mean_iou' in self.val_metrics:
                    metric = self.val_metrics['mean_iou']
                    if hasattr(metric, 'confusion_matrix'):
                        confmat = metric.confusion_matrix.cpu().numpy()
                        import numpy as np
                        intersection = np.diag(confmat)
                        union = confmat.sum(1) + confmat.sum(0) - np.diag(confmat)
                        per_class_iou = intersection / (union + 1e-10)
                        per_class_precision = intersection / (confmat.sum(0) + 1e-10)
                        per_class_recall = intersection / (confmat.sum(1) + 1e-10)
                        per_class_f1 = 2 * per_class_precision * per_class_recall / (per_class_precision + per_class_recall + 1e-10)

                # ËæìÂá∫Ê†áÈ¢òÂíåÊÄª‰ΩìÊåáÊ†á
                print(f"\n{'='*100}")
                print(f"Validation Epoch {self.current_epoch} - Metrics")
                print(f"{'='*100}")
                if overall_acc is not None:
                    print(f"Overall Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)")
                print(f"Mean IoU (current): {current_miou:.4f}")
                print(f"Mean IoU (best)   : {self.best_miou:.4f} (Epoch {self.best_miou_epoch})")
                if current_miou > self.best_miou - 1e-6:  # ÂΩìÂâçÊòØÊúÄ‰Ω≥
                    print(f"üéâ New best mIoU achieved!")
                print(f"{'='*100}")
                
                # ËæìÂá∫ÊØè‰∏™Á±ªÂà´ÁöÑËØ¶ÁªÜÊåáÊ†á
                if per_class_iou is not None:
                    print(f"  {'Class':15s}  {'IoU':>8s}  {'Precision':>10s}  {'Recall':>8s}  {'F1-Score':>10s}")
                    print(f"  {'-'*15}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
                    
                    # Ëé∑ÂèñÁ±ªÂà´Âêç
                    class_names = print_metrics.get('class_names', None)
                    if class_names is None:
                        class_names = self.hparams.get('class_names', None) if hasattr(self, 'hparams') else None
                    
                    import numpy as np
                    # Á°Æ‰øùÊòØ numpy Êï∞ÁªÑ
                    if isinstance(per_class_iou, torch.Tensor): per_class_iou = per_class_iou.cpu().numpy()
                    if isinstance(per_class_precision, torch.Tensor): per_class_precision = per_class_precision.cpu().numpy()
                    if isinstance(per_class_recall, torch.Tensor): per_class_recall = per_class_recall.cpu().numpy()
                    if isinstance(per_class_f1, torch.Tensor): per_class_f1 = per_class_f1.cpu().numpy()

                    num_classes = len(per_class_iou)
                    for i in range(num_classes):
                        c_name = class_names[i] if class_names and i < len(class_names) else f"Class {i}"
                        print(f"  {c_name:15s}  {per_class_iou[i]:8.4f}  {per_class_precision[i]:10.4f}  "
                              f"{per_class_recall[i]:8.4f}  {per_class_f1[i]:10.4f}")
                    
                    # ËÆ°ÁÆóÂπ≥ÂùáÊåáÊ†á
                    mean_precision = np.nanmean(per_class_precision)
                    mean_recall = np.nanmean(per_class_recall)
                    mean_f1 = np.nanmean(per_class_f1)
                    
                    print(f"  {'-'*15}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
                    print(f"  {'Mean':15s}  {current_miou:8.4f}  {mean_precision:10.4f}  "
                          f"{mean_recall:8.4f}  {mean_f1:10.4f}")
                print(f"{'='*100}\n")
            except Exception as e:
                print(f"Warning: Could not print detailed metrics: {e}")
                import traceback
                traceback.print_exc()

    # --- ÊµãËØï (Test) ÈÄªËæë ---
    
    def test_step(self, batch: Dict[str, Any], batch_idx: int):
        """
        ÊµãËØïÊ≠•È™§ÔºöËÆ°ÁÆóÊçüÂ§±ÂíåÊåáÊ†á
        """
        # ÈÄªËæë‰∏é validation_step Áõ∏Âêå
        preds = self.forward(batch)
        loss_dict = self._calculate_total_loss(preds, batch)
        batch_size = self._get_batch_size(batch)
        self.log_dict(loss_dict, on_step=False, on_epoch=True, batch_size=batch_size)
        
        # ÂêéÂ§ÑÁêÜÈ¢ÑÊµãÁªìÊûú
        processed_preds = self.postprocess_predictions(preds)
        
        # ÊèêÂèñÁõÆÊ†áÊ†áÁ≠æ (ÊîØÊåÅÂ§öÁßçÂëΩÂêçÁ∫¶ÂÆö)
        target = batch.get('class', batch.get('label', batch.get('labels', batch.get('target'))))
        for metric in self.test_metrics.values():
            metric.update(processed_preds, target)

    def on_test_epoch_end(self):
        # Âú® epoch ÁªìÊùüÊó∂ÔºåËÆ°ÁÆóÂπ∂ËÆ∞ÂΩïÊâÄÊúâÊåáÊ†á
        metric_results = {}
        print_metrics = {}
        
        for name, metric in self.test_metrics.items():
            val = metric.compute()
            
            if isinstance(val, dict):
                for k, v in val.items():
                    if isinstance(v, (torch.Tensor, float, int)):
                        # Á°Æ‰øù tensor ÊòØÊ†áÈáè
                        if isinstance(v, torch.Tensor) and v.numel() > 1:
                            continue
                        metric_results[k] = v
                
                print_metrics.update(val)
                
                if 'iou_per_class' in val:
                    print_metrics['per_class_iou'] = val['iou_per_class']
                if 'precision_per_class' in val:
                    print_metrics['per_class_precision'] = val['precision_per_class']
                if 'recall_per_class' in val:
                    print_metrics['per_class_recall'] = val['recall_per_class']
                if 'f1_per_class' in val:
                    print_metrics['per_class_f1'] = val['f1_per_class']
            else:
                metric_results[name] = val
                print_metrics[name] = val
            
            metric.reset()
            
        self.log_dict(metric_results, on_step=False, on_epoch=True)
        
        # --- ÊâìÂç∞ËØ¶ÁªÜÊåáÊ†á ---
        miou_key = 'mean_iou'
        if miou_key in print_metrics:
            try:
                current_miou = float(print_metrics[miou_key])
                overall_acc = print_metrics.get('overall_accuracy', None)
                
                per_class_iou = print_metrics.get('per_class_iou', None)
                per_class_precision = print_metrics.get('per_class_precision', None)
                per_class_recall = print_metrics.get('per_class_recall', None)
                per_class_f1 = print_metrics.get('per_class_f1', None)
                
                # ÂÖºÂÆπÊóß‰ª£Á†Å
                if per_class_iou is None and 'mean_iou' in self.test_metrics:
                    metric = self.test_metrics['mean_iou']
                    if hasattr(metric, 'confusion_matrix'):
                        confmat = metric.confusion_matrix.cpu().numpy()
                        import numpy as np
                        intersection = np.diag(confmat)
                        union = confmat.sum(1) + confmat.sum(0) - np.diag(confmat)
                        per_class_iou = intersection / (union + 1e-10)
                        per_class_precision = intersection / (confmat.sum(0) + 1e-10)
                        per_class_recall = intersection / (confmat.sum(1) + 1e-10)
                        per_class_f1 = 2 * per_class_precision * per_class_recall / (per_class_precision + per_class_recall + 1e-10)

                print(f"\n{'='*100}")
                print(f"Test Results - Metrics")
                print(f"{'='*100}")
                if overall_acc is not None:
                    print(f"Overall Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)")
                print(f"Mean IoU: {current_miou:.4f}")
                print(f"{'='*100}")
                
                if per_class_iou is not None:
                    print(f"  {'Class':15s}  {'IoU':>8s}  {'Precision':>10s}  {'Recall':>8s}  {'F1-Score':>10s}")
                    print(f"  {'-'*15}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
                    
                    class_names = print_metrics.get('class_names', None)
                    if class_names is None:
                        class_names = self.hparams.get('class_names', None) if hasattr(self, 'hparams') else None
                    
                    import numpy as np
                    if isinstance(per_class_iou, torch.Tensor): per_class_iou = per_class_iou.cpu().numpy()
                    if isinstance(per_class_precision, torch.Tensor): per_class_precision = per_class_precision.cpu().numpy()
                    if isinstance(per_class_recall, torch.Tensor): per_class_recall = per_class_recall.cpu().numpy()
                    if isinstance(per_class_f1, torch.Tensor): per_class_f1 = per_class_f1.cpu().numpy()

                    num_classes = len(per_class_iou)
                    for i in range(num_classes):
                        c_name = class_names[i] if class_names and i < len(class_names) else f"Class {i}"
                        print(f"  {c_name:15s}  {per_class_iou[i]:8.4f}  {per_class_precision[i]:10.4f}  "
                              f"{per_class_recall[i]:8.4f}  {per_class_f1[i]:10.4f}")
                    
                    mean_precision = np.nanmean(per_class_precision)
                    mean_recall = np.nanmean(per_class_recall)
                    mean_f1 = np.nanmean(per_class_f1)
                    
                    print(f"  {'-'*15}  {'-'*8}  {'-'*10}  {'-'*8}  {'-'*10}")
                    print(f"  {'Mean':15s}  {current_miou:8.4f}  {mean_precision:10.4f}  {mean_recall:8.4f}  {mean_f1:10.4f}")
                print(f"{'='*100}\n")
            except Exception as e:
                print(f"Ë≠¶Âëä: Êó†Ê≥ïÊâìÂç∞ËØ¶ÁªÜÊåáÊ†á: {e}")