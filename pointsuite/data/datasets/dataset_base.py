import os
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union
from abc import ABC, abstractmethod

from torch.utils.data import Dataset
from collections.abc import Sequence
from ..transforms import Compose
from ...utils.mapping import ClassMapping, ClassMappingInput, normalize_class_mapping
from ...utils.logger import log_info, Colors


class DatasetBase(Dataset, ABC):
    """
    ç‚¹äº‘æ•°æ®çš„æŠ½è±¡åŸºç¡€æ•°æ®é›†ç±»
    
    è¿™æ˜¯æ‰€æœ‰æ•°æ®é›†å®ç°çš„åŸºç¡€
    å­ç±»åº”å®ç°æŠ½è±¡æ–¹æ³•æ¥å¤„ç†ç‰¹å®šçš„æ•°æ®æ ¼å¼
    """

    VALID_ASSETS = [
        "coord",  # XYZ åæ ‡ï¼ˆå¿…éœ€ï¼‰
        "color",  # RGB é¢œè‰²
        "normal",  # æ³•å‘é‡
        "intensity",  # å¼ºåº¦
        "echo",  # å›æ³¢ä¿¡æ¯
        "h_norm",  # å½’ä¸€åŒ–é«˜ç¨‹
        "class",  # åˆ†ç±»æ ‡ç­¾
    ]

    def __init__(
            self,
            data_root,
            split: str = 'train',
            assets: Optional[List[str]] = None,
            transform: Optional[List] = None,
            ignore_label: int = -1,
            loop: int = 1,
            class_mapping: ClassMappingInput = None,
            **kwargs
    ):
        """
        åˆå§‹åŒ–åŸºç¡€æ•°æ®é›†
        
        å‚æ•°ï¼š
            data_root: æ ¹ç›®å½•ã€å•ä¸ªæ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            split: æ•°æ®é›†åˆ’åˆ†ï¼ˆ'train'ã€'val'ã€'test'ï¼‰
            assets: è¦åŠ è½½çš„æ•°æ®å±æ€§åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼ï¼‰
            transform: è¦åº”ç”¨çš„æ•°æ®å˜æ¢
            ignore_label: åœ¨è®­ç»ƒ/è¯„ä¼°ä¸­å¿½ç•¥çš„æ ‡ç­¾
            loop: éå†æ•°æ®é›†çš„æ¬¡æ•°ï¼ˆç”¨äºè®­ç»ƒå¢å¼ºï¼‰
            class_mapping: ç±»åˆ«æ ‡ç­¾æ˜ å°„é…ç½®ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
                - None: ä¸åšæ˜ å°„ï¼Œä½¿ç”¨åŸå§‹æ ‡ç­¾
                - Dict[int, int]: æ˜¾å¼æ˜ å°„ {åŸå§‹ID: æ–°ID}
                - List[int]: åŸå§‹ç±»åˆ«IDåˆ—è¡¨ï¼Œè‡ªåŠ¨æ˜ å°„ä¸º [0, 1, 2, ...]
                ç¤ºä¾‹ï¼š{1: 0, 2: 1, 6: 2} æˆ– [1, 2, 6]ï¼ˆä¸¤è€…ç­‰ä»·ï¼‰
            **kwargs: å­ç±»çš„å…¶ä»–å‚æ•°
        """
        super().__init__()
        
        # å¤„ç†ä¸åŒçš„ data_root ç±»å‹
        if isinstance(data_root, (list, tuple)):
            # è·¯å¾„åˆ—è¡¨
            self.data_root = data_root
        else:
            # å•ä¸ªè·¯å¾„
            self.data_root = Path(data_root)
        
        self.split = split
        self.assets = assets if assets is not None else self.VALID_ASSETS.copy()
        self.transform = Compose(transform) if transform is not None else None
        self.ignore_label = ignore_label
        self.loop = loop  # æ”¯æŒæ‰€æœ‰ split çš„ loopï¼ˆTest-Time Augmentationï¼‰
        
        # ğŸ”¥ æ ‡å‡†åŒ–ç±»åˆ«æ˜ å°„ï¼šæ”¯æŒ Dictã€List æˆ– None
        self.class_mapping = normalize_class_mapping(class_mapping, ignore_label)
        # ä¿å­˜ ClassMapping å®ä¾‹ä»¥ä¾¿ä½¿ç”¨å…¶æ–¹æ³•
        self._class_mapper = ClassMapping(class_mapping, ignore_label)
        
        # ç¼“å­˜ç±»åˆ«æƒé‡
        self._class_weights = None
        self._class_weights_dict = None
        
        # éªŒè¯æ•°æ®æ ¹ç›®å½•ï¼ˆå¯¹äºåˆ—è¡¨ç±»å‹è·³è¿‡éªŒè¯ï¼Œç”±å­ç±»å¤„ç†ï¼‰
        if not isinstance(self.data_root, (list, tuple)) and not self.data_root.exists():
            raise ValueError(f"æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {self.data_root}")
        
        # åŠ è½½æ•°æ®åˆ—è¡¨ï¼ˆç”±å­ç±»å®ç°ï¼‰
        self.data_list = self._load_data_list()
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        self._print_init_info()
    
    def _print_init_info(self):
        """æ‰“å°æ•°æ®é›†åˆå§‹åŒ–ä¿¡æ¯"""
        log_info(f"{Colors.BOLD}{self.__class__.__name__}{Colors.RESET} ({Colors.SUCCESS}{self.split}{Colors.RESET}) å·²åˆå§‹åŒ–: "
                 f"æ ·æœ¬æ•°={Colors.INFO}{len(self.data_list)}{Colors.RESET}, "
                 f"å¾ªç¯={Colors.INFO}{self.loop}{Colors.RESET}")
    
    @abstractmethod
    def _load_data_list(self) -> List[Dict[str, Any]]:
        """
        åŠ è½½æ‰€æœ‰æ•°æ®æ ·æœ¬çš„åˆ—è¡¨
        å¿…é¡»ç”±å­ç±»å®ç°
        
        è¿”å›ï¼š
            åŒ…å«æ ·æœ¬ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° _load_data_list() æ–¹æ³•")
    
    @abstractmethod
    def _load_data(self, idx: int) -> Dict[str, Any]:
        """
        åŠ è½½ç»™å®šç´¢å¼•çš„ç‚¹äº‘æ•°æ®
        å¿…é¡»ç”±å­ç±»å®ç°
        
        å‚æ•°ï¼š
            idx: æ•°æ®ç´¢å¼•
            
        è¿”å›ï¼š
            åŒ…å«åŠ è½½æ•°æ®çš„å­—å…¸ï¼ˆcoordã€labels ç­‰ï¼‰
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° _load_data() æ–¹æ³•")
    
    def __len__(self) -> int:
        """è¿”å›è€ƒè™‘å¾ªç¯å› å­çš„æ•°æ®é›†é•¿åº¦"""
        return len(self.data_list) * self.loop
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        åŠ è½½å¹¶è¿”å›ä¸€ä¸ªæ•°æ®æ ·æœ¬
        
        å‚æ•°ï¼š
            idx: æ ·æœ¬ç´¢å¼•
            
        è¿”å›ï¼š
            åŒ…å«ç‚¹äº‘æ•°æ®å’Œæ ‡ç­¾çš„å­—å…¸
        """
        # å¤„ç†å¾ªç¯
        data_idx = idx % len(self.data_list)
        
        # åŠ è½½æ•°æ®ï¼ˆç”±å­ç±»å®ç°ï¼‰
        data_dict = self._load_data(data_idx)
        
        # åº”ç”¨å˜æ¢
        if self.transform is not None:
            data_dict = self.transform(data_dict)
        
        return data_dict
    
    def get_sample_info(self, idx: int) -> Dict[str, Any]:
        """
        è·å–æ ·æœ¬ä¿¡æ¯è€Œä¸åŠ è½½æ•°æ®
        
        å‚æ•°ï¼š
            idx: æ ·æœ¬ç´¢å¼•
            
        è¿”å›ï¼š
            æ ·æœ¬ä¿¡æ¯å­—å…¸
        """
        data_idx = idx % len(self.data_list)
        return self.data_list[data_idx]
    
    def get_class_distribution(self) -> Optional[Dict[int, int]]:
        """
        è·å–æ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒï¼ˆæ¯ä¸ªç±»åˆ«çš„æ ·æœ¬ç‚¹æ•°ï¼‰
        
        å­ç±»åº”é‡å†™æ­¤æ–¹æ³•ä»¥æä¾›ç‰¹å®šæ ¼å¼çš„ç±»åˆ«ç»Ÿè®¡
        
        è¿”å›ï¼š
            ç±»åˆ«åˆ†å¸ƒå­—å…¸ {class_id: count}ï¼Œå¦‚æœä¸æ”¯æŒåˆ™è¿”å› None
        """
        return None
    
    def get_sample_weights(self, class_weights: Optional[Dict[int, float]] = None) -> Optional[np.ndarray]:
        """
        è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æƒé‡ï¼ˆç”¨äº WeightedRandomSamplerï¼‰
        
        æ ·æœ¬æƒé‡åŸºäºå…¶åŒ…å«çš„ç±»åˆ«æƒé‡ä¹‹å’Œï¼Œè¿™æ ·ï¼š
        - åŒ…å«ç¨€æœ‰ç±»åˆ«çš„æ ·æœ¬è·å¾—æ›´é«˜æƒé‡
        - åŒ…å«å¤šä¸ªç±»åˆ«çš„æ ·æœ¬è·å¾—æ›´é«˜æƒé‡
        
        å‚æ•°ï¼š
            class_weights: ç±»åˆ«æƒé‡å­—å…¸ {class_id: weight}
                          å¦‚æœä¸º Noneï¼Œåˆ™è¿”å› Noneï¼ˆä¸æ”¯æŒåŠ æƒé‡‡æ ·ï¼‰
        
        è¿”å›ï¼š
            æ ·æœ¬æƒé‡æ•°ç»„ [num_samples]ï¼Œå¦‚æœä¸æ”¯æŒåˆ™è¿”å› None
        """
        return None
    
    def compute_class_weights(
        self,
        method: str = 'inverse',
        smooth: float = 1.0,
        normalize: bool = True
    ) -> Optional[Dict[int, float]]:
        """
        ä»æ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒè®¡ç®—ç±»åˆ«æƒé‡
        
        è¿™æ˜¯ä¸€ä¸ªä¾¿æ·æ–¹æ³•ï¼ŒåŸºäº get_class_distribution() è‡ªåŠ¨è®¡ç®—æƒé‡
        å­ç±»é€šå¸¸ä¸éœ€è¦é‡å†™æ­¤æ–¹æ³•ï¼Œåªéœ€å®ç° get_class_distribution()
        
        å‚æ•°ï¼š
            method: æƒé‡è®¡ç®—æ–¹æ³•
                   - 'inverse': 1 / countï¼ˆåæ¯”ä¾‹ï¼‰
                   - 'sqrt_inverse': 1 / sqrt(count)ï¼ˆå¹³æ–¹æ ¹åæ¯”ä¾‹ï¼‰
                   - 'log_inverse': 1 / log(count + 1)ï¼ˆå¯¹æ•°åæ¯”ä¾‹ï¼‰
                   - 'effective_num': Effective Number of Samples (ENS) æ–¹æ³•
            smooth: å¹³æ»‘å‚æ•°ï¼Œé¿å…æƒé‡è¿‡å¤§ï¼ˆåŠ åˆ°åˆ†æ¯ä¸Šï¼‰
            normalize: æ˜¯å¦å½’ä¸€åŒ–æƒé‡ä½¿å…¶å’Œä¸º 1
        
        è¿”å›ï¼š
            ç±»åˆ«æƒé‡å­—å…¸ {class_id: weight}ï¼Œå¦‚æœä¸æ”¯æŒåˆ™è¿”å› None
        """
        class_distribution = self.get_class_distribution()
        if class_distribution is None or len(class_distribution) == 0:
            return None
        
        # è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼
        num_classes = max(class_distribution.keys()) + 1
        counts = np.zeros(num_classes, dtype=np.float64)
        for class_id, count in class_distribution.items():
            counts[class_id] = count
        
        # å¤„ç†ç©ºç±»åˆ«
        empty_classes = np.where(counts == 0)[0]
        if len(empty_classes) > 0:
            counts[empty_classes] = 1.0
        
        # è®¡ç®—æƒé‡
        if method == 'inverse':
            weights = 1.0 / (counts + smooth)
        elif method == 'sqrt_inverse':
            weights = 1.0 / np.sqrt(counts + smooth)
        elif method == 'log_inverse':
            weights = 1.0 / np.log(counts + smooth + 1)
        elif method == 'effective_num':
            beta = 0.9999
            effective_num = 1.0 - np.power(beta, counts)
            weights = (1.0 - beta) / (effective_num + 1e-8)
        else:
            raise ValueError(f"æœªçŸ¥çš„æƒé‡è®¡ç®—æ–¹æ³•: {method}")
        
        # å½’ä¸€åŒ–ï¼šä½¿æœ€å°æƒé‡ä¸º1ï¼Œè€Œä¸æ˜¯æ€»å’Œä¸º1
        # è¿™æ ·æƒé‡æ›´ç›´è§‚ï¼šç¨€æœ‰ç±»åˆ«æƒé‡é«˜ï¼Œå¸¸è§ç±»åˆ«æƒé‡çº¦ä¸º1
        if normalize:
            weights = weights / weights.min()  # æœ€å°æƒé‡å˜ä¸º1
        
        # è½¬æ¢ä¸ºå­—å…¸
        return {i: float(weights[i]) for i in range(num_classes) if counts[i] > 0}

    @property
    def class_weights(self):
        """
        è·å–ç±»åˆ«æƒé‡ Tensor (ç”¨äº Loss)
        ä½¿ç”¨ sqrt_inverse æ–¹æ³•è®¡ç®—ï¼Œæ¯” log_inverse æœ‰æ›´å¤§çš„æƒé‡å·®å¼‚
        """
        if self._class_weights is None:
            weights_dict = self.compute_class_weights(method='sqrt_inverse')
            if weights_dict is None:
                return None
            
            import torch
            # å‡è®¾æœ€å¤§ç±»åˆ«ID
            num_classes = max(weights_dict.keys()) + 1
            weights = torch.ones(num_classes, dtype=torch.float32)
            for cls_idx, w in weights_dict.items():
                weights[cls_idx] = w
            self._class_weights = weights
            
        return self._class_weights

    @property
    def class_weights_dict(self):
        """
        è·å–ç±»åˆ«æƒé‡å­—å…¸
        """
        if self._class_weights_dict is None:
             self._class_weights_dict = self.compute_class_weights(method='sqrt_inverse')
        return self._class_weights_dict





