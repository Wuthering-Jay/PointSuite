"""
è¯­ä¹‰åˆ†å‰²å¼•æ“

åŸºäº BaseEngine å®ç°è¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬:
- BinPklDataModule åˆ›å»º
- SemanticSegmentationTask åˆ›å»º
- è¯­ä¹‰åˆ†å‰²ç‰¹å®šçš„å›è°ƒ (SemanticPredictLasWriter)
"""

import os
from typing import Any, Dict, List, Optional, Union
from pathlib import Path

import pytorch_lightning as pl
from pytorch_lightning.callbacks import Callback

from .base import BaseEngine
from ..data import BinPklDataModule
from ..tasks import SemanticSegmentationTask
from ..utils.callbacks import SemanticPredictLasWriter, AutoEmptyCacheCallback, TextLoggingCallback
from ..utils.logger import Colors, print_config


class SemanticSegmentationEngine(BaseEngine):
    """
    è¯­ä¹‰åˆ†å‰²å¼•æ“
    
    å¤„ç†è¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„å®Œæ•´æµç¨‹:
    - æ•°æ®åŠ è½½ (BinPklDataModule)
    - æ¨¡å‹è®­ç»ƒ (SemanticSegmentationTask)
    - é¢„æµ‹ç»“æœä¿å­˜ (SemanticPredictLasWriter)
    
    ä½¿ç”¨ç¤ºä¾‹:
        # æ–¹å¼1: YAML é…ç½®
        >>> engine = SemanticSegmentationEngine.from_config(
        ...     'configs/experiments/dales_semseg.yaml'
        ... )
        >>> engine.run()
        
        # æ–¹å¼2: Python é…ç½®
        >>> engine = SemanticSegmentationEngine(config={
        ...     'run': {'mode': 'train', 'output_dir': './outputs'},
        ...     'data': {...},
        ...     'model': {...}
        ... })
        >>> engine.run()
        
        # æ–¹å¼3: å®Œå…¨ç¼–ç¨‹å¼
        >>> datamodule = BinPklDataModule(...)
        >>> task = SemanticSegmentationTask(...)
        >>> engine = SemanticSegmentationEngine(
        ...     datamodule=datamodule,
        ...     task=task
        ... )
        >>> engine.train().test().predict()
    """
    
    TASK_TYPE = "è¯­ä¹‰åˆ†å‰²"
    
    def _create_datamodule(self) -> pl.LightningDataModule:
        """
        åˆ›å»º BinPklDataModule
        
        Returns:
            BinPklDataModule å®ä¾‹
        """
        data_config = self.config.data.copy()
        
        # å¤„ç†å˜æ¢é…ç½®
        train_transforms = data_config.pop('train_transforms', None)
        val_transforms = data_config.pop('val_transforms', None)
        test_transforms = data_config.pop('test_transforms', None)
        predict_transforms = data_config.pop('predict_transforms', None)
        
        # å®ä¾‹åŒ–å˜æ¢
        if train_transforms and isinstance(train_transforms[0], dict):
            train_transforms = self._instantiate_transforms(train_transforms)
        if val_transforms and isinstance(val_transforms[0], dict):
            val_transforms = self._instantiate_transforms(val_transforms)
        if test_transforms and isinstance(test_transforms[0], dict):
            test_transforms = self._instantiate_transforms(test_transforms)
        if predict_transforms and isinstance(predict_transforms[0], dict):
            predict_transforms = self._instantiate_transforms(predict_transforms)
        
        # ç§»é™¤ä¸å±äº DataModule çš„é…ç½®
        data_config.pop('num_classes', None)  # è¿™æ˜¯æ´¾ç”Ÿå±æ€§
        
        # æ‰“å°æ•°æ®é…ç½®
        print_config({
            'è®­ç»ƒæ•°æ®': data_config.get('train_data', 'N/A'),
            'éªŒè¯æ•°æ®': data_config.get('val_data', 'N/A'),
            'æµ‹è¯•æ•°æ®': data_config.get('test_data', 'N/A'),
            'é¢„æµ‹æ•°æ®': data_config.get('predict_data', 'N/A'),
        }, "ğŸ“ æ•°æ®è·¯å¾„")
        
        print_config({
            'ç±»åˆ«æ•°é‡': len(data_config.get('class_mapping', [])),
            'ç±»åˆ«åç§°': ', '.join(data_config.get('class_names', [])),
            'å¿½ç•¥æ ‡ç­¾': data_config.get('ignore_label', -1),
        }, "ğŸ·ï¸  ç±»åˆ«é…ç½®")
        
        print_config({
            'é‡‡æ ·æ¨¡å¼': data_config.get('mode', 'grid'),
            'æ‰¹æ¬¡å¤§å°': data_config.get('batch_size', 4),
            'æœ€å¤§ç‚¹æ•°(è®­ç»ƒ)': f"{data_config.get('max_points', 100000):,}",
            'æœ€å¤§ç‚¹æ•°(æ¨ç†)': f"{data_config.get('max_points_inference', 100000):,}",
            'Workers': data_config.get('num_workers', 4),
        }, "âš™ï¸  æ•°æ®åŠ è½½é…ç½®")
        
        datamodule = BinPklDataModule(
            train_transforms=train_transforms,
            val_transforms=val_transforms,
            test_transforms=test_transforms,
            predict_transforms=predict_transforms,
            **data_config
        )
        
        return datamodule
    
    def _create_task(self) -> pl.LightningModule:
        """
        åˆ›å»º SemanticSegmentationTask
        
        Returns:
            SemanticSegmentationTask å®ä¾‹
        """
        model_config = self.config.model.copy()
        task_config = self.config.task.copy() if self.config.task else {}
        
        # ä»é…ç½®ä¸­è·å–æŸå¤±å‡½æ•°å’ŒæŒ‡æ ‡é…ç½®
        loss_configs = self.config._raw.get('losses', [])
        metric_configs = self.config._raw.get('metrics', [])
        
        # ä» data é…ç½®è·å–ç±»åˆ«ä¿¡æ¯
        data_config = self.config.data
        class_mapping = data_config.get('class_mapping')
        class_names = data_config.get('class_names')
        ignore_label = data_config.get('ignore_label', -1)
        
        # å¤„ç†æŸå¤±å‡½æ•°ä¸­çš„ç±»åˆ«æƒé‡
        if loss_configs and hasattr(self._datamodule, 'train_dataset'):
            for loss_cfg in loss_configs:
                init_args = loss_cfg.get('init_args', {})
                # å¦‚æœéœ€è¦ç±»åˆ«æƒé‡ä½†æœªæŒ‡å®šï¼Œä» datamodule è·å–
                if 'weight' not in init_args and hasattr(self._datamodule.train_dataset, 'class_weights'):
                    init_args['weight'] = self._datamodule.train_dataset.class_weights
        
        # è·å– task åˆå§‹åŒ–å‚æ•°
        task_init_args = task_config.get('init_args', {})
        learning_rate = task_init_args.get('learning_rate', 1e-3)
        
        # æ‰“å°æ¨¡å‹é…ç½®
        backbone_name = model_config.get('backbone', {}).get('class_path', 'Unknown').split('.')[-1]
        head_name = model_config.get('head', {}).get('class_path', 'Unknown').split('.')[-1]
        in_channels = model_config.get('backbone', {}).get('init_args', {}).get('in_channels', 'Unknown')
        
        print(f"  {Colors.DIM}â”œâ”€{Colors.RESET} Backbone: {Colors.GREEN}{backbone_name}{Colors.RESET}")
        print(f"  {Colors.DIM}â”œâ”€{Colors.RESET} Head: {Colors.GREEN}{head_name}{Colors.RESET}")
        print(f"  {Colors.DIM}â””â”€{Colors.RESET} è¾“å…¥é€šé“: {Colors.YELLOW}{in_channels}{Colors.RESET}")
        
        task = SemanticSegmentationTask(
            model_config=model_config,
            learning_rate=learning_rate,
            class_mapping=class_mapping,
            class_names=class_names,
            ignore_label=ignore_label,
            loss_configs=loss_configs,
            metric_configs=metric_configs,
        )
        
        return task
    
    def _get_default_callbacks(self) -> List[Callback]:
        """
        è·å–è¯­ä¹‰åˆ†å‰²ç‰¹å®šçš„å›è°ƒ
        
        Returns:
            å›è°ƒåˆ—è¡¨
        """
        callbacks = []
        callback_config = self.config._raw.get('callbacks', {})
        
        # SemanticPredictLasWriter
        if 'predict_writer' in callback_config:
            writer_cfg = callback_config['predict_writer']
            callbacks.append(self._instantiate_class(writer_cfg))
        else:
            # é»˜è®¤é¢„æµ‹å†™å…¥å™¨
            callbacks.append(SemanticPredictLasWriter(
                output_dir=os.path.join(self.config.output_dir, 'predictions'),
                save_logits=False,
                auto_infer_reverse_mapping=True
            ))
        
        # TextLoggingCallback
        callbacks.append(TextLoggingCallback(log_interval=10))
        
        # AutoEmptyCacheCallback
        callbacks.append(AutoEmptyCacheCallback(
            slowdown_threshold=3.0,
            absolute_threshold=1.5,
            clear_interval=0,
            warmup_steps=10,
            verbose=True
        ))
        
        return callbacks
    
    def _print_config(self) -> None:
        """æ‰“å°è¯­ä¹‰åˆ†å‰²é…ç½®"""
        from ..utils.logger import print_header
        print_header("DALES è¯­ä¹‰åˆ†å‰²è®­ç»ƒ", "ğŸ¯")
        
        print_config({
            'è¿è¡Œæ¨¡å¼': self.config.mode,
            'éšæœºç§å­': self.config.seed,
            'è¾“å‡ºç›®å½•': self.config.output_dir,
            'Checkpoint': self.config.checkpoint_path or 'N/A',
        }, "âš™ï¸  è¿è¡Œé…ç½®")
