import torch
import torch.nn as nn
import einops
import pointops
from torch_geometric.nn.pool import voxel_grid
from torch_scatter import segment_csr
from pointsuite.models.utils import offset2batch, batch2offset

# â€”â€”â€”â€” Normalization å±‚ â€”â€”â€”â€”
class PointBatchNorm(nn.Module):
    """
    Batch Normalization for Point Clouds data in shape of [B*N, C], [B*N, L, C]
    å¯¹å½¢çŠ¶ä¸º[n, c], [n, l, c]çš„ç‚¹äº‘æ•°æ®è¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–
    """

    def __init__(self, embed_channels):
        super().__init__()
        self.norm = nn.BatchNorm1d(embed_channels)

    def forward(self, input: torch.Tensor) -> torch.Tensor:
        if input.dim() == 3:
            return (
                self.norm(input.transpose(1, 2).contiguous())
                .transpose(1, 2)
                .contiguous()
            )
        elif input.dim() == 2:
            return self.norm(input)
        else:
            raise NotImplementedError


class PointLayerNorm(nn.Module):
    """
    Layer Normalization for Point Clouds data in shape of [B*N, C], [B*N, L, C]
    å¯¹å½¢çŠ¶ä¸º[n, c], [n, l, c]çš„ç‚¹äº‘æ•°æ®è¿›è¡Œå±‚å½’ä¸€åŒ–
    """
    def __init__(self, embed_channels):
        super().__init__()
        self.norm = nn.LayerNorm(embed_channels)

    def forward(self, input: torch.Tensor) -> torch.Tensor:
        if input.dim() == 3:
            return self.norm(input)
        elif input.dim() == 2:
            return self.norm(input)
        else:
            raise NotImplementedError
        

# â€”â€”â€”â€” å±€éƒ¨ç‰¹å¾èšåˆå±‚ â€”â€”â€”â€”
class GroupedVectorAttention(nn.Module):
    """
    åˆ†ç»„å‘é‡æ³¨æ„åŠ›æœºåˆ¶
    Args:
        embed_channesl: è¾“å…¥è¾“å‡ºç»´åº¦
        groups: åˆ†ç»„æ•°é‡
        attn_drop_rate: dropæ¯”ä¾‹
        qkv_bias: æ— ç”¨
        pe_multiplier: ä½ç½®ç¼–ç ä¹˜æ€§å› å­
        pe_bias: ä½ç½®ç¼–ç åç½®å› å­
        norm_layer: å½’ä¸€åŒ–å±‚ç±»å‹
    """
    def __init__(
        self,
        embed_channels,
        groups,
        attn_drop_rate=0.0,
        qkv_bias=True,
        pe_multiplier=False,
        pe_bias=True,
        norm_layer=PointLayerNorm,
    ):
        super(GroupedVectorAttention, self).__init__()
        self.embed_channels = embed_channels
        self.groups = groups
        assert embed_channels % groups == 0
        self.attn_drop_rate = attn_drop_rate
        self.qkv_bias = qkv_bias
        self.pe_multiplier = pe_multiplier
        self.pe_bias = pe_bias
        self.norm_layer = norm_layer

        self.linear_q = nn.Sequential(
            nn.Linear(embed_channels, embed_channels, bias=qkv_bias),
            self.norm_layer(embed_channels),
            nn.ReLU(inplace=True),
        )
        self.linear_k = nn.Sequential(
            nn.Linear(embed_channels, embed_channels, bias=qkv_bias),
            self.norm_layer(embed_channels),
            nn.ReLU(inplace=True),
        )

        self.linear_v = nn.Linear(embed_channels, embed_channels, bias=qkv_bias)

        if self.pe_multiplier:
            self.linear_p_multiplier = nn.Sequential(
                nn.Linear(3, embed_channels),
                self.norm_layer(embed_channels),
                nn.ReLU(inplace=True),
                nn.Linear(embed_channels, embed_channels),
            )
        if self.pe_bias:
            self.linear_p_bias = nn.Sequential(
                nn.Linear(3, embed_channels),
                self.norm_layer(embed_channels),
                nn.ReLU(inplace=True),
                nn.Linear(embed_channels, embed_channels),
            )
        self.weight_encoding = nn.Sequential(
            nn.Linear(embed_channels, groups),
            self.norm_layer(groups),
            nn.ReLU(inplace=True),
            nn.Linear(groups, groups),
        )
        self.softmax = nn.Softmax(dim=1)
        self.attn_drop = nn.Dropout(attn_drop_rate)

    def forward(self, feat, coord, reference_index):
        """
        input: feat: [n, c], coord: [n, 3], reference_index: [n, k]
        output: feat: [n, c]
        """
        query, key, value = (
            self.linear_q(feat), # [n, c]
            self.linear_k(feat), # [n, c]
            self.linear_v(feat), # [n, c]
        )
        
        # pointops.grouping åªæ”¯æŒ FP32 è¾“å…¥ï¼Œè¾“å‡ºè®© autocast ç®¡ç†
        key = pointops.grouping(reference_index, key.float(), coord.float(), with_xyz=True) # [n, k, 3+c]
        value = pointops.grouping(reference_index, value.float(), coord.float(), with_xyz=False) # [n, k, c]
        pos, key = key[:, :, 0:3], key[:, :, 3:] # [n, k, 3], [n, k, c]
        relation_qk = key - query.unsqueeze(1) # [n, k ,c], é‚»åŸŸå†…ä¸ä¸­å¿ƒç‚¹çš„ç›¸å¯¹ä½ç½®, ç”¨äºç›¸å¯¹ä½ç½®ç¼–ç 
        if self.pe_multiplier: # ä¹˜æ€§å› å­
            pem = self.linear_p_multiplier(pos) # [n, k, c]
            relation_qk = relation_qk * pem # [n, k, c]
        if self.pe_bias: # åç½®å› å­
            peb = self.linear_p_bias(pos) # [n, k, c]
            relation_qk = relation_qk + peb # [n, k, c]
            value = value + peb # [n, k, c]

        weight = self.weight_encoding(relation_qk) # [n, k, g]
        weight = self.attn_drop(self.softmax(weight)) # [n, k, g]

        # mask æ“ä½œä¸éœ€è¦æ¢¯åº¦
        with torch.no_grad():
            mask = torch.sign(reference_index + 1) # [n, k], æ— æ•ˆé‚»åŸŸç‚¹æ ‡è®°ä¸º0
        
        weight = torch.einsum("n s g, n s -> n s g", weight, mask) # [n, k, g]
        value = einops.rearrange(value, "n ns (g i) -> n ns g i", g=self.groups) # [n, k, g, i]
        feat = torch.einsum("n s g i, n s g -> n g i", value, weight) # [n, g, i]
        feat = einops.rearrange(feat, "n g i -> n (g i)") # [n, c]
        return feat # [n, c]
    

class PointNetLayer(nn.Module):
    def __init__(self, in_channels, out_channels, norm_layer=PointLayerNorm, k_neighbors=16):
        """
        ä½¿ç”¨ Linear å±‚å’Œ PointBatchNorm çš„ PointNet å±‚å®ç°
        
        å‚æ•°:
            in_channels: è¾“å…¥ç‰¹å¾ç»´åº¦ c1
            out_channels: è¾“å‡ºç‰¹å¾ç»´åº¦ c2
            k_neighbors: KNNè¿‘é‚»æ•°
            norm_layer: å½’ä¸€åŒ–å±‚ç±»å‹
        """
        super().__init__()
        self.k_neighbors = k_neighbors
        self.norm_layer = norm_layer

        # è®¡ç®—ä¸­é—´å±‚ç»´åº¦
        mid_channels = max(in_channels, out_channels // 2)
        
        # è¾“å…¥ç‰¹å¾ç»´åº¦è°ƒæ•´ï¼ˆå¦‚æœåŒ…å«xyzåæ ‡ï¼‰
        mlp_in_channels = in_channels
        
        # å®šä¹‰å…±äº«MLPç½‘ç»œï¼ˆä½¿ç”¨Linearå±‚ï¼‰
        self.shared_mlp = nn.Sequential(
            nn.Linear(mlp_in_channels, mid_channels),
            self.norm_layer(mid_channels),
            nn.ReLU(inplace=True),
            nn.Linear(mid_channels, out_channels),
            self.norm_layer(out_channels),
            nn.ReLU(inplace=True)
        )
        
    def forward(self, points):
        coord, feat, offset = points
        
        # KNN æŸ¥è¯¢éœ€è¦ FP32 åæ ‡
        with torch.no_grad():
            reference_index, _ = pointops.knn_query(self.k_neighbors, coord.float(), offset)
        
        # pointops.grouping åªæ”¯æŒ FP32 è¾“å…¥ï¼Œè¾“å‡ºè®© autocast ç®¡ç†
        grouped_features = pointops.grouping(reference_index, feat.float(), coord.float(), with_xyz=False)
        
        n_points = grouped_features.shape[0]
        grouped_features = grouped_features.reshape(-1, grouped_features.shape[-1])
        out = self.shared_mlp(grouped_features)
        out = out.reshape(n_points, self.k_neighbors, -1)
        out = out.max(dim=1)[0]
        
        return out
    

 # â€”â€”â€”â€” æ± åŒ–å±‚ â€”â€”â€”â€”

 # ... (ä¹‹å‰çš„å¯¼å…¥ä¿æŒä¸å˜)

class GridPool(nn.Module):
    """
    Partition-based Pooling (Grid Pooling)
    """
    def __init__(self, in_channels, out_channels, grid_size, bias=False):
        super(GridPool, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.grid_size = grid_size

        self.fc = nn.Linear(in_channels, out_channels, bias=bias)
        self.norm = PointLayerNorm(out_channels)
        self.act = nn.ReLU(inplace=True)

    def forward(self, points, start=None):
        """
        input: points: [pxo], [[n,3],[n,c],[b]], start: [b, 3]
        output: points: [pxo], [[v,3],[v,c],[b]], cluster: [n]
        """
        coord, feat, offset = points
        batch = offset2batch(offset)
        
        # 1. ç¡®ä¿ feat è®¡ç®—åœ¨è‡ªåŠ¨æ··åˆç²¾åº¦ä¸‹è¿›è¡Œ
        feat = self.act(self.norm(self.fc(feat)))
        
        # 2. åæ ‡è®¡ç®—å¿…é¡»ä½¿ç”¨ FP32
        coord_fp32 = coord.float()
        
        with torch.no_grad():
            start = (
                segment_csr(
                    coord_fp32,
                    torch.cat([batch.new_zeros(1), torch.cumsum(batch.bincount(), dim=0)]),
                    reduce="min",
                )
                if start is None
                else start
            )
        
        cluster = voxel_grid(
            pos=coord_fp32 - start[batch], size=self.grid_size, batch=batch, start=0
        )
        unique, cluster, counts = torch.unique(
            cluster, sorted=True, return_inverse=True, return_counts=True
        )
        
        # è·å–æ’åºç´¢å¼•
        _, sorted_cluster_indices = torch.sort(cluster)
        idx_ptr = torch.cat([counts.new_zeros(1), torch.cumsum(counts, dim=0)])
        
        # 3. æ± åŒ–æ“ä½œ
        coord = segment_csr(coord_fp32[sorted_cluster_indices], idx_ptr, reduce="mean")
        feat = segment_csr(feat[sorted_cluster_indices], idx_ptr, reduce="max")
        
        # ğŸ”¥ [ä¿®å¤ 1] æ­£ç¡®æ›´æ–° batch ç´¢å¼• (å…ˆé‡æ’å†åˆ‡ç‰‡)
        batch = batch[sorted_cluster_indices][idx_ptr[:-1]]
        
        # ğŸ”¥ [ä¿®å¤ 2] å¼ºåˆ¶ offset ä¸º int32 !!! (è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥)
        offset = batch2offset(batch).int()
        
        return [coord, feat, offset], cluster

        
class GridPool1(nn.Module):
    """
    Partition-based Pooling (Grid Pooling)
    æ ¼ç½‘æ± åŒ–ï¼ŒåŸºäºä½“ç´ åˆ’åˆ†è¿›è¡Œæ± åŒ–ä¸‹é‡‡æ ·ï¼Œä½“ç´ å†…åæ ‡å¹³å‡æ± åŒ–ï¼Œç‰¹å¾æœ€å¤§æ± åŒ–ï¼Œå¾—åˆ°æ–°çš„pxoï¼ŒåŒæ—¶è¾“å‡ºä½“ç´ ç´¢å¼•
    Args:
        in_channels: è¾“å…¥ç»´åº¦
        out_channels: è¾“å‡ºç»´åº¦
        grid_size: ä½“ç´ å¤§å°
        bias: fcå±‚åç½®
    """

    def __init__(self, in_channels, out_channels, grid_size, bias=False):
        super(GridPool1, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.grid_size = grid_size

        self.fc = nn.Linear(in_channels, out_channels, bias=bias)
        self.norm = PointLayerNorm(out_channels)
        self.act = nn.ReLU(inplace=True)

    def forward(self, points, start=None):
        """
        input: points: [pxo], [[n,3],[n,c],[b]], start: [b, 3]
        output: points: [pxo], [[v,3],[v,c],[b]], cluster: [n]
        """
        coord, feat, offset = points # [n, 3] [n, c] [b]
        batch = offset2batch(offset) # [b] -> [n]
        feat = self.act(self.norm(self.fc(feat))) # [n, c]
        
        # åæ ‡æ“ä½œéœ€è¦ FP32 ç²¾åº¦ï¼Œä½†ä¸ç¦ç”¨ autocast
        # åªåœ¨éœ€è¦æ—¶è½¬æ¢ coord åˆ° FP32ï¼Œè®© feat ä¿æŒ autocast çš„ç±»å‹
        coord_fp32 = coord.float()
        
        # è®¡ç®— start (batch å†…æ¯ä¸ªæ ·æœ¬çš„æœ€å°åæ ‡)
        with torch.no_grad():
            start = (
                segment_csr(
                    coord_fp32,
                    torch.cat([batch.new_zeros(1), torch.cumsum(batch.bincount(), dim=0)]),
                    reduce="min",
                )
                if start is None
                else start
            )
        
        # voxel_grid å’Œåç»­æ“ä½œä¸èƒ½åœ¨ no_grad ä¸­ï¼Œå› ä¸ºéœ€è¦è·Ÿè¸ªæ¢¯åº¦
        cluster = voxel_grid(
            pos=coord_fp32 - start[batch], size=self.grid_size, batch=batch, start=0
        )
        unique, cluster, counts = torch.unique(
            cluster, sorted=True, return_inverse=True, return_counts=True
        )
        _, sorted_cluster_indices = torch.sort(cluster)
        idx_ptr = torch.cat([counts.new_zeros(1), torch.cumsum(counts, dim=0)])
        
        # è¾“å‡ºåæ ‡ç”¨ FP32ï¼Œfeat ä¿æŒåŸå§‹ç±»å‹
        coord = segment_csr(coord_fp32[sorted_cluster_indices], idx_ptr, reduce="mean")
        feat = segment_csr(feat[sorted_cluster_indices], idx_ptr, reduce="max")
        batch = batch[idx_ptr[:-1]]
        offset = batch2offset(batch)
        return [coord, feat, offset], cluster  # ä¸ detachï¼Œè®© PyTorch ç®¡ç†æ¢¯åº¦
    
class UnpoolWithSkip(nn.Module):
    """
    Map Unpooling with skip connection
    å¸¦æœ‰è·³è·ƒè¿æ¥çš„ä¸Šé‡‡æ ·
    Args:
        in_channels: è¾“å…¥ç»´åº¦
        out_channels: è¾“å‡ºç»´åº¦
        skip_channels: è·³è·ƒè¿æ¥ç»´åº¦
        bias: fcå±‚åç½®
        skip: æ˜¯å¦ä½¿ç”¨è·³è·ƒè¿æ¥
        backend: ä¸Šé‡‡æ ·æ–¹å¼ï¼Œ'map' or 'interp'
    """

    def __init__(
        self,
        in_channels,
        skip_channels,
        out_channels,
        bias=True,
        skip=True,
        backend="map",
    ):
        super(UnpoolWithSkip, self).__init__()
        self.in_channels = in_channels
        self.skip_channels = skip_channels
        self.out_channels = out_channels
        self.skip = skip
        self.backend = backend
        assert self.backend in ["map", "interp"]

        self.proj = nn.Sequential(
            nn.Linear(in_channels, out_channels, bias=bias),
            PointLayerNorm(out_channels),
            nn.ReLU(inplace=True),
        )
        self.proj_skip = nn.Sequential(
            nn.Linear(skip_channels, out_channels, bias=bias),
            PointLayerNorm(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, points, skip_points, cluster=None):
        """
        input: points: [pxo], [[n,3],[n,c],[b]], skip_points: [pxo], [[ns,3],[ns,c],[b]], cluster: [ns]
        output: points: [pxo], [[ns,3],[ns,c],[b]]
        """
        coord, feat, offset = points 
        skip_coord, skip_feat, skip_offset = skip_points 
        
        if self.backend == "map" and cluster is not None:
            feat = self.proj(feat)[cluster] 
        else:
            feat_proj = self.proj(feat)
            # ğŸ”¥ [ä¿®å¤ 3] é˜²å¾¡æ€§ç¼–ç¨‹ï¼šç¡®ä¿ interpolation æ¥æ”¶ int32 offset
            if offset.dtype != torch.int32:
                offset = offset.int()
            if skip_offset.dtype != torch.int32:
                skip_offset = skip_offset.int()
                
            feat = pointops.interpolation(
                coord.float(), skip_coord.float(), feat_proj.float(), offset, skip_offset
            ) 
        
        if self.skip: 
            feat = feat + self.proj_skip(skip_feat) 
        return [skip_coord, feat, skip_offset]