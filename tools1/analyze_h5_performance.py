"""
H5éšæœºè¯»å–æ€§èƒ½æ·±åº¦åˆ†æ

æµ‹è¯•ä¸åŒå­˜å‚¨ç­–ç•¥å¯¹éšæœºè¯»å–çš„å½±å“ï¼š
1. å½“å‰æ–¹æ¡ˆï¼ˆgzipå‹ç¼© + éœ€è¦æ’åºindicesï¼‰
2. æ— å‹ç¼© + é¢„æ’åºindices
3. è¿ç»­å­˜å‚¨ï¼ˆæ¯ä¸ªsegmentç‹¬ç«‹å­˜å‚¨ï¼‰
"""

import h5py
import numpy as np
import time
from pathlib import Path
import tempfile


def analyze_current_h5_bottleneck(h5_path: str):
    """åˆ†æå½“å‰H5æ–‡ä»¶çš„ç“¶é¢ˆ"""
    
    print("="*70)
    print("å½“å‰H5æ–‡ä»¶æ€§èƒ½ç“¶é¢ˆåˆ†æ")
    print("="*70)
    
    with h5py.File(h5_path, 'r') as f:
        # è·å–æ•°æ®é›†ä¿¡æ¯
        x_dataset = f['data']['x']
        print(f"\nå½“å‰å­˜å‚¨æ–¹å¼:")
        print(f"  å‹ç¼©: {x_dataset.compression}")
        print(f"  å‹ç¼©çº§åˆ«: {x_dataset.compression_opts}")
        print(f"  Chunkå¤§å°: {x_dataset.chunks}")
        print(f"  æ•°æ®ç±»å‹: {x_dataset.dtype}")
        
        # æµ‹è¯•è¯»å–æ€§èƒ½
        num_tests = 20
        indices_to_test = np.random.choice(f['segments'].attrs['num_segments'], num_tests, replace=False)
        
        print(f"\næµ‹è¯•éšæœºè¯»å–{num_tests}ä¸ªsegments:")
        
        # æµ‹è¯•1: è¯»å–indices
        start = time.time()
        for idx in indices_to_test:
            indices = f['segments'][f'segment_{idx:04d}']['indices'][:]
        time_read_indices = time.time() - start
        print(f"  è¯»å–indices: {time_read_indices*1000:.2f}ms")
        
        # æµ‹è¯•2: æ£€æŸ¥æ’åº
        start = time.time()
        needs_sort_count = 0
        for idx in indices_to_test:
            indices = f['segments'][f'segment_{idx:04d}']['indices'][:]
            if not np.all(indices[:-1] <= indices[1:]):
                needs_sort_count += 1
        time_check_sort = time.time() - start
        print(f"  æ£€æŸ¥æ’åº: {time_check_sort*1000:.2f}ms")
        print(f"  éœ€è¦æ’åº: {needs_sort_count}/{num_tests}")
        
        # æµ‹è¯•3: æ’åºindices
        start = time.time()
        for idx in indices_to_test:
            indices = f['segments'][f'segment_{idx:04d}']['indices'][:]
            if not np.all(indices[:-1] <= indices[1:]):
                sort_order = np.argsort(indices)
                sorted_indices = indices[sort_order]
                unsort_order = np.argsort(sort_order)
        time_sort = time.time() - start
        print(f"  æ’åºæ“ä½œ: {time_sort*1000:.2f}ms")
        
        # æµ‹è¯•4: è¯»å–æ•°æ®ï¼ˆfancy indexingï¼‰
        start = time.time()
        for idx in indices_to_test[:5]:  # åªæµ‹5ä¸ªï¼Œå› ä¸ºæ…¢
            indices = f['segments'][f'segment_{idx:04d}']['indices'][:]
            if np.all(indices[:-1] <= indices[1:]):
                xyz = np.stack([
                    x_dataset[indices],
                    f['data']['y'][indices],
                    f['data']['z'][indices]
                ], axis=1)
        time_read_data = time.time() - start
        print(f"  è¯»å–æ•°æ®(5ä¸ª): {time_read_data*1000:.2f}ms ({time_read_data/5*1000:.2f}ms/segment)")
        
        # æµ‹è¯•5: è§£å‹ç¼©å¼€é”€
        # è¯»å–è¿ç»­æ•°æ® vs fancy indexing
        start = time.time()
        for _ in range(5):
            data = x_dataset[:10000]  # è¯»å–è¿ç»­1ä¸‡ç‚¹
        time_sequential = time.time() - start
        print(f"  è¿ç»­è¯»å–(5x10kç‚¹): {time_sequential*1000:.2f}ms")
        
        avg_seg_size = len(f['segments']['segment_0000']['indices'][:])
        print(f"\nç“¶é¢ˆåˆ†æï¼ˆå¹³å‡æ¯segment {avg_seg_size}ç‚¹ï¼‰:")
        print(f"  1. Indicesè¯»å–: {time_read_indices/num_tests*1000:.2f}ms (å°å¼€é”€)")
        print(f"  2. æ’åºæ£€æŸ¥: {time_check_sort/num_tests*1000:.2f}ms (å°å¼€é”€)")
        print(f"  3. æ’åºæ“ä½œ: {time_sort/num_tests*1000:.2f}ms (ä¸­ç­‰å¼€é”€)")
        print(f"  4. âš ï¸ Fancy indexingè¯»å–: {time_read_data/5*1000:.2f}ms (ä¸»è¦ç“¶é¢ˆ!)")
        print(f"  5. è¿ç»­è¯»å–: {time_sequential/5*1000:.2f}ms (å¿«{(time_read_data/5)/(time_sequential/5):.1f}å€)")
        
        print(f"\nğŸ’¡ æ ¸å¿ƒé—®é¢˜:")
        print(f"  Fancy indexing + å‹ç¼© â†’ éœ€è¦è§£å‹å¤§é‡chunks â†’ ææ…¢")
        print(f"  è¿ç»­è¯»å– + å‹ç¼© â†’ åªéœ€è§£å‹å°‘é‡chunks â†’ å¿«")


def test_storage_strategies():
    """æµ‹è¯•ä¸åŒå­˜å‚¨ç­–ç•¥çš„æ€§èƒ½"""
    
    print("\n" + "="*70)
    print("å­˜å‚¨ç­–ç•¥æ€§èƒ½å¯¹æ¯”")
    print("="*70)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    num_points = 1000000
    num_segments = 50
    
    test_data = {
        'x': np.random.randn(num_points).astype(np.float32),
        'y': np.random.randn(num_points).astype(np.float32),
        'z': np.random.randn(num_points).astype(np.float32),
        'labels': np.random.randint(0, 10, num_points, dtype=np.int32)
    }
    
    # ç”Ÿæˆsegmentsï¼ˆéšæœºç´¢å¼•ï¼‰
    segments = []
    points_per_seg = num_points // num_segments
    for i in range(num_segments):
        start = i * points_per_seg
        end = start + points_per_seg
        indices = np.random.permutation(np.arange(start, end))[:int(points_per_seg*0.8)]
        segments.append(indices)
    
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir = Path(tmpdir)
        
        # ===== ç­–ç•¥1: å½“å‰æ–¹æ¡ˆï¼ˆgzip + æœªæ’åºindicesï¼‰ =====
        print("\nç­–ç•¥1: Gzipå‹ç¼© + Fancy Indexing (å½“å‰æ–¹æ¡ˆ)")
        h5_gzip = tmpdir / "test_gzip.h5"
        
        start = time.time()
        with h5py.File(h5_gzip, 'w') as f:
            data_group = f.create_group('data')
            for key, arr in test_data.items():
                data_group.create_dataset(
                    key, data=arr, 
                    compression='gzip', compression_opts=4,
                    chunks=(8192,), shuffle=True
                )
            
            seg_group = f.create_group('segments')
            seg_group.attrs['num_segments'] = num_segments
            for i, indices in enumerate(segments):
                sg = seg_group.create_group(f'segment_{i:04d}')
                sg.create_dataset('indices', data=indices, dtype=np.int64)
        
        write_time = time.time() - start
        file_size = h5_gzip.stat().st_size / (1024**2)
        
        # æµ‹è¯•è¯»å–
        start = time.time()
        with h5py.File(h5_gzip, 'r') as f:
            for i in range(10):
                indices = f['segments'][f'segment_{i:04d}']['indices'][:]
                sort_order = np.argsort(indices)
                sorted_indices = indices[sort_order]
                xyz = np.stack([
                    f['data']['x'][sorted_indices],
                    f['data']['y'][sorted_indices],
                    f['data']['z'][sorted_indices]
                ], axis=1)
        read_time = time.time() - start
        
        print(f"  å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
        print(f"  è¯»å–10 segments: {read_time:.2f}ç§’ ({read_time/10*1000:.0f}ms/seg)")
        
        # ===== ç­–ç•¥2: æ— å‹ç¼© + Fancy Indexing =====
        print("\nç­–ç•¥2: æ— å‹ç¼© + Fancy Indexing")
        h5_nocomp = tmpdir / "test_nocomp.h5"
        
        start = time.time()
        with h5py.File(h5_nocomp, 'w') as f:
            data_group = f.create_group('data')
            for key, arr in test_data.items():
                data_group.create_dataset(
                    key, data=arr,
                    chunks=(8192,)  # æ— å‹ç¼©
                )
            
            seg_group = f.create_group('segments')
            seg_group.attrs['num_segments'] = num_segments
            for i, indices in enumerate(segments):
                sg = seg_group.create_group(f'segment_{i:04d}')
                sg.create_dataset('indices', data=np.sort(indices), dtype=np.int64)
        
        write_time = time.time() - start
        file_size = h5_nocomp.stat().st_size / (1024**2)
        
        # æµ‹è¯•è¯»å–
        start = time.time()
        with h5py.File(h5_nocomp, 'r') as f:
            for i in range(10):
                indices = f['segments'][f'segment_{i:04d}']['indices'][:]
                xyz = np.stack([
                    f['data']['x'][indices],
                    f['data']['y'][indices],
                    f['data']['z'][indices]
                ], axis=1)
        read_time = time.time() - start
        
        print(f"  å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
        print(f"  è¯»å–10 segments: {read_time:.2f}ç§’ ({read_time/10*1000:.0f}ms/seg)")
        
        # ===== ç­–ç•¥3: è¿ç»­å­˜å‚¨ï¼ˆæ¯ä¸ªsegmentç‹¬ç«‹å­˜å‚¨ï¼‰ =====
        print("\nç­–ç•¥3: è¿ç»­å­˜å‚¨ (æ¯segmentç‹¬ç«‹)")
        h5_contiguous = tmpdir / "test_contiguous.h5"
        
        start = time.time()
        with h5py.File(h5_contiguous, 'w') as f:
            seg_group = f.create_group('segments')
            seg_group.attrs['num_segments'] = num_segments
            
            for i, indices in enumerate(segments):
                sg = seg_group.create_group(f'segment_{i:04d}')
                # ç›´æ¥å­˜å‚¨segmentçš„æ•°æ®ï¼Œä¸å­˜indices
                sg.create_dataset('x', data=test_data['x'][indices])
                sg.create_dataset('y', data=test_data['y'][indices])
                sg.create_dataset('z', data=test_data['z'][indices])
                sg.create_dataset('labels', data=test_data['labels'][indices])
        
        write_time = time.time() - start
        file_size = h5_contiguous.stat().st_size / (1024**2)
        
        # æµ‹è¯•è¯»å–
        start = time.time()
        with h5py.File(h5_contiguous, 'r') as f:
            for i in range(10):
                xyz = np.stack([
                    f['segments'][f'segment_{i:04d}']['x'][:],
                    f['segments'][f'segment_{i:04d}']['y'][:],
                    f['segments'][f'segment_{i:04d}']['z'][:]
                ], axis=1)
        read_time = time.time() - start
        
        print(f"  å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
        print(f"  è¯»å–10 segments: {read_time:.2f}ç§’ ({read_time/10*1000:.0f}ms/seg)")
        
        # ===== ç­–ç•¥4: è¿ç»­å­˜å‚¨ + æ— å‹ç¼©ä½†chunked =====
        print("\nç­–ç•¥4: è¿ç»­å­˜å‚¨ + Chunkingä¼˜åŒ–")
        h5_optimized = tmpdir / "test_optimized.h5"
        
        start = time.time()
        with h5py.File(h5_optimized, 'w') as f:
            seg_group = f.create_group('segments')
            seg_group.attrs['num_segments'] = num_segments
            
            for i, indices in enumerate(segments):
                sg = seg_group.create_group(f'segment_{i:04d}')
                seg_len = len(indices)
                # ä½¿ç”¨contiguouså­˜å‚¨ï¼ˆä¸chunkingï¼‰
                sg.create_dataset('x', data=test_data['x'][indices], chunks=None)
                sg.create_dataset('y', data=test_data['y'][indices], chunks=None)
                sg.create_dataset('z', data=test_data['z'][indices], chunks=None)
                sg.create_dataset('labels', data=test_data['labels'][indices], chunks=None)
        
        write_time = time.time() - start
        file_size = h5_optimized.stat().st_size / (1024**2)
        
        # æµ‹è¯•è¯»å–
        start = time.time()
        with h5py.File(h5_optimized, 'r') as f:
            for i in range(10):
                xyz = np.stack([
                    f['segments'][f'segment_{i:04d}']['x'][:],
                    f['segments'][f'segment_{i:04d}']['y'][:],
                    f['segments'][f'segment_{i:04d}']['z'][:]
                ], axis=1)
        read_time = time.time() - start
        
        print(f"  å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
        print(f"  è¯»å–10 segments: {read_time:.2f}ç§’ ({read_time/10*1000:.0f}ms/seg)")
    
    print("\n" + "="*70)
    print("ç»“è®º")
    print("="*70)
    print("""
1. Fancy Indexing + å‹ç¼© = ææ…¢ï¼ˆå½“å‰æ–¹æ¡ˆï¼‰
   - éœ€è¦è§£å‹å¤§é‡ä¸ç›¸å…³çš„chunks
   - ç´¢å¼•ä¸è¿ç»­å¯¼è‡´ç¼“å­˜å¤±æ•ˆ
   
2. Fancy Indexing + æ— å‹ç¼© = å¿«ä¸€äº›
   - æ¶ˆé™¤è§£å‹å¼€é”€
   - ä½†ä»éœ€éšæœºè®¿é—®
   
3. è¿ç»­å­˜å‚¨ = æœ€å¿«ï¼
   - æ¯ä¸ªsegmentçš„æ•°æ®è¿ç»­å­˜å‚¨
   - é¡ºåºè¯»å–ï¼Œç¼“å­˜å‹å¥½
   - æ–‡ä»¶ç¨å¤§ä½†æ€§èƒ½æœ€ä½³
   
æ¨è: ç­–ç•¥4ï¼ˆè¿ç»­å­˜å‚¨ + æ— å‹ç¼© + contiguousï¼‰
    """)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        h5_path = sys.argv[1]
        analyze_current_h5_bottleneck(h5_path)
    else:
        print("æœªæä¾›H5æ–‡ä»¶ï¼Œåªè¿è¡Œæµ‹è¯•")
    
    test_storage_strategies()
