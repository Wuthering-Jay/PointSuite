# PointSuite

PointSuite æ˜¯ä¸€ä¸ªåŸºäº `PyTorch Lightning` æ„å»ºçš„ç‚¹äº‘æ·±åº¦å­¦ä¹ é€šç”¨å·¥å…·ç®±ï¼Œæ”¯æŒè¯­ä¹‰åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ç­‰å¤šç§ä»»åŠ¡ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: YAML é…ç½®è¿è¡Œ

```bash
# è®­ç»ƒ
python main.py --config configs/experiments/dales_semseg.yaml

# æµ‹è¯•
python main.py --config configs/experiments/dales_semseg.yaml --run.mode test --run.checkpoint_path path/to/ckpt

# è¦†ç›–é…ç½®
python main.py --config configs/experiments/dales_semseg.yaml --trainer.max_epochs 50 --data.batch_size 8
```

### æ–¹å¼2: Python API

```python
from pointsuite.engine import SemanticSegmentationEngine

# ä» YAML é…ç½®è¿è¡Œ
engine = SemanticSegmentationEngine.from_config('configs/experiments/dales_semseg.yaml')
engine.run()

# æˆ–åˆ†æ­¥æ‰§è¡Œ
engine.setup()
engine.train()
engine.test()
engine.predict()
```

### æ–¹å¼3: ç¼–ç¨‹å¼è°ƒç”¨

```python
from pointsuite import BinPklDataModule, SemanticSegmentationTask
import pytorch_lightning as pl

# åˆ›å»º DataModule
datamodule = BinPklDataModule(
    train_data='path/to/train',
    val_data='path/to/val',
    ...
)

# åˆ›å»º Task
task = SemanticSegmentationTask(
    model_config={...},
    loss_configs=[...],
    ...
)

# è®­ç»ƒ
trainer = pl.Trainer(...)
trainer.fit(task, datamodule)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
PointSuite/
â”œâ”€â”€ main.py                 # ç»Ÿä¸€å…¥å£
â”œâ”€â”€ configs/                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ experiments/        # å®éªŒé…ç½® (å…¥å£)
â”‚   â”‚   â””â”€â”€ dales_semseg.yaml
â”‚   â”œâ”€â”€ data/               # æ•°æ®é…ç½®
â”‚   â”‚   â””â”€â”€ dales.yaml
â”‚   â”œâ”€â”€ model/              # æ¨¡å‹é…ç½®
â”‚   â”‚   â””â”€â”€ ptv2_semseg.yaml
â”‚   â””â”€â”€ trainer/            # è®­ç»ƒå™¨é…ç½®
â”‚       â””â”€â”€ default.yaml
â”œâ”€â”€ pointsuite/             # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ data/               # æ•°æ®åŠ è½½
â”‚   â”‚   â”œâ”€â”€ datamodule_base.py
â”‚   â”‚   â”œâ”€â”€ datamodule_bin.py
â”‚   â”‚   â”œâ”€â”€ transforms.py
â”‚   â”‚   â””â”€â”€ datasets/
â”‚   â”œâ”€â”€ models/             # æ¨¡å‹æ¶æ„
â”‚   â”‚   â”œâ”€â”€ backbones/      # Backbone (PTv2, ...)
â”‚   â”‚   â”œâ”€â”€ heads/          # Head (SegHead, ...)
â”‚   â”‚   â””â”€â”€ losses/         # æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ tasks/              # Lightning ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ base_task.py
â”‚   â”‚   â””â”€â”€ semantic_segmentation.py
â”‚   â”œâ”€â”€ engine/             # ä»»åŠ¡å¼•æ“
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ semantic_segmentation.py
â”‚   â”‚   â”œâ”€â”€ instance_segmentation.py  # TODO
â”‚   â”‚   â””â”€â”€ object_detection.py       # TODO
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ config.py       # é…ç½®ç®¡ç†
â”‚       â”œâ”€â”€ callbacks.py    # å›è°ƒå‡½æ•°
â”‚       â””â”€â”€ metrics/        # è¯„ä¼°æŒ‡æ ‡
â””â”€â”€ examples/               # ä½¿ç”¨ç¤ºä¾‹
    â””â”€â”€ run_experiment.py
```

## âš™ï¸ é…ç½®ç³»ç»Ÿ

é‡‡ç”¨åˆ†å±‚é…ç½®æ¶æ„:

```yaml
# experiments/dales_semseg.yaml (å…¥å£é…ç½®)
defaults:
  - data: dales.yaml          # æ•°æ®é…ç½®
  - model: ptv2_semseg.yaml   # æ¨¡å‹é…ç½®
  - trainer: default.yaml     # è®­ç»ƒå™¨é…ç½®

run:
  mode: train                  # train/resume/finetune/test/predict
  seed: 42
  output_dir: ./outputs/dales
```

æ”¯æŒå˜é‡å¼•ç”¨:
```yaml
head:
  init_args:
    num_classes: ${data.num_classes}  # å¼•ç”¨ data é…ç½®ä¸­çš„å€¼
```

è¯¦ç»†æ–‡æ¡£è§ [configs/README.md](configs/README.md)

## ğŸ¯ æ”¯æŒçš„ä»»åŠ¡

| ä»»åŠ¡ | çŠ¶æ€ | Engine | Task |
|------|------|--------|------|
| è¯­ä¹‰åˆ†å‰² | âœ… | `SemanticSegmentationEngine` | `SemanticSegmentationTask` |
| å®ä¾‹åˆ†å‰² | ğŸš§ | `InstanceSegmentationEngine` | `InstanceSegmentationTask` |
| ç›®æ ‡æ£€æµ‹ | ğŸš§ | `ObjectDetectionEngine` | `ObjectDetectionTask` |

## ğŸ“Š æ”¯æŒçš„æ¨¡å‹

### Backbone
- PointTransformerV2 (PTv2)
- æ›´å¤šå¼€å‘ä¸­...

### Head
- SegHead (è¯­ä¹‰åˆ†å‰²)
- æ›´å¤šå¼€å‘ä¸­...

## ğŸ”§ è¿è¡Œæ¨¡å¼

```yaml
run:
  mode: train      # ä»å¤´è®­ç»ƒ
  mode: resume     # ä» checkpoint ç»§ç»­è®­ç»ƒ (æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€)
  mode: finetune   # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œä»å¤´è®­ç»ƒ
  mode: test       # ä»…æµ‹è¯•
  mode: predict    # ä»…é¢„æµ‹
```

## å…³é”®è®¾è®¡

1. éœ€è¦ `[B,C,N]` å’Œ `[C,N]+offset` ä¸¤ç§æ•°æ®åŠ è½½æ–¹å¼ï¼Œè¿™æ ·å¯ä»¥å®ç°å¤§é‡å¼€æºå·¥ä½œçš„å¿«é€Ÿå…¼å®¹
2. é‡‡ç”¨ bin+pkl æ•°æ®æ ¼å¼å­˜å‚¨åˆ†å—è£å‰ªåçš„ç‚¹äº‘æ•°æ®ï¼Œæ”¯æŒå¿«é€Ÿ memmap è¯»å–
3. é€šè¿‡ä¼ å…¥ `require_labels` æ‰‹åŠ¨æ§åˆ¶æœ‰æ•ˆç±»åˆ«ï¼Œå¼•å…¥ `garbage_bin` æ¨¡å¼
4. å¯¹äºåˆ†å¸ƒå¼è®­ç»ƒé‡‡ç”¨ `ddp` ç­–ç•¥ï¼Œä½¿ç”¨ `torchmetrics` è¿›è¡ŒæŒ‡æ ‡è®¡ç®—

## ğŸ“ å¼€å‘æ—¥å¿—

* **2025/12/04**: å®ç°åŸºäº YAML é…ç½®çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ”¯æŒ experiment/data/model/trainer åˆ†å±‚é…ç½®
* **2025/11/01**: bin+pkl çš„å®ç°å·²ç»å®Œæˆï¼Œæ”¯æŒ overlap å’Œ gridsample æ¨¡å¼
* **2025/10/29**: è®¾è®¡ bin+pkl æ•°æ®æ ¼å¼ï¼ŒåŸºäº np.memmap è¿›è¡Œå¿«é€Ÿè¯»å–
* **2025/10/25**: é¡¹ç›®åˆå§‹åŒ–ï¼Œç¡®å®šæ•´ä½“æ¶æ„
