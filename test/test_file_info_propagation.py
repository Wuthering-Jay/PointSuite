"""
æµ‹è¯•æ–‡ä»¶ä¿¡æ¯åœ¨æ•°æ®æµä¸­çš„ä¼ é€’

éªŒè¯ä» tile.py â†’ dataset_bin.py â†’ semantic_segmentation.py â†’ callbacks.py çš„å®Œæ•´æµç¨‹
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import pickle
import tempfile
import shutil


def test_tile_metadata_structure():
    """æµ‹è¯• tile.py ç”Ÿæˆçš„ metadata æ˜¯å¦åŒ…å«æ–‡ä»¶ä¿¡æ¯"""
    
    print("="*70)
    print("æµ‹è¯• 1: Tile Metadata ç»“æ„")
    print("="*70)
    
    # æ¨¡æ‹Ÿ tile.py ç”Ÿæˆçš„ segment ä¿¡æ¯
    bin_path = Path("/data/test/5080_54400.bin")
    pkl_path = Path("/data/test/5080_54400.pkl")
    base_name = "5080_54400"
    
    segment_info = {
        'segment_id': 0,
        'indices': np.array([0, 1, 2, 3, 4]),
        'num_points': 5,
        # ğŸ”¥ æ–°å¢çš„æ–‡ä»¶å…³è”ä¿¡æ¯
        'bin_file': base_name,
        'bin_path': str(bin_path),
        'pkl_path': str(pkl_path),
    }
    
    print("\nç”Ÿæˆçš„ segment_info:")
    print(f"  - segment_id: {segment_info['segment_id']}")
    print(f"  - num_points: {segment_info['num_points']}")
    print(f"  - bin_file: {segment_info['bin_file']}")
    print(f"  - bin_path: {segment_info['bin_path']}")
    print(f"  - pkl_path: {segment_info['pkl_path']}")
    
    # éªŒè¯å¿…è¦å­—æ®µ
    assert 'bin_file' in segment_info, "ç¼ºå°‘ bin_file"
    assert 'bin_path' in segment_info, "ç¼ºå°‘ bin_path"
    assert 'pkl_path' in segment_info, "ç¼ºå°‘ pkl_path"
    
    print("\nâœ“ Tile metadata ç»“æ„æ­£ç¡®!")


def test_dataset_propagation():
    """æµ‹è¯• dataset æ˜¯å¦æ­£ç¡®ä¼ é€’æ–‡ä»¶ä¿¡æ¯"""
    
    print("\n" + "="*70)
    print("æµ‹è¯• 2: Dataset æ–‡ä»¶ä¿¡æ¯ä¼ é€’")
    print("="*70)
    
    # æ¨¡æ‹Ÿ dataset çš„ sample_info (æ¥è‡ª pkl)
    sample_info = {
        'segment_id': 0,
        'bin_path': '/data/test/5080_54400.bin',
        'pkl_path': '/data/test/5080_54400.pkl',
        'bin_file': '5080_54400',
        'num_points': 1000,
    }
    
    # æ¨¡æ‹Ÿ dataset._load_data çš„è¿”å›
    data = {
        'coord': np.random.randn(1000, 3),
        'feat': np.random.randn(1000, 4),
        'class': np.zeros(1000, dtype=np.int64),
    }
    
    # åœ¨ test split ä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯
    split = 'test'
    if split == 'test':
        indices = np.arange(1000)
        data['indices'] = indices.copy()
        
        # ğŸ”¥ æ·»åŠ æ–‡ä»¶ä¿¡æ¯
        data['bin_file'] = sample_info.get('bin_file', Path(sample_info['bin_path']).stem)
        data['bin_path'] = sample_info['bin_path']
        data['pkl_path'] = sample_info['pkl_path']
    
    print("\nDataset è¿”å›çš„ data å­—å…¸åŒ…å«:")
    for key in data.keys():
        if isinstance(data[key], np.ndarray):
            print(f"  - {key}: shape={data[key].shape}, dtype={data[key].dtype}")
        else:
            print(f"  - {key}: {data[key]}")
    
    # éªŒè¯
    assert 'bin_file' in data, "Dataset æœªä¼ é€’ bin_file"
    assert 'bin_path' in data, "Dataset æœªä¼ é€’ bin_path"
    assert 'pkl_path' in data, "Dataset æœªä¼ é€’ pkl_path"
    assert 'indices' in data, "Dataset æœªä¼ é€’ indices"
    
    print("\nâœ“ Dataset æ–‡ä»¶ä¿¡æ¯ä¼ é€’æ­£ç¡®!")
    
    return data


def test_task_propagation(data):
    """æµ‹è¯• task.predict_step æ˜¯å¦ä¼ é€’æ–‡ä»¶ä¿¡æ¯"""
    
    print("\n" + "="*70)
    print("æµ‹è¯• 3: Task Predict Step æ–‡ä»¶ä¿¡æ¯ä¼ é€’")
    print("="*70)
    
    # æ¨¡æ‹Ÿ batch (collate_fn çš„è¾“å‡º)
    # åœ¨å®é™…åœºæ™¯ä¸­ï¼Œcollate_fn ä¼šä¿æŒæŸäº›å­—æ®µä¸ºåˆ—è¡¨
    batch = {
        'coord': data['coord'],  # [N, 3]
        'feat': data['feat'],    # [N, C]
        'indices': data['indices'],  # [N]
        'bin_file': [data['bin_file']],  # åˆ—è¡¨å½¢å¼
        'bin_path': [data['bin_path']],
        'pkl_path': [data['pkl_path']],
        'offset': np.array([len(data['coord'])]),  # batch size = 1
    }
    
    print("\nBatch åŒ…å«:")
    for key, value in batch.items():
        if isinstance(value, np.ndarray):
            print(f"  - {key}: shape={value.shape}")
        elif isinstance(value, list):
            print(f"  - {key}: {value}")
        else:
            print(f"  - {key}: {type(value)}")
    
    # æ¨¡æ‹Ÿ predict_step çš„è¿”å›
    results = {
        'logits': np.random.randn(len(data['coord']), 8),  # [N, C]
    }
    
    # ä¼ é€’å¿…è¦ä¿¡æ¯
    if "indices" in batch:
        results["indices"] = batch["indices"]
    
    # ğŸ”¥ ä¼ é€’æ–‡ä»¶ä¿¡æ¯
    if "bin_file" in batch:
        results["bin_file"] = batch["bin_file"]
    if "bin_path" in batch:
        results["bin_path"] = batch["bin_path"]
    if "pkl_path" in batch:
        results["pkl_path"] = batch["pkl_path"]
    
    if "coord" in batch:
        results["coord"] = batch["coord"]
    
    print("\nPredict step è¿”å›çš„ results åŒ…å«:")
    for key, value in results.items():
        if isinstance(value, np.ndarray):
            print(f"  - {key}: shape={value.shape}")
        elif isinstance(value, list):
            print(f"  - {key}: {value}")
        else:
            print(f"  - {key}: {type(value)}")
    
    # éªŒè¯
    assert 'bin_file' in results, "Predict step æœªä¼ é€’ bin_file"
    assert 'bin_path' in results, "Predict step æœªä¼ é€’ bin_path"
    assert 'pkl_path' in results, "Predict step æœªä¼ é€’ pkl_path"
    
    print("\nâœ“ Task predict step æ–‡ä»¶ä¿¡æ¯ä¼ é€’æ­£ç¡®!")
    
    return results


def test_callback_extraction(results):
    """æµ‹è¯• callback æ˜¯å¦æ­£ç¡®æå–æ–‡ä»¶ä¿¡æ¯"""
    
    print("\n" + "="*70)
    print("æµ‹è¯• 4: Callback æ–‡ä»¶ä¿¡æ¯æå–")
    print("="*70)
    
    # æ¨¡æ‹Ÿ write_on_batch_end çš„å¤„ç†
    prediction = results
    
    # ğŸ”¥ ç›´æ¥ä» prediction è·å– bin æ–‡ä»¶ä¿¡æ¯
    if 'bin_file' in prediction and len(prediction['bin_file']) > 0:
        bin_files = prediction['bin_file']
        
        # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶å
        if isinstance(bin_files, list):
            bin_basename = bin_files[0]
        else:
            bin_basename = str(bin_files)
        
        print(f"\nâœ“ ç›´æ¥ä» prediction è·å– bin_basename: {bin_basename}")
    else:
        print("\nâœ— æ— æ³•ä» prediction è·å– bin_fileï¼Œéœ€è¦ä½¿ç”¨æ¨æ–­æ–¹æ³•")
        return False
    
    # éªŒè¯æ–‡ä»¶å
    assert bin_basename == "5080_54400", f"æ–‡ä»¶åä¸åŒ¹é…: {bin_basename}"
    
    # æ¨¡æ‹Ÿä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_dir = tempfile.mkdtemp()
    try:
        batch_idx = 0
        tmp_filename = f"{bin_basename}_batch_{batch_idx}.pred.tmp"
        tmp_path = Path(temp_dir) / tmp_filename
        
        # ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°ä¸´æ—¶æ–‡ä»¶
        save_dict = {
            'logits': prediction['logits'],
            'indices': prediction['indices'],
            'bin_file': bin_basename,
            'bin_path': prediction['bin_path'],
            'pkl_path': prediction['pkl_path'],
        }
        
        # ä½¿ç”¨ pickle æ¨¡æ‹Ÿä¿å­˜
        with open(tmp_path, 'wb') as f:
            pickle.dump(save_dict, f)
        
        print(f"âœ“ ä¿å­˜ä¸´æ—¶æ–‡ä»¶: {tmp_filename}")
        
        # æ¨¡æ‹Ÿä»ä¸´æ—¶æ–‡ä»¶è¯»å–
        with open(tmp_path, 'rb') as f:
            loaded = pickle.load(f)
        
        print("\nä»ä¸´æ—¶æ–‡ä»¶è¯»å–çš„ä¿¡æ¯:")
        print(f"  - bin_file: {loaded['bin_file']}")
        print(f"  - bin_path: {loaded['bin_path']}")
        print(f"  - pkl_path: {loaded['pkl_path']}")
        
        # éªŒè¯è·¯å¾„å¯ä»¥ç›´æ¥ä½¿ç”¨
        assert 'bin_path' in loaded, "ä¸´æ—¶æ–‡ä»¶ç¼ºå°‘ bin_path"
        assert 'pkl_path' in loaded, "ä¸´æ—¶æ–‡ä»¶ç¼ºå°‘ pkl_path"
        
        bin_path_from_tmp = loaded['bin_path']
        pkl_path_from_tmp = loaded['pkl_path']
        
        if isinstance(bin_path_from_tmp, list):
            bin_path_from_tmp = bin_path_from_tmp[0]
            pkl_path_from_tmp = pkl_path_from_tmp[0]
        
        print(f"\nâœ“ å¯ç›´æ¥ä½¿ç”¨çš„å®Œæ•´è·¯å¾„:")
        print(f"  - Bin: {bin_path_from_tmp}")
        print(f"  - Pkl: {pkl_path_from_tmp}")
        
        print("\nâœ“ Callback æ–‡ä»¶ä¿¡æ¯æå–æ­£ç¡®!")
        
    finally:
        shutil.rmtree(temp_dir)
    
    return True


def test_complete_flow():
    """æµ‹è¯•å®Œæ•´çš„æ–‡ä»¶ä¿¡æ¯ä¼ é€’æµç¨‹"""
    
    print("\n" + "="*70)
    print("æµ‹è¯• 5: å®Œæ•´æ•°æ®æµæµ‹è¯•")
    print("="*70)
    
    # 1. Tile.py é˜¶æ®µ
    print("\n[1/4] Tile.py ç”Ÿæˆ metadata...")
    test_tile_metadata_structure()
    
    # 2. Dataset é˜¶æ®µ
    print("\n[2/4] Dataset åŠ è½½æ•°æ®...")
    data = test_dataset_propagation()
    
    # 3. Task é˜¶æ®µ
    print("\n[3/4] Task predict_step...")
    results = test_task_propagation(data)
    
    # 4. Callback é˜¶æ®µ
    print("\n[4/4] Callback å¤„ç†...")
    success = test_callback_extraction(results)
    
    if success:
        print("\n" + "="*70)
        print("âœ… å®Œæ•´æ•°æ®æµæµ‹è¯•é€šè¿‡!")
        print("="*70)
        print("\nä¼˜åŠ¿:")
        print("  1. âœ“ æ— éœ€æ¨æ–­ï¼Œæ–‡ä»¶ä¿¡æ¯æ˜¾å¼ä¼ é€’")
        print("  2. âœ“ æ›´é«˜æ•ˆï¼Œé¿å…éå† data_list æŸ¥æ‰¾")
        print("  3. âœ“ æ›´å¯é ï¼Œä¸ä¾èµ–ç´¢å¼•åŒ¹é…")
        print("  4. âœ“ æ›´æ¸…æ™°ï¼Œæ•°æ®æµå‘ä¸€ç›®äº†ç„¶")
        print("="*70)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    test_complete_flow()
