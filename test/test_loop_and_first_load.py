"""
æµ‹è¯•ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š
1. ç¬¬ä¸€æ¬¡åŠ è½½æ•°æ®æ˜¯å¦æ¯”è¾ƒæ…¢ï¼Ÿ
2. loop å‚æ•°è®¾ç½®è¾ƒå¤§å€¼æ˜¯å¦æœ‰å½±å“ï¼Ÿ
"""
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import sys
from pathlib import Path
import time
import numpy as np
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pointsuite.data.datasets.dataset_bin import BinPklDataset
from pointsuite.data.datasets.collate import DynamicBatchSampler, collate_fn


def test_first_vs_second_pass():
    """æµ‹è¯•ç¬¬ä¸€æ¬¡éå† vs ç¬¬äºŒæ¬¡éå†çš„é€Ÿåº¦å·®å¼‚"""
    print("="*70)
    print("[é—®é¢˜1] ç¬¬ä¸€æ¬¡åŠ è½½æ•°æ®æ˜¯å¦æ¯”è¾ƒæ…¢ï¼Ÿ")
    print("="*70)
    
    data_root = r"E:\data\DALES\dales_las\bin\train"
    
    if not Path(data_root).exists():
        print(f"[X] æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return
    
    dataset = BinPklDataset(
        data_root=data_root,
        split='train',
        assets=['coord', 'intensity', 'classification'],
        cache_data=False,  # ä¸ç¼“å­˜æ•°æ®ï¼Œåªç¼“å­˜ metadata
        loop=1
    )
    
    print(f"\næ•°æ®é›†æ€»æ ·æœ¬æ•°: {len(dataset):,}")
    
    # æµ‹è¯•ï¼šåˆ†æ®µè®¿é—®ï¼Œè§‚å¯Ÿé¦–æ¬¡åŠ è½½æ¯ä¸ªæ–‡ä»¶çš„å¼€é”€
    print(f"\n[å®éªŒ] è®¿é—® 200 ä¸ªæ ·æœ¬ï¼Œè§‚å¯Ÿé¦–æ¬¡åŠ è½½ pkl çš„æ—¶é—´å³°å€¼")
    
    times = []
    for i in range(200):
        start = time.time()
        sample = dataset[i]
        elapsed = time.time() - start
        times.append(elapsed)
        
        # å¦‚æœè€—æ—¶è¶…è¿‡ 50msï¼Œè¯´æ˜æ˜¯é¦–æ¬¡åŠ è½½ pkl
        if elapsed > 0.05:
            print(f"  æ ·æœ¬ {i}: {elapsed*1000:.2f} ms âš ï¸ (é¦–æ¬¡åŠ è½½ pkl)")
    
    avg_time = np.mean(times) * 1000
    max_time = np.max(times) * 1000
    min_time = np.min(times) * 1000
    
    print(f"\nå‰ 200 ä¸ªæ ·æœ¬ç»Ÿè®¡:")
    print(f"  - å¹³å‡æ—¶é—´: {avg_time:.2f} ms")
    print(f"  - æœ€å¤§æ—¶é—´: {max_time:.2f} ms (é¦–æ¬¡åŠ è½½ pkl)")
    print(f"  - æœ€å°æ—¶é—´: {min_time:.2f} ms (metadata å·²ç¼“å­˜)")
    print(f"  - å³°å€¼ / å¹³å‡: {max_time/avg_time:.1f}x")
    
    # ç¬¬äºŒæ¬¡éå†åŒæ ·çš„æ ·æœ¬
    print(f"\n[ç¬¬äºŒæ¬¡éå†] é‡å¤è®¿é—®å‰ 200 ä¸ªæ ·æœ¬")
    
    start = time.time()
    for i in range(200):
        sample = dataset[i]
    second_pass_time = time.time() - start
    
    first_pass_time = sum(times)
    
    print(f"\nå¯¹æ¯”:")
    print(f"  - ç¬¬ä¸€æ¬¡éå†: {first_pass_time:.2f}s ({first_pass_time/200*1000:.2f} ms/æ ·æœ¬)")
    print(f"  - ç¬¬äºŒæ¬¡éå†: {second_pass_time:.2f}s ({second_pass_time/200*1000:.2f} ms/æ ·æœ¬)")
    print(f"  - åŠ é€Ÿæ¯”: {first_pass_time/second_pass_time:.2f}x")
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"  - âœ… ç¬¬ä¸€æ¬¡è®¿é—®æŸä¸ª pkl æ–‡ä»¶ä¸­çš„æ ·æœ¬æ—¶ä¼šæ…¢ï¼ˆéœ€åŠ è½½ pklï¼‰")
    print(f"  - âœ… ä½†æ¯ä¸ª pkl åªéœ€åŠ è½½ä¸€æ¬¡ï¼Œåç»­è®¿é—®éƒ½å¾ˆå¿«")
    print(f"  - âœ… å®Œæ•´ epoch ä¸­ï¼Œ29 ä¸ª pkl å„åŠ è½½ 1 æ¬¡ï¼Œæ€»å¼€é”€çº¦ {29*max_time/1000:.2f}s")
    print(f"  - âœ… ç›¸æ¯”æ€»æ—¶é—´ 99sï¼Œå¼€é”€å æ¯” {29*max_time/1000/99*100:.1f}%ï¼Œå¯æ¥å—")
    print()


def test_loop_parameter():
    """æµ‹è¯• loop å‚æ•°çš„å½±å“"""
    print("="*70)
    print("[é—®é¢˜2] loop å‚æ•°è®¾ç½®è¾ƒå¤§å€¼æ˜¯å¦æœ‰å½±å“ï¼Ÿ")
    print("="*70)
    
    data_root = r"E:\data\DALES\dales_las\bin\train"
    
    if not Path(data_root).exists():
        print(f"[X] æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return
    
    # æµ‹è¯•ä¸åŒçš„ loop å€¼
    loop_values = [1, 2, 5, 10]
    
    print(f"\næµ‹è¯•ä¸åŒ loop å€¼å¯¹æ•°æ®è®¿é—®çš„å½±å“:\n")
    
    for loop in loop_values:
        dataset = BinPklDataset(
            data_root=data_root,
            split='train',
            assets=['coord', 'intensity', 'classification'],
            cache_data=False,
            loop=loop
        )
        
        actual_samples = len(dataset.data_list)
        virtual_length = len(dataset)
        
        print(f"loop={loop}:")
        print(f"  - å®é™…æ ·æœ¬æ•°: {actual_samples:,}")
        print(f"  - è™šæ‹Ÿé•¿åº¦: {virtual_length:,} (= {actual_samples:,} Ã— {loop})")
        
        # æµ‹è¯•è®¿é—®ä¸åŒç´¢å¼•çš„é€Ÿåº¦
        test_indices = [0, actual_samples - 1, actual_samples, virtual_length - 1]
        
        print(f"  - è®¿é—®æµ‹è¯•:")
        for idx in test_indices:
            if idx >= virtual_length:
                continue
            
            start = time.time()
            sample = dataset[idx]
            elapsed = time.time() - start
            
            # è®¡ç®—å®é™…è®¿é—®çš„æ•°æ®ç´¢å¼•
            data_idx = idx % actual_samples
            
            print(f"    * dataset[{idx}] â†’ data_list[{data_idx}]: {elapsed*1000:.2f} ms")
        
        print()
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"  - âœ… loop åªæ˜¯è™šæ‹Ÿåœ°æ‰©å±•äº†æ•°æ®é›†é•¿åº¦")
    print(f"  - âœ… dataset[idx] å®é™…è®¿é—®çš„æ˜¯ data_list[idx % len(data_list)]")
    print(f"  - âœ… ä¸ä¼šå¢åŠ å†…å­˜å ç”¨ï¼ˆä¸ä¼šå¤åˆ¶æ•°æ®ï¼‰")
    print(f"  - âœ… ä¸ä¼šå¢åŠ åŠ è½½æ—¶é—´ï¼ˆmetadata ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼‰")
    print(f"  - âš ï¸ loop å¤§çš„è¯ï¼Œæ¯ä¸ª epoch æ—¶é—´ = åŸå§‹æ—¶é—´ Ã— loop")
    print()


def test_loop_with_dataloader():
    """æµ‹è¯• loop å‚æ•°åœ¨ DataLoader ä¸­çš„å®é™…æ•ˆæœ"""
    print("="*70)
    print("[æ·±å…¥æµ‹è¯•] loop å‚æ•°å¯¹ DataLoader è®­ç»ƒçš„å½±å“")
    print("="*70)
    
    data_root = r"E:\data\DALES\dales_las\bin\train"
    
    if not Path(data_root).exists():
        print(f"[X] æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return
    
    print(f"\næ¨¡æ‹Ÿè®­ç»ƒåœºæ™¯ï¼šå¯¹æ¯” loop=1 å’Œ loop=3\n")
    
    # æµ‹è¯• loop=1
    print(f"[æµ‹è¯•] loop=1 (æ ‡å‡†è®¾ç½®)")
    dataset_loop1 = BinPklDataset(
        data_root=data_root,
        split='train',
        assets=['coord', 'intensity', 'classification'],
        cache_data=False,
        loop=1
    )
    
    batch_sampler_loop1 = DynamicBatchSampler(
        dataset_loop1,
        max_points=300000,
        shuffle=True,
        drop_last=False
    )
    
    dataloader_loop1 = DataLoader(
        dataset_loop1,
        batch_sampler=batch_sampler_loop1,
        collate_fn=collate_fn,
        num_workers=0,
    )
    
    print(f"  - æ•°æ®é›†é•¿åº¦: {len(dataset_loop1):,}")
    print(f"  - é¢„ä¼° batches: {len(batch_sampler_loop1):,}")
    
    # åŠ è½½å‰ 100 ä¸ª batch
    start = time.time()
    batch_count = 0
    sample_count = 0
    for batch in dataloader_loop1:
        batch_count += 1
        sample_count += len(batch['offset'])
        if batch_count >= 100:
            break
    elapsed_loop1 = time.time() - start
    
    print(f"  - å‰ 100 batch æ—¶é—´: {elapsed_loop1:.2f}s")
    print(f"  - åŠ è½½æ ·æœ¬æ•°: {sample_count}")
    
    # æµ‹è¯• loop=3
    print(f"\n[æµ‹è¯•] loop=3")
    dataset_loop3 = BinPklDataset(
        data_root=data_root,
        split='train',
        assets=['coord', 'intensity', 'classification'],
        cache_data=False,
        loop=3
    )
    
    batch_sampler_loop3 = DynamicBatchSampler(
        dataset_loop3,
        max_points=300000,
        shuffle=True,
        drop_last=False
    )
    
    dataloader_loop3 = DataLoader(
        dataset_loop3,
        batch_sampler=batch_sampler_loop3,
        collate_fn=collate_fn,
        num_workers=0,
    )
    
    print(f"  - æ•°æ®é›†é•¿åº¦: {len(dataset_loop3):,}")
    print(f"  - é¢„ä¼° batches: {len(batch_sampler_loop3):,}")
    
    # åŠ è½½å‰ 100 ä¸ª batch
    start = time.time()
    batch_count = 0
    sample_count = 0
    for batch in dataloader_loop3:
        batch_count += 1
        sample_count += len(batch['offset'])
        if batch_count >= 100:
            break
    elapsed_loop3 = time.time() - start
    
    print(f"  - å‰ 100 batch æ—¶é—´: {elapsed_loop3:.2f}s")
    print(f"  - åŠ è½½æ ·æœ¬æ•°: {sample_count}")
    
    # å¯¹æ¯”
    print(f"\nå¯¹æ¯”:")
    print(f"  - loop=1: {elapsed_loop1:.2f}s")
    print(f"  - loop=3: {elapsed_loop3:.2f}s")
    print(f"  - é€Ÿåº¦æ¯”: {elapsed_loop3/elapsed_loop1:.2f}x")
    
    if abs(elapsed_loop3 / elapsed_loop1 - 1.0) < 0.1:
        print(f"  - âœ… ç›¸åŒæ•°é‡ batch çš„åŠ è½½æ—¶é—´å‡ ä¹ä¸€è‡´")
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"  - âœ… loop ä¸å½±å“å•ä¸ªæ ·æœ¬çš„åŠ è½½é€Ÿåº¦")
    print(f"  - âœ… loop åªæ˜¯è®©æ•°æ®é›†ã€Œçœ‹èµ·æ¥ã€æ›´å¤§")
    print(f"  - âœ… ç”¨äºå¢åŠ æ¯ä¸ª epoch ä¸­çš„æ•°æ®å¢å¼ºå¤šæ ·æ€§")
    print(f"  - ğŸ“Œ å¦‚æœ loop=3ï¼Œæ¯ä¸ª epoch ä¼šè®¿é—®æ¯ä¸ªæ ·æœ¬ 3 æ¬¡")
    print(f"  - ğŸ“Œ é…åˆæ•°æ®å¢å¼ºï¼Œæ¯æ¬¡è®¿é—®åŒä¸€æ ·æœ¬ä¼šå¾—åˆ°ä¸åŒç»“æœ")
    print(f"  - âš ï¸ æ€»è®­ç»ƒæ—¶é—´ â‰ˆ åŸå§‹æ—¶é—´ Ã— loop")
    print()


def test_cache_data_with_loop():
    """æµ‹è¯• cache_data + loop çš„ç»„åˆæ•ˆæœ"""
    print("="*70)
    print("[ç»„åˆæµ‹è¯•] cache_data + loop çš„æ•ˆæœ")
    print("="*70)
    
    data_root = r"E:\data\DALES\dales_las\bin\train"
    
    if not Path(data_root).exists():
        print(f"[X] æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return
    
    print(f"\nå¯¹æ¯”ä¸¤ç§é…ç½®:\n")
    
    # é…ç½®1: cache_data=False, loop=3
    print(f"[é…ç½®1] cache_data=False, loop=3")
    dataset1 = BinPklDataset(
        data_root=data_root,
        split='train',
        assets=['coord', 'intensity', 'classification'],
        cache_data=False,
        loop=3
    )
    
    # éå†å‰ 300 ä¸ªæ ·æœ¬ï¼ˆå®é™…ä¼šé‡å¤è®¿é—®ï¼‰
    start = time.time()
    for i in range(300):
        sample = dataset1[i]
    time1 = time.time() - start
    
    print(f"  - è®¿é—® 300 ä¸ªæ ·æœ¬: {time1:.2f}s ({time1/300*1000:.2f} ms/æ ·æœ¬)")
    
    # é…ç½®2: cache_data=True, loop=3
    print(f"\n[é…ç½®2] cache_data=True, loop=3")
    dataset2 = BinPklDataset(
        data_root=data_root,
        split='train',
        assets=['coord', 'intensity', 'classification'],
        cache_data=True,
        loop=3
    )
    
    # é¦–æ¬¡éå†ï¼ˆè§¦å‘ç¼“å­˜ï¼‰
    start = time.time()
    for i in range(300):
        sample = dataset2[i]
    time2_first = time.time() - start
    
    print(f"  - é¦–æ¬¡è®¿é—® 300 ä¸ªæ ·æœ¬: {time2_first:.2f}s ({time2_first/300*1000:.2f} ms/æ ·æœ¬)")
    
    # ç¬¬äºŒæ¬¡éå†ï¼ˆä»ç¼“å­˜ï¼‰
    start = time.time()
    for i in range(300):
        sample = dataset2[i]
    time2_second = time.time() - start
    
    print(f"  - ç¬¬äºŒæ¬¡è®¿é—®: {time2_second:.2f}s ({time2_second/300*1000:.2f} ms/æ ·æœ¬)")
    print(f"  - åŠ é€Ÿæ¯”: {time2_first/max(time2_second, 0.001):.1f}x")
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"  - cache_data=False: æ¯æ¬¡éƒ½ä»ç£ç›˜åŠ è½½ï¼ˆæ…¢ä½†çœå†…å­˜ï¼‰")
    print(f"  - cache_data=True: é¦–æ¬¡æ…¢ï¼Œåç»­æå¿«ï¼ˆå¿«ä½†å å†…å­˜ï¼‰")
    print(f"  - æ¨è: å¤§æ•°æ®é›†ç”¨ cache_data=False")
    print(f"  - æ¨è: å°æ•°æ®é›†ç”¨ cache_data=True + loop>1")
    print()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("="*70)
    print("æ·±å…¥åˆ†æï¼šé¦–æ¬¡åŠ è½½é€Ÿåº¦ & loop å‚æ•°å½±å“")
    print("="*70)
    print()
    
    try:
        # æµ‹è¯•1: ç¬¬ä¸€æ¬¡ vs ç¬¬äºŒæ¬¡éå†
        test_first_vs_second_pass()
        
        # æµ‹è¯•2: loop å‚æ•°çš„å½±å“
        test_loop_parameter()
        
        # æµ‹è¯•3: loop åœ¨ DataLoader ä¸­çš„å½±å“
        test_loop_with_dataloader()
        
        # æµ‹è¯•4: cache_data + loop ç»„åˆ
        test_cache_data_with_loop()
        
        print("="*70)
        print("[å®Œæˆ] æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("="*70)
        
        print("\nã€æœ€ç»ˆå»ºè®®ã€‘")
        print("-"*70)
        print("é—®é¢˜1: ç¬¬ä¸€æ¬¡åŠ è½½æ˜¯å¦æ…¢ï¼Ÿ")
        print("  - âœ… ç¬¬ä¸€æ¬¡è®¿é—®æŸä¸ª pkl æ–‡ä»¶ä¸­çš„æ ·æœ¬ä¼šæ…¢ï¼ˆ~60msï¼‰")
        print("  - âœ… ä½† metadata ç¼“å­˜åï¼Œåç»­è®¿é—®è¯¥æ–‡ä»¶çš„æ ·æœ¬å¾ˆå¿«ï¼ˆ~6msï¼‰")
        print("  - âœ… å®Œæ•´ epoch ä¸­ï¼Œ29 ä¸ª pkl å„åŠ è½½ 1 æ¬¡ï¼Œæ€»å¼€é”€ <2s")
        print("  - âœ… å æ€»æ—¶é—´ <2%ï¼Œå¯æ¥å—")
        print()
        print("é—®é¢˜2: loop å¤§å€¼æ˜¯å¦æœ‰å½±å“ï¼Ÿ")
        print("  - âœ… loop ä¸å½±å“å•ä¸ªæ ·æœ¬åŠ è½½é€Ÿåº¦")
        print("  - âœ… loop ä¸å¢åŠ å†…å­˜å ç”¨ï¼ˆä¸å¤åˆ¶æ•°æ®ï¼‰")
        print("  - âœ… loop åªæ˜¯è™šæ‹Ÿæ‰©å±•æ•°æ®é›†é•¿åº¦")
        print("  - âš ï¸ loop=3 â†’ æ¯ä¸ª epoch æ—¶é—´ Ã— 3")
        print("  - ğŸ’¡ é€‚åˆé…åˆæ•°æ®å¢å¼ºï¼Œå¢åŠ è®­ç»ƒå¤šæ ·æ€§")
        print()
        print("æœ€ä½³å®è·µ:")
        print("  - å¤§æ•°æ®é›†: cache_data=False, loop=1-2")
        print("  - å°æ•°æ®é›†: cache_data=True, loop=3-5")
        print("  - æ•°æ®å¢å¼º: ä¸ loop é…åˆä½¿ç”¨ï¼Œæ¯æ¬¡è®¿é—®å¾—åˆ°ä¸åŒæ ·æœ¬")
        print("="*70)
        
    except Exception as e:
        print(f"\n[X] æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
